@online{abdin_etal24,
  title = {Phi-3 {{Technical Report}}: {{A Highly Capable Language Model Locally}} on {{Your Phone}}},
  shorttitle = {Phi-3 {{Technical Report}}},
  author = {Abdin, Marah and Jacobs, Sam Ade and Awan, Ammar Ahmad and Aneja, Jyoti and Awadallah, Ahmed and Awadalla, Hany and Bach, Nguyen and Bahree, Amit and Bakhtiari, Arash and Bao, Jianmin and Behl, Harkirat and Benhaim, Alon and Bilenko, Misha and Bjorck, Johan and Bubeck, Sébastien and Cai, Qin and Cai, Martin and Mendes, Caio César Teodoro and Chen, Weizhu and Chaudhary, Vishrav and Chen, Dong and Chen, Dongdong and Chen, Yen-Chun and Chen, Yi-Ling and Chopra, Parul and Dai, Xiyang and Del Giorno, Allie and family=Rosa, given=Gustavo, prefix=de, useprefix=true and Dixon, Matthew and Eldan, Ronen and Fragoso, Victor and Iter, Dan and Gao, Mei and Gao, Min and Gao, Jianfeng and Garg, Amit and Goswami, Abhishek and Gunasekar, Suriya and Haider, Emman and Hao, Junheng and Hewett, Russell J. and Huynh, Jamie and Javaheripi, Mojan and Jin, Xin and Kauffmann, Piero and Karampatziakis, Nikos and Kim, Dongwoo and Khademi, Mahoud and Kurilenko, Lev and Lee, James R. and Lee, Yin Tat and Li, Yuanzhi and Li, Yunsheng and Liang, Chen and Liden, Lars and Liu, Ce and Liu, Mengchen and Liu, Weishung and Lin, Eric and Lin, Zeqi and Luo, Chong and Madan, Piyush and Mazzola, Matt and Mitra, Arindam and Modi, Hardik and Nguyen, Anh and Norick, Brandon and Patra, Barun and Perez-Becker, Daniel and Portet, Thomas and Pryzant, Reid and Qin, Heyang and Radmilac, Marko and Rosset, Corby and Roy, Sambudha and Ruwase, Olatunji and Saarikivi, Olli and Saied, Amin and Salim, Adil and Santacroce, Michael and Shah, Shital and Shang, Ning and Sharma, Hiteshi and Shukla, Swadheen and Song, Xia and Tanaka, Masahiro and Tupini, Andrea and Wang, Xin and Wang, Lijuan and Wang, Chunyu and Wang, Yu and Ward, Rachel and Wang, Guanhua and Witte, Philipp and Wu, Haiping and Wyatt, Michael and Xiao, Bin and Xu, Can and Xu, Jiahang and Xu, Weijian and Yadav, Sonali and Yang, Fan and Yang, Jianwei and Yang, Ziyi and Yang, Yifan and Yu, Donghan and Yuan, Lu and Zhang, Chengruidong and Zhang, Cyril and Zhang, Jianwen and Zhang, Li Lyna and Zhang, Yi and Zhang, Yue and Zhang, Yunan and Zhou, Xiren},
  date = {2024-05-23},
  eprint = {2404.14219},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2404.14219},
  url = {http://arxiv.org/abs/2404.14219},
  urldate = {2024-06-05},
  abstract = {We introduce phi-3-mini, a 3.8 billion parameter language model trained on 3.3 trillion tokens, whose overall performance, as measured by both academic benchmarks and internal testing, rivals that of models such as Mixtral 8x7B and GPT-3.5 (e.g., phi-3-mini achieves 69\% on MMLU and 8.38 on MT-bench), despite being small enough to be deployed on a phone. The innovation lies entirely in our dataset for training, a scaled-up version of the one used for phi-2, composed of heavily filtered publicly available web data and synthetic data. The model is also further aligned for robustness, safety, and chat format. We also provide some initial parameter-scaling results with a 7B and 14B models trained for 4.8T tokens, called phi-3-small and phi-3-medium, both significantly more capable than phi-3-mini (e.g., respectively 75\% and 78\% on MMLU, and 8.7 and 8.9 on MT-bench). Moreover, we also introduce phi-3-vision, a 4.2 billion parameter model based on phi-3-mini with strong reasoning capabilities for image and text prompts.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/ral/Zotero/storage/K5TL8ZKQ/Abdin et al_2024_Phi-3 Technical Report.pdf;/home/ral/Zotero/storage/ATC7BYU6/2404.html}
}

@article{acerbi_stubbersfield23,
  title = {Large Language Models Show Human-like Content Biases in Transmission Chain Experiments},
  author = {Acerbi, Alberto and Stubbersfield, Joseph M.},
  date = {2023-10-31},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {120},
  number = {44},
  pages = {e2313790120},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.2313790120},
  url = {https://www.pnas.org/doi/abs/10.1073/pnas.2313790120},
  urldate = {2023-12-23},
  abstract = {As the use of large language models (LLMs) grows, it is important to examine whether they exhibit biases in their output. Research in cultural evolution, using transmission chain experiments, demonstrates that humans have biases to attend to, remember, and transmit some types of content over others. Here, in five preregistered experiments using material from previous studies with human participants, we use the same, transmission chain-like methodology, and find that the LLM ChatGPT-3 shows biases analogous to humans for content that is gender-stereotype-consistent, social, negative, threat-related, and biologically counterintuitive, over other content. The presence of these biases in LLM output suggests that such content is widespread in its training data and could have consequential downstream effects, by magnifying preexisting human tendencies for cognitively appealing and not necessarily informative, or valuable, content.},
  annotation = {24 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/D8KKXY8T/Acerbi et Stubbersfield - 2023 - Large language models show human-like content bias.pdf}
}

@book{adams_etal05,
  title = {A {{Unified Theory}} of {{Party Competition}}: {{A Cross-National Analysis Integrating Spatial}} and {{Behavioral Factors}}},
  shorttitle = {A {{Unified Theory}} of {{Party Competition}}},
  author = {Adams, James F. and III, Samuel Merrill and Grofman, Bernard},
  date = {2005-03-21},
  eprint = {AHw6vYDv69cC},
  eprinttype = {googlebooks},
  publisher = {Cambridge University Press},
  abstract = {This book integrates spatial and behavioral perspectives - in a word, those of the Rochester and Michigan schools - into a unified theory of voter choice and party strategy. The theory encompasses both policy and non-policy factors, effects of turnout, voter discounting of party promises, expectations of coalition governments, and party motivations based on policy as well as office. Optimal (Nash equilibrium) strategies are determined for alternative models for presidential elections in the US and France, and for parliamentary elections in Britain and Norway. These polities cover a wide range of electoral rules, number of major parties, and governmental structures. The analyses suggest that the more competitive parties generally take policy positions that come close to maximizing their electoral support, and that these vote-maximizing positions correlate strongly with the mean policy positions of their supporters.},
  isbn = {978-1-139-44400-2},
  langid = {english},
  pagetotal = {344}
}

@article{adams_etal17,
  title = {Shades of {{Grey}}: {{Guidelines}} for {{Working}} with the {{Grey Literature}} in {{Systematic Reviews}} for {{Management}} and {{Organizational Studies}}},
  shorttitle = {Shades of {{Grey}}},
  author = {Adams, Richard J. and Smart, Palie and Huff, Anne Sigismund},
  date = {2017},
  journaltitle = {International Journal of Management Reviews},
  volume = {19},
  number = {4},
  pages = {432--454},
  issn = {1468-2370},
  doi = {10.1111/ijmr.12102},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ijmr.12102},
  urldate = {2024-10-27},
  abstract = {This paper suggests how the ‘grey literature’, the diverse and heterogeneous body of material that is made public outside, and not subject to, traditional academic peer-review processes, can be used to increase the relevance and impact of management and organization studies (MOS). The authors clarify the possibilities by reviewing 140 systematic reviews published in academic and practitioner outlets to answer the following three questions: (i) Why is grey literature excluded from/included in systematic reviews in MOS? (ii) What types of grey material have been included in systematic reviews since guidelines for practice were first established in this discipline? (iii) How is the grey literature treated currently to advance management and organization scholarship and knowledge? This investigation updates previous guidelines for more inclusive systematic reviews that respond to criticisms of current review practices and the needs of evidence-based management.},
  langid = {english},
  annotation = {513 citations (Crossref/DOI) [2024-11-13]},
  file = {/home/ral/Zotero/storage/5Q3TK7Z8/Adams et al. - 2017 - Shades of Grey Guidelines for Working with the Grey Literature in Systematic Reviews for Management.pdf;/home/ral/Zotero/storage/MPVWUL25/ijmr.html}
}

@article{agrawal_etal23,
  title = {Do We Want Less Automation?},
  author = {Agrawal, Ajay and Gans, Joshua S. and Goldfarb, Avi},
  date = {2023-07-14},
  journaltitle = {Science},
  shortjournal = {Science},
  volume = {381},
  number = {6654},
  pages = {155--158},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.adh9429},
  url = {https://www.science.org/doi/10.1126/science.adh9429},
  urldate = {2023-09-27},
  abstract = {AI may provide a path to decrease inequality , Impressive achievements made through artificial intelligence (AI) innovations in automating the tasks required in many jobs have reinforced concerns about labor market disruption and increased income inequality. This has motivated calls for change in the direction of AI innovation from being guided by task automation to instead focusing on labor augmentation ( 1 ). But task automation and labor augmentation are not polar opposites. Instead, automation of some tasks can lead to augmentation of labor elsewhere. Furthermore, AI automation may provide a path to reversing the trend of increasing income inequality by enabling disproportionate productivity improvements for lower-wage workers, allowing them to perform at levels that would previously require years of education and experience.},
  langid = {english},
  annotation = {14 citations (Crossref/DOI) [2024-10-14]}
}

@article{alafnan_etal23,
  title = {Chatgpt as an Educational Tool: {{Opportunities}}, Challenges, and Recommendations for Communication, Business Writing, and Composition Courses},
  shorttitle = {Chatgpt as an Educational Tool},
  author = {AlAfnan, Mohammad Awad and Dishari, Samira and Jovic, Marina and Lomidze, Koba},
  date = {2023},
  journaltitle = {Journal of Artificial Intelligence and Technology},
  volume = {3},
  number = {2},
  pages = {60--68},
  url = {https://ojs.istp-press.com/jait/article/view/184},
  urldate = {2023-09-27},
  file = {/home/ral/Zotero/storage/YL6SVLCJ/AlAfnan et al. - 2023 - Chatgpt as an educational tool Opportunities, challenges, and recommendations for communication, bu.pdf}
}

@article{alexanderobaigbena_etal24,
  title = {{{AI}} and Human-Robot Interaction: {{A}} Review of Recent Advances and Challenges},
  shorttitle = {{{AI}} and Human-Robot Interaction},
  author = {{Alexander Obaigbena} and {Oluwaseun Augustine Lottu} and {Ejike David Ugwuanyi} and {Boma Sonimitiem Jacks} and {Enoch Oluwademilade Sodiya} and {Obinna Donald Daraojimba} and {Oluwaseun Augustine Lottu}},
  date = {2024-02-28},
  journaltitle = {GSC Advanced Research and Reviews},
  shortjournal = {GSC Adv. Res. Rev.},
  volume = {18},
  number = {2},
  pages = {321--330},
  issn = {25824597},
  doi = {10.30574/gscarr.2024.18.2.0070},
  url = {https://gsconlinepress.com/journals/gscarr/content/ai-and-human-robot-interaction-review-recent-advances-and-challenges},
  urldate = {2024-09-12},
  abstract = {The integration of artificial intelligence (AI) into human-robot interaction (HRI) has witnessed significant advancements in recent years, revolutionizing the way humans and robots collaborate and coexist. This review provides a comprehensive overview of the latest breakthroughs in AI-driven HRI and identifies the challenges that lie ahead. Recent years have seen a surge in AI-driven capabilities that enhance human-robot interaction. Machine learning algorithms enable robots to adapt to user preferences and behaviors, creating personalized and intuitive interactions. Natural language processing (NLP) facilitates seamless communication between humans and robots, enabling voice commands and context-aware responses. Computer vision advancements empower robots with enhanced perception, enabling them to recognize and interpret human gestures, emotions, and facial expressions. Reinforcement learning has played a pivotal role in enabling robots to learn from human feedback and optimize their actions in real-time. Socially assistive robots leverage AI to provide emotional support and companionship, particularly in healthcare and elderly care settings. Despite these advancements, challenges persist in the field of AI-driven HRI. Ethical considerations, including privacy concerns and the responsible use of AI in influencing human behavior, demand careful attention. Ensuring the safety and security of AI-driven robotic systems remains paramount, requiring robust measures against malicious attacks and unintended consequences. Human-robot trust remains a critical challenge, necessitating transparent AI algorithms and effective communication strategies. Interdisciplinary collaboration between AI researchers, roboticists, psychologists, and ethicists is essential to address the complex socio-technical aspects of HRI. The fusion of AI and human-robot interaction holds immense potential to redefine various facets of our daily lives. This review highlights recent strides in AI-driven HRI, emphasizing the need for interdisciplinary efforts to address challenges and ensure the responsible development and deployment of AI-powered robotic systems. As researchers continue to innovate, the dynamic landscape of AI and human-robot interaction promises a future where seamless collaboration and coexistence between humans and robots become an integral part of our societal fabric.},
  langid = {english},
  annotation = {6 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/BA4KP68Z/Alexander Obaigbena et al. - 2024 - AI and human-robot interaction A review of recent advances and challenges.pdf}
}

@article{alkaissi_mcfarlane23,
  title = {Artificial {{Hallucinations}} in {{ChatGPT}}: {{Implications}} in {{Scientific Writing}}},
  shorttitle = {Artificial {{Hallucinations}} in {{ChatGPT}}},
  author = {Alkaissi, Hussam and McFarlane, Samy I},
  date = {2023},
  journaltitle = {Cureus},
  abstract = {While still in its infancy, ChatGPT (Generative Pretrained Transformer), introduced in November 2022, is bound to hugely impact many industries, including healthcare, medical education, biomedical research, and scientific writing. Implications of ChatGPT, that new chatbot introduced by OpenAI on academic writing, is largely unknown. In response to the Journal of Medical Science (Cureus) Turing Test - call for case reports written with the assistance of ChatGPT, we present two cases one of homocystinuria-associated osteoporosis, and the other is on late-onset Pompe disease (LOPD), a rare metabolic disorder. We tested ChatGPT to write about the pathogenesis of these conditions. We documented the positive, negative, and rather troubling aspects of our newly introduced chatbot’s performance.},
  langid = {english},
  file = {/home/ral/Zotero/storage/ST5ZGXIQ/Alkaissi and McFarlane - 2023 - Artificial Hallucinations in ChatGPT Implications.pdf}
}

@article{alshami_etal23,
  title = {Harnessing the {{Power}} of {{ChatGPT}} for {{Automating Systematic Review Process}}: {{Methodology}}, {{Case Study}}, {{Limitations}}, and {{Future Directions}}},
  shorttitle = {Harnessing the {{Power}} of {{ChatGPT}} for {{Automating Systematic Review Process}}},
  author = {Alshami, Ahmad and Elsayed, Moustafa and Ali, Eslam and Eltoukhy, Abdelrahman EE and Zayed, Tarek},
  date = {2023},
  journaltitle = {Systems},
  volume = {11},
  number = {7},
  pages = {351},
  publisher = {MDPI},
  url = {https://www.mdpi.com/2079-8954/11/7/351},
  urldate = {2023-09-27},
  file = {/home/ral/Zotero/storage/EJMZ7V2C/Alshami et al. - 2023 - Harnessing the Power of ChatGPT for Automating Systematic Review Process Methodology, Case Study, L.pdf}
}

@book{anderson83,
  title = {Imagined Communities: Reflections on the Origin and Spread of Nationalism},
  shorttitle = {Imagined Communities},
  author = {Anderson, Benedict R. O'G},
  date = {1983},
  edition = {Rev. and extended ed., 13. impression},
  publisher = {Verso},
  location = {London},
  isbn = {978-0-86091-546-1 978-0-86091-329-0},
  langid = {english},
  pagetotal = {224},
  file = {/home/ral/Zotero/storage/3JVW3EAK/Benedict Anderson - Imagined Communities_ Reflections on the Origin and Spread of Nationalism-Verso (1991).pdf}
}

@report{arel-bundock_etal22,
  type = {preprint},
  title = {Quantitative {{Political Science Research}} Is {{Greatly Underpowered}}},
  author = {Arel-Bundock, Vincent and Briggs, Ryan C and Doucouliagos, Hristos and Mendoza Aviña, Marco and Stanley, T.D.},
  date = {2022-07-05},
  institution = {Open Science Framework},
  doi = {10.31219/osf.io/7vy2f},
  url = {https://osf.io/7vy2f},
  urldate = {2023-05-01},
  abstract = {The social sciences face a replicability crisis. A key determinant of replication success is statistical power. We assess the power of political science research by collating over 16,000 hypothesis tests from about 2,000 articles in 46 areas of the discipline. Under generous assumptions, we show that quantitative research in political science is greatly underpowered: the median analysis has about 10\% power, and only about 1 in 10 tests have at least 80\% power to detect the consensus effects reported in the literature. We also find substantial heterogeneity in tests across research areas, with some being characterized by high power but most having very low power. To contextualize our findings, we survey political methodologists to assess their expectations about power levels. Most methodologists greatly overestimate the statistical power of political science research.},
  langid = {english},
  keywords = {duplicate-citation-key,notion}
}

@article{arksey_omalley05,
  title = {Scoping Studies: Towards a Methodological Framework},
  shorttitle = {Scoping Studies},
  author = {Arksey, Hilary and O'Malley, Lisa},
  date = {2005-02-01},
  journaltitle = {International Journal of Social Research Methodology},
  volume = {8},
  number = {1},
  pages = {19--32},
  publisher = {Routledge},
  issn = {1364-5579},
  doi = {10.1080/1364557032000119616},
  url = {https://doi.org/10.1080/1364557032000119616},
  urldate = {2024-03-18},
  abstract = {This paper focuses on scoping studies, an approach to reviewing the literature which to date has received little attention in the research methods literature. We distinguish between different types of scoping studies and indicate where these stand in relation to full systematic reviews. We outline a framework for conducting a scoping study based on our recent experiences of reviewing the literature on services for carers for people with mental health problems. Where appropriate, our approach to scoping the field is contrasted with the procedures followed in systematic reviews. We emphasize how including a consultation exercise in this sort of study may enhance the results, making them more useful to policy makers, practitioners and service users. Finally, we consider the advantages and limitations of the approach and suggest that a wider debate is called for about the role of the scoping study in relation to other types of literature reviews.},
  annotation = {19455 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/IMRFMXE9/Arksey et O'Malley - 2005 - Scoping studies towards a methodological framewor.pdf;/home/ral/Zotero/storage/MTIN8EL5/Arksey and O'Malley - 2005 - Scoping studies Towards a methodological framework.pdf}
}

@inproceedings{asyrofi_etal23a,
  title = {Systematic {{Literature Review Langchain Proposed}}},
  booktitle = {2023 {{International Electronics Symposium}} ({{IES}})},
  author = {Asyrofi, Rakha and Dewi, Mutia Rahmi and Lutfhi, Muhammad Irfan and Wibowo, Prasetyo},
  date = {2023-08-08},
  pages = {533--537},
  publisher = {IEEE},
  location = {Denpasar, Indonesia},
  doi = {10.1109/IES59143.2023.10242497},
  url = {https://ieeexplore.ieee.org/document/10242497/},
  urldate = {2023-10-19},
  abstract = {While systematic literature reviews are frequently carried out within software engineering research, performing them in a rigorous and reproducible manner can be difficult. This paper proposes some new methods for evaluating and validating systematic literature reviews. Our approach consists of several steps, such as: Selecting a set of relevant scientific papers to analyze, Developing a list of questions and criteria to evaluate each literature review, and Determining what types of functionality and performance should be evaluated. We tested our method by having multiple experts evaluate the literature reviews based on our questions and criteria. We measured the similarity in scores between each expert to determine the reliability of the evaluations. The average similarity index between experts was 0.58 to 0.83, indicating a reasonable level of agreement in their assessments. This shows our evaluation method can produce fairly consistent results, even when different experts are involved. The relatively high level of agreement is notable considering each expert brings their perspectives and opinions in analyzing literature reviews. By providing concrete questions, criteria, and evaluation methods, we aimed to guide the experts toward more uniform evaluations. In summary, we developed and tested a new approach for evaluating and validating systematic literature reviews in software engineering. By assessing reliability via interrater agreement, we showed that consistent and reproducible results are possible using our evaluation framework and methodology. Our methods could help researchers gain more insight into what makes for an effective and high-quality literature review.},
  eventtitle = {2023 {{International Electronics Symposium}} ({{IES}})},
  isbn = {9798350314731},
  langid = {english},
  annotation = {5 citations (Crossref/DOI) [2024-10-14]}
}

@article{azamfirei_etal23,
  title = {Application of Automation for In-Line Quality Inspection, a Zero-Defect Manufacturing Approach},
  author = {Azamfirei, Victor and Psarommatis, Foivos and Lagrosen, Yvonne},
  date = {2023},
  journaltitle = {Journal of Manufacturing Systems},
  volume = {67},
  pages = {1--22},
  publisher = {Elsevier},
  url = {https://www.sciencedirect.com/science/article/pii/S0278612522002291},
  urldate = {2023-09-27},
  file = {/home/ral/Zotero/storage/W2VII8MA/Azamfirei et al. - 2023 - Application of automation for in-line quality inspection, a zero-defect manufacturing approach.pdf}
}

@unpublished{azaria22,
  title = {{{ChatGPT Usage}} and {{Limitations}}},
  author = {Azaria, Amos},
  date = {2022-12},
  url = {https://hal.science/hal-03913837},
  urldate = {2023-09-27},
  abstract = {Large language models have been shown useful in multiple domains including conversational agents, education, and explainable AI. ChatGPT is a large language model developed by OpenAI as a conversational agent. Being a large language model, ChatGPT is trained on massive amounts of data. Clearly, the characteristics of the data influence ChatGPT's responses. In this paper, we stress a surprising bias of ChatGPT related to the use of digits in numbers. Namely, we show a very high correlation between the frequency of digits generated by ChatGPT and humans' favorite numbers, with the most frequent digit generated by ChatGPT, matching humans' most favorable number, 7. We also show some advantages of ChatGPT being developed as a conversational agent, and discuss some of its limitations.},
  file = {/home/ral/Zotero/storage/GYUMQ8U5/Azaria - 2022 - ChatGPT Usage and Limitations.pdf}
}

@inproceedings{baack24,
  title = {A {{Critical Analysis}} of the {{Largest Source}} for {{Generative AI Training Data}}: {{Common Crawl}}},
  shorttitle = {A {{Critical Analysis}} of the {{Largest Source}} for {{Generative AI Training Data}}},
  booktitle = {Proceedings of the 2024 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Baack, Stefan},
  date = {2024-06-05},
  series = {{{FAccT}} '24},
  pages = {2199--2208},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3630106.3659033},
  url = {https://doi.org/10.1145/3630106.3659033},
  urldate = {2024-10-25},
  abstract = {Common Crawl is the largest freely available collection of web crawl data and one of the most important sources of pre-training data for large language models (LLMs). It is used so frequently and makes up such large proportions of the overall pre-training data in many cases that it arguably has become a foundational building block for LLM development, and subsequently generative AI products built on top of LLMs. Despite its pivotal role, Common Crawl itself is not widely understood, nor is there much reflection evident among LLM builders about the implications of using Common Crawl's data. This paper discusses what Common Crawl's popularity for LLM development means for fairness, accountability, and transparency in generative AI by highlighting the organization's values and practices, as well as how it views its own role within the AI ecosystem. Our qualitative analysis is based on in-depth interviews with Common Crawl staffers and relevant online documents.After discussing Common Crawl's role in generative AI and how LLM builders have typically used its data for pre-training LLMs, we review Common Crawl's self-defined values and priorities and highlight the limitations and biases of its crawling process. We find that Common Crawl's popularity has contributed to making generative AI more transparent to scrutiny in many ways, and that it has enabled more LLM research and development to take place beyond well-resourced leading AI companies. At the same time, many LLM builders have used Common Crawl as a source for training data in ways that are problematic: for instance, with lack of care and transparency for how Common Crawl's massive crawl data was filtered for harmful content before the pre-training, often by relying on rudimentary automated filtering techniques. We offer recommendations for Common Crawl and LLM builders on how to improve fairness, accountability, and transparency in LLM research and development.},
  isbn = {9798400704505},
  annotation = {0 citations (Crossref/DOI) [2024-11-13]}
}

@article{babl_babl23,
  title = {Generative Artificial Intelligence: {{Can}} {{{\textsc{ChatGPT}}}} Write a Quality Abstract?},
  shorttitle = {Generative Artificial Intelligence},
  author = {Babl, Franz E and Babl, Maximilian P},
  date = {2023-10},
  journaltitle = {Emergency Medicine Australasia},
  shortjournal = {Emerg Medicine Australasia},
  volume = {35},
  number = {5},
  pages = {809--811},
  issn = {1742-6731, 1742-6723},
  doi = {10.1111/1742-6723.14233},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/1742-6723.14233},
  urldate = {2023-09-27},
  abstract = {Abstract ChatGPT is a generative artificial intelligence chatbot which may have a role in medicine and science. We investigated if the freely available version of ChatGPT can produce a quality conference abstract using a fictitious but accurately calculated data table as applied by a non‐medically trained person. The resulting abstract was well written without obvious errors and followed the abstract instructions. One of the references was fictitious, known as ‘hallucination’. ChatGPT or similar programmes, with careful review of the product by authors, may become a valuable scientific writing tool. The scientific and medical use of generative artificial intelligence, however, raises many questions.},
  langid = {english},
  annotation = {27 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/WFEUVBCS/Babl and Babl - 2023 - Generative artificial intelligence Can ChatGPT write.pdf}
}

@article{baidoo-anu_owusuansah23,
  title = {Education in the {{Era}} of {{Generative Artificial Intelligence}} ({{AI}}): {{Understanding}} the {{Potential Benefits}} of {{ChatGPT}} in {{Promoting Teaching}} and {{Learning}}},
  shorttitle = {Education in the {{Era}} of {{Generative Artificial Intelligence}} ({{AI}})},
  author = {Baidoo-Anu, David and Owusu Ansah, Leticia},
  date = {2023},
  journaltitle = {SSRN Electronic Journal},
  shortjournal = {SSRN Journal},
  issn = {1556-5068},
  doi = {10.2139/ssrn.4337484},
  url = {https://www.ssrn.com/abstract=4337484},
  urldate = {2023-09-26},
  abstract = {Since its maiden release into the public domain on November 30, 2022, ChatGPT garnered more than one million subscribers within a week. The generative AI tool ⎼ChatGPT took the world by surprise with it sophisticated capacity to carry out remarkably complex tasks. The extraordinary abilities of ChatGPT to perform complex tasks within the field of education has caused mixed feelings among educators, as this advancement in AI seems to revolutionize existing educational praxis. This is an exploratory study that synthesizes recent extant literature to offer some potential benefits and drawbacks of ChatGPT in promoting teaching and learning. Benefits of ChatGPT include but are not limited to promotion of personalized and interactive learning, generating prompts for formative assessment activities that provide ongoing feedback to inform teaching and learning etc. The paper also highlights some inherent limitations in the ChatGPT such as generating wrong information, biases in data training, which may augment existing biases, privacy issues etc. The study offers recommendations on how ChatGPT could be leveraged to maximize teaching and learning. Policy makers, researchers, educators and technology experts could work together and start conversations on how these evolving generative AI tools could be used safely and constructively to improve education and support students’ learning.},
  langid = {english},
  annotation = {342 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/MJEL8HHH/Baidoo-Anu and Owusu Ansah - 2023 - Education in the Era of Generative Artificial Intelligence (AI) Understanding the Potential Benefit.pdf}
}

@article{bail23,
  title = {Can {{Generative AI Improve Social Science}}?},
  author = {Bail, Christopher A.},
  date = {2023},
  publisher = {SocArXiv},
  url = {https://osf.io/rwtzs/download},
  urldate = {2023-09-27}
}

@article{ballandonne_cersosimo23,
  title = {Towards a “{{Text}} as {{Data}}” {{Approach}} in the {{History}} of {{Economics}}: {{An Application}} to {{Adam Smith}}’s {{Classics}}},
  shorttitle = {Towards a “{{Text}} as {{Data}}” {{Approach}} in the {{History}} of {{Economics}}},
  author = {Ballandonne, Matthieu and Cersosimo, Igor},
  date = {2023},
  journaltitle = {Journal of the History of Economic Thought},
  volume = {45},
  number = {1},
  pages = {27--49},
  publisher = {Cambridge University Press},
  url = {https://www.cambridge.org/core/journals/journal-of-the-history-of-economic-thought/article/towards-a-text-as-data-approach-in-the-history-of-economics-an-application-to-adam-smiths-classics/30DC11E004DE0F7A33F5B30669D195DD},
  urldate = {2023-09-27}
}

@online{bang_etal23,
  title = {A {{Multitask}}, {{Multilingual}}, {{Multimodal Evaluation}} of {{ChatGPT}} on {{Reasoning}}, {{Hallucination}}, and {{Interactivity}}},
  author = {Bang, Yejin and Cahyawijaya, Samuel and Lee, Nayeon and Dai, Wenliang and Su, Dan and Wilie, Bryan and Lovenia, Holy and Ji, Ziwei and Yu, Tiezheng and Chung, Willy and Do, Quyet V. and Xu, Yan and Fung, Pascale},
  date = {2023-02-08},
  url = {https://arxiv.org/abs/2302.04023v4},
  urldate = {2023-12-06},
  abstract = {This paper proposes a framework for quantitatively evaluating interactive LLMs such as ChatGPT using publicly available data sets. We carry out an extensive technical evaluation of ChatGPT using 23 data sets covering 8 different common NLP application tasks. We evaluate the multitask, multilingual and multi-modal aspects of ChatGPT based on these data sets and a newly designed multimodal dataset. We find that ChatGPT outperforms LLMs with zero-shot learning on most tasks and even outperforms fine-tuned models on some tasks. We find that it is better at understanding non-Latin script languages than generating them. It is able to generate multimodal content from textual prompts, via an intermediate code generation step. Moreover, we find that ChatGPT is 63.41\% accurate on average in 10 different reasoning categories under logical reasoning, non-textual reasoning, and commonsense reasoning, hence making it an unreliable reasoner. It is, for example, better at deductive than inductive reasoning. ChatGPT suffers from hallucination problems like other LLMs and it generates more extrinsic hallucinations from its parametric memory as it does not have access to an external knowledge base. Finally, the interactive feature of ChatGPT enables human collaboration with the underlying LLM to improve its performance, i.e, 8\% ROUGE-1 on summarization and 2\% ChrF++ on machine translation, in a multi-turn "prompt engineering" fashion. We also release codebase for evaluation set extraction.},
  langid = {english},
  file = {/home/ral/Zotero/storage/5QQ27NKA/Bang et al. - 2023 - A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interac.pdf}
}

@article{barbera15,
  title = {Birds of the {{Same Feather Tweet Together}}: {{Bayesian Ideal Point Estimation Using Twitter Data}}},
  shorttitle = {Birds of the {{Same Feather Tweet Together}}},
  author = {Barberá, Pablo},
  date = {2015-01},
  journaltitle = {Political Analysis},
  volume = {23},
  number = {1},
  pages = {76--91},
  publisher = {Cambridge University Press},
  issn = {1047-1987, 1476-4989},
  doi = {10.1093/pan/mpu011},
  url = {https://www.cambridge.org/core/journals/political-analysis/article/birds-of-the-same-feather-tweet-together-bayesian-ideal-point-estimation-using-twitter-data/91E37205F69AEA32EF27F12563DC2A0A},
  urldate = {2023-12-26},
  abstract = {Politicians and citizens increasingly engage in political conversations on social media outlets such as Twitter. In this article, I show that the structure of the social networks in which they are embedded can be a source of information about their ideological positions. Under the assumption that social networks are homophilic, I develop a Bayesian Spatial Following model that considers ideology as a latent variable, whose value can be inferred by examining which politics actors each user is following. This method allows us to estimate ideology for more actors than any existing alternative, at any point in time and across many polities. I apply this method to estimate ideal points for a large sample of both elite and mass public Twitter users in the United States and five European countries. The estimated positions of legislators and political parties replicate conventional measures of ideology. The method is also able to successfully classify individuals who state their political preferences publicly and a sample of users matched with their party registration records. To illustrate the potential contribution of these estimates, I examine the extent to which online behavior during the 2012 US presidential election campaign is clustered along ideological lines.},
  langid = {english},
  annotation = {478 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/DHMM959M/Barberá_2015_Birds of the Same Feather Tweet Together.pdf}
}

@article{bates_jenkins07,
  title = {Teaching and {{Learning Ontology}} and {{Epistemology}} in {{Political Science}}},
  author = {Bates, Stephen R. and Jenkins, Laura},
  date = {2007-02},
  journaltitle = {Politics},
  shortjournal = {Politics},
  volume = {27},
  number = {1},
  pages = {55--63},
  issn = {0263-3957, 1467-9256},
  doi = {10.1111/j.1467-9256.2007.00279.x},
  url = {http://journals.sagepub.com/doi/10.1111/j.1467-9256.2007.00279.x},
  urldate = {2023-01-27},
  abstract = {The teaching and learning of ontology and epistemology is an important element of political science, as it helps students to appraise, differentiate and choose between competing philosophies, theories and analytical traditions. Thus, it encourages reflexive learning through the strategies of inquiry, role taking and benign disruption. However, we argue that there are aspects within the most prominent introductory material on these meta-theoretical issues which may undermine these processes. In particular, definitional inaccuracies and a lack of sustained reflection on the contested nature of the directional relationship between ontology and epistemology tend towards a prescriptive ‘path dependency’ and curtail the possibility of reflexive learning. By subjecting this received knowledge to critical reflection, we hope to overturn these weaknesses and open up a debate on the teaching and learning of ontology and epistemology.},
  langid = {english},
  keywords = {notion},
  annotation = {26 citations (Crossref/DOI) [2024-10-14]}
}

@article{baturo_etal17,
  title = {Understanding State Preferences with Text as Data: {{Introducing}} the {{UN General Debate}} Corpus},
  shorttitle = {Understanding State Preferences with Text as Data},
  author = {Baturo, Alexander and Dasandi, Niheer and Mikhaylov, Slava J.},
  date = {2017-04},
  journaltitle = {Research \& Politics},
  shortjournal = {Research \& Politics},
  volume = {4},
  number = {2},
  pages = {205316801771282},
  issn = {2053-1680, 2053-1680},
  doi = {10.1177/2053168017712821},
  url = {http://journals.sagepub.com/doi/10.1177/2053168017712821},
  urldate = {2023-09-27},
  abstract = {Every year at the United Nations (UN), member states deliver statements during the General Debate (GD) discussing major issues in world politics. These speeches provide invaluable information on governments’ perspectives and preferences on a wide range of issues, but have largely been overlooked in the study of international politics. This paper introduces a new dataset consisting of over 7300 country statements from 1970–2014. We demonstrate how the UN GD corpus (UNGDC) can be used as a resource from which country positions on different policy dimensions can be derived using text analytic methods. The article provides applications of these estimates, demonstrating the contribution the UNGDC can make to the study of international politics.},
  langid = {english},
  annotation = {85 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/W4KYIBZW/Baturo et al. - 2017 - Understanding state preferences with text as data Introducing the UN General Debate corpus.pdf}
}

@article{bayer_etal23,
  title = {Data Augmentation in Natural Language Processing: A Novel Text Generation Approach for Long and Short Text Classifiers},
  shorttitle = {Data Augmentation in Natural Language Processing},
  author = {Bayer, Markus and Kaufhold, Marc-André and Buchhold, Björn and Keller, Marcel and Dallmeyer, Jörg and Reuter, Christian},
  date = {2023-01},
  journaltitle = {International Journal of Machine Learning and Cybernetics},
  shortjournal = {Int. J. Mach. Learn. \& Cyber.},
  volume = {14},
  number = {1},
  pages = {135--150},
  issn = {1868-8071, 1868-808X},
  doi = {10.1007/s13042-022-01553-3},
  url = {https://link.springer.com/10.1007/s13042-022-01553-3},
  urldate = {2023-09-27},
  abstract = {Abstract In many cases of machine learning, research suggests that the development of training data might have a higher relevance than the choice and modelling of classifiers themselves. Thus, data augmentation methods have been developed to improve classifiers by artificially created training data. In NLP, there is the challenge of establishing universal rules for text transformations which provide new linguistic patterns. In this paper, we present and evaluate a text generation method suitable to increase the performance of classifiers for long and short texts. We achieved promising improvements when evaluating short as well as long text tasks with the enhancement by our text generation method. Especially with regard to small data analytics, additive accuracy gains of up to 15.53\% and 3.56\% are achieved within a constructed low data regime, compared to the no augmentation baseline and another data augmentation technique. As the current track of these constructed regimes is not universally applicable, we also show major improvements in several real world low data tasks (up to +4.84 F1-score). Since we are evaluating the method from many perspectives (in total 11 datasets), we also observe situations where the method might not be suitable. We discuss implications and patterns for the successful application of our approach on different types of datasets.},
  langid = {english},
  annotation = {54 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/4XRVYQRM/Bayer et al. - 2023 - Data augmentation in natural language processing a novel text generation approach for long and shor.pdf}
}

@article{baytak23,
  title = {The {{Acceptance}} and {{Diffusion}} of {{Generative Artificial Intelligence}} in {{Education}}: {{A Literature Review}}},
  shorttitle = {The {{Acceptance}} and {{Diffusion}} of {{Generative Artificial Intelligence}} in {{Education}}},
  author = {Baytak, Ahmet},
  date = {2023},
  journaltitle = {Current Perspectives in Educational Research},
  volume = {6},
  number = {1},
  pages = {7--18},
  url = {https://cuperjournal.org/index.php/cuper/article/view/7},
  urldate = {2023-09-27},
  file = {/home/ral/Zotero/storage/NSGZ6832/Baytak - 2023 - The Acceptance and Diffusion of Generative Artificial Intelligence in Education A Literature Review.pdf}
}

@inproceedings{bender_etal21,
  title = {On the {{Dangers}} of {{Stochastic Parrots}}: {{Can Language Models Be Too Big}}?},
  shorttitle = {On the {{Dangers}} of {{Stochastic Parrots}}},
  booktitle = {Proceedings of the 2021 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Bender, Emily M. and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  date = {2021-03-01},
  series = {{{FAccT}} '21},
  pages = {610--623},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3442188.3445922},
  url = {https://dl.acm.org/doi/10.1145/3442188.3445922},
  urldate = {2024-01-03},
  abstract = {The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.},
  isbn = {978-1-4503-8309-7},
  annotation = {1562 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/5P53LISW/Bender et al_2021_On the Dangers of Stochastic Parrots.pdf;/home/ral/Zotero/storage/9L9XVM22/Bender et al. - 2021 - On the Dangers of Stochastic Parrots Can Language.pdf}
}

@article{berinsky_etal21,
  title = {Publication {{Biases}} in {{Replication Studies}}},
  author = {Berinsky, Adam J. and Druckman, James N. and Yamamoto, Teppei},
  date = {2021-07},
  journaltitle = {Political Analysis},
  shortjournal = {Polit. Anal.},
  volume = {29},
  number = {3},
  pages = {370--384},
  issn = {1047-1987, 1476-4989},
  doi = {10.1017/pan.2020.34},
  url = {https://www.cambridge.org/core/product/identifier/S1047198720000340/type/journal_article},
  urldate = {2023-09-04},
  abstract = {One of the strongest findings across the sciences is that publication bias occurs. Of particular note is a “file drawer bias” where statistically significant results are privileged over nonsignificant results. Recognition of this bias, along with increased calls for “open science,” has led to an emphasis on replication studies. Yet, few have explored publication bias and its consequences in replication studies. We offer a model of the publication process involving an initial study and a replication. We use the model to describe three types of publication biases: ( ) file drawer bias, ( ) a “repeat study” bias against the publication of replication studies, and ( ) a “gotcha bias” where replication results that run contrary to a prior study are more likely to be published. We estimate the model’s parameters with a vignette experiment conducted with political science professors teaching at Ph.D. granting institutions in the United States. We find evidence of all three types of bias, although those explicitly involving replication studies are notably smaller. This bodes well for the replication movement. That said, the aggregation of all of the biases increases the number of false positives in a literature. We conclude by discussing a path for future work on publication biases.},
  langid = {english},
  keywords = {notion},
  annotation = {3 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/KNI3I9LD/Berinsky et al. - 2021 - Publication Biases in Replication Studies.pdf}
}

@book{bickman_rog09,
  title = {The {{SAGE}} Handbook of Applied Social Research Methods},
  editor = {Bickman, Leonard and Rog, Debra J.},
  date = {2009},
  edition = {2nd ed},
  publisher = {SAGE},
  location = {Los Angeles},
  isbn = {978-1-4129-5031-2},
  langid = {english},
  pagetotal = {661},
  keywords = {Methodology,Research Methodology,Social sciences},
  annotation = {OCLC: ocn212893577},
  file = {/home/ral/Zotero/storage/R8WRFFDY/Bickman and Rog - 2009 - The SAGE handbook of applied social research metho.pdf}
}

@online{binz_etal23,
  title = {How Should the Advent of Large Language Models Affect the Practice of Science?},
  author = {Binz, Marcel and Alaniz, Stephan and Roskies, Adina and Aczel, Balazs and Bergstrom, Carl T. and Allen, Colin and Schad, Daniel and Wulff, Dirk and West, Jevin D. and Zhang, Qiong and Shiffrin, Richard M. and Gershman, Samuel J. and Popov, Ven and Bender, Emily M. and Marelli, Marco and Botvinick, Matthew M. and Akata, Zeynep and Schulz, Eric},
  date = {2023-12-05},
  eprint = {2312.03759},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2312.03759},
  url = {http://arxiv.org/abs/2312.03759},
  urldate = {2024-10-26},
  abstract = {Large language models (LLMs) are being increasingly incorporated into scientific workflows. However, we have yet to fully grasp the implications of this integration. How should the advent of large language models affect the practice of science? For this opinion piece, we have invited four diverse groups of scientists to reflect on this query, sharing their perspectives and engaging in debate. Schulz et al. make the argument that working with LLMs is not fundamentally different from working with human collaborators, while Bender et al. argue that LLMs are often misused and over-hyped, and that their limitations warrant a focus on more specialized, easily interpretable tools. Marelli et al. emphasize the importance of transparent attribution and responsible use of LLMs. Finally, Botvinick and Gershman advocate that humans should retain responsibility for determining the scientific roadmap. To facilitate the discussion, the four perspectives are complemented with a response from each group. By putting these different perspectives in conversation, we aim to bring attention to important considerations within the academic community regarding the adoption of LLMs and their impact on both current and future scientific practices.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computers and Society,Computer Science - Digital Libraries},
  file = {/home/ral/Zotero/storage/8XXAIC2K/Binz et al. - 2023 - How should the advent of large language models affect the practice of science.pdf;/home/ral/Zotero/storage/GG6XIJV8/2312.html}
}

@online{biswas23,
  type = {SSRN Scholarly Paper},
  title = {Role of {{Chat GPT}} in {{Education}}},
  author = {Biswas, Som},
  date = {2023-02-25},
  number = {4369981},
  location = {Rochester, NY},
  url = {https://papers.ssrn.com/abstract=4369981},
  urldate = {2023-09-26},
  abstract = {ChatGPT, a powerful language model from OpenAI, reached 1 million users in just 5 days. Other popular platforms like Facebook, Netflix, Instagram, and Twitter took much longer to reach this number, with 300, 1200, 75, and 720 days respectively. With its ability to generate writing that closely mimics human language and its capacity for multiple ongoing conversations, ChatGPT is a versatile tool that can aid in open education by providing personalized support, direction, and feedback to autodidactic learners, thus increasing motivation and engagement. The author acknowledges asking chatGPT questions regarding its uses for education. Some of the uses that it states are possible now and some are potentials for the future. The author has analyzed and edited the replies of chat GPT.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {autodidactic,Chat GPT,GPT-3,NLP,open education,OpenAI}
}

@article{biswas23a,
  title = {{{ChatGPT}} and the {{Future}} of {{Medical Writing}}},
  author = {Biswas, Som},
  date = {2023-04-01},
  journaltitle = {Radiology},
  shortjournal = {Radiology},
  volume = {307},
  number = {2},
  pages = {e223312},
  issn = {0033-8419, 1527-1315},
  doi = {10.1148/radiol.223312},
  url = {http://pubs.rsna.org/doi/10.1148/radiol.223312},
  urldate = {2023-09-27},
  langid = {english},
  annotation = {349 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/P39SQA5X/Biswas - 2023 - ChatGPT and the Future of Medical Writing.pdf}
}

@inproceedings{blackwell02,
  title = {What Is Programming?},
  booktitle = {{{PPIG}}},
  author = {Blackwell, Alan F.},
  date = {2002},
  pages = {20},
  publisher = {Citeseer},
  url = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=fffaed8f98da11d4c6fb3d692dc0ffd41736f209},
  urldate = {2023-12-08},
  file = {/home/ral/Zotero/storage/C7QDRXE4/Blackwell - 2002 - What is programming.pdf}
}

@article{blais_dobrzynska98,
  title = {Turnout in Electoral Democracies},
  author = {Blais, André and Dobrzynska, Agnieszka},
  date = {1998-03-01},
  journaltitle = {European Journal of Political Research},
  shortjournal = {European Journal of Political Research},
  volume = {33},
  number = {2},
  pages = {239--262},
  issn = {1475-6765},
  doi = {10.1023/A:1006802916256},
  url = {https://doi.org/10.1023/A:1006802916256},
  urldate = {2023-12-26},
  abstract = {We examine turnout in 324 democratic national lower house elections held in 91 countries, between 1972 and 1995. We rely on Freedom House ratings of political rights to determine whether an election is democratic or not. We distinguish three blocs of factors that affect turnout: the socio-economic environment, institutions, and party systems. We show that turnout is influenced by a great number of factors and that the patterns that have been shown to prevail in studies dealing with more limited samples of countries generally hold when we look at a larger set of democracies. But we also show that the socio-economic environment, which has been downplayed in previous studies, has a substantial impact on turnout.},
  langid = {english},
  annotation = {3 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/XUM5SU8D/Blais_Dobrzynska_1998_Turnout in electoral democracies.pdf}
}

@article{boix99,
  title = {Setting the {{Rules}} of the {{Game}}: {{The Choice}} of {{Electoral Systems}} in {{Advanced Democracies}}},
  shorttitle = {Setting the {{Rules}} of the {{Game}}},
  author = {Boix, Carles},
  date = {1999-09},
  journaltitle = {American Political Science Review},
  volume = {93},
  number = {3},
  pages = {609--624},
  issn = {0003-0554, 1537-5943},
  doi = {10.2307/2585577},
  url = {https://www.cambridge.org/core/journals/american-political-science-review/article/setting-the-rules-of-the-game-the-choice-of-electoral-systems-in-advanced-democracies/837FE064C59D68FCF673EF1FECFC8014},
  urldate = {2024-09-12},
  abstract = {Looking at the history of democracies in the developed world, I show that electoral systems derive from the decisions the ruling parties make to maximize their representation according to the following conditions. As long as the electoral arena does not change and the current electoral regime benefits the ruling parties, the electoral system is not altered. As the electoral arena changes (due to the entry of new voters or a change in voters' preferences), the ruling parties modify the electoral system, depending on the emergence of new parties and the coordinating capacities of the old parties. When the new parties are strong, the old parties shift from plurality/majority to proportional representation if no old party enjoys a dominant position, but they do not do this if there is a dominant old party. When new entrants are weak, a system of nonproportional representation is maintained, regardless of the structure of the old party system.},
  langid = {english},
  file = {/home/ral/Zotero/storage/EU25KY2J/Boix - 1999 - Setting the Rules of the Game The Choice of Electoral Systems in Advanced Democracies.pdf}
}

@online{bommasani_etal22,
  title = {On the {{Opportunities}} and {{Risks}} of {{Foundation Models}}},
  author = {Bommasani, Rishi and Hudson, Drew A. and Adeli, Ehsan and Altman, Russ and Arora, Simran and family=Arx, given=Sydney, prefix=von, useprefix=true and Bernstein, Michael S. and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and Brynjolfsson, Erik and Buch, Shyamal and Card, Dallas and Castellon, Rodrigo and Chatterji, Niladri and Chen, Annie and Creel, Kathleen and Davis, Jared Quincy and Demszky, Dora and Donahue, Chris and Doumbouya, Moussa and Durmus, Esin and Ermon, Stefano and Etchemendy, John and Ethayarajh, Kawin and Fei-Fei, Li and Finn, Chelsea and Gale, Trevor and Gillespie, Lauren and Goel, Karan and Goodman, Noah and Grossman, Shelby and Guha, Neel and Hashimoto, Tatsunori and Henderson, Peter and Hewitt, John and Ho, Daniel E. and Hong, Jenny and Hsu, Kyle and Huang, Jing and Icard, Thomas and Jain, Saahil and Jurafsky, Dan and Kalluri, Pratyusha and Karamcheti, Siddharth and Keeling, Geoff and Khani, Fereshte and Khattab, Omar and Koh, Pang Wei and Krass, Mark and Krishna, Ranjay and Kuditipudi, Rohith and Kumar, Ananya and Ladhak, Faisal and Lee, Mina and Lee, Tony and Leskovec, Jure and Levent, Isabelle and Li, Xiang Lisa and Li, Xuechen and Ma, Tengyu and Malik, Ali and Manning, Christopher D. and Mirchandani, Suvir and Mitchell, Eric and Munyikwa, Zanele and Nair, Suraj and Narayan, Avanika and Narayanan, Deepak and Newman, Ben and Nie, Allen and Niebles, Juan Carlos and Nilforoshan, Hamed and Nyarko, Julian and Ogut, Giray and Orr, Laurel and Papadimitriou, Isabel and Park, Joon Sung and Piech, Chris and Portelance, Eva and Potts, Christopher and Raghunathan, Aditi and Reich, Rob and Ren, Hongyu and Rong, Frieda and Roohani, Yusuf and Ruiz, Camilo and Ryan, Jack and Ré, Christopher and Sadigh, Dorsa and Sagawa, Shiori and Santhanam, Keshav and Shih, Andy and Srinivasan, Krishnan and Tamkin, Alex and Taori, Rohan and Thomas, Armin W. and Tramèr, Florian and Wang, Rose E. and Wang, William and Wu, Bohan and Wu, Jiajun and Wu, Yuhuai and Xie, Sang Michael and Yasunaga, Michihiro and You, Jiaxuan and Zaharia, Matei and Zhang, Michael and Zhang, Tianyi and Zhang, Xikun and Zhang, Yuhui and Zheng, Lucia and Zhou, Kaitlyn and Liang, Percy},
  date = {2022-07-12},
  eprint = {2108.07258},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2108.07258},
  url = {http://arxiv.org/abs/2108.07258},
  urldate = {2024-09-12},
  abstract = {AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Computer Science - Machine Learning},
  file = {/home/ral/Zotero/storage/3ZP6J8SN/Bommasani et al. - 2022 - On the Opportunities and Risks of Foundation Models.pdf;/home/ral/Zotero/storage/AFKKUUTH/2108.html}
}

@book{booth_etal16a,
  title = {The Craft of Research},
  author = {Booth, Wayne C. and Colomb, Gregory G. and Williams, Joseph M. and Bizup, Joseph and FitzGerald, William T.},
  date = {2016},
  series = {Chicago Guides to Writing, Editing, and Publishing},
  edition = {Fourth edition},
  publisher = {The University of Chicago Press},
  location = {Chicago},
  isbn = {978-0-226-23956-9 978-0-226-23973-6},
  pagetotal = {316},
  keywords = {Methodology,notion,Research,Technical writing}
}

@online{borchers_etal22,
  title = {Looking for a {{Handsome Carpenter}}! {{Debiasing GPT-3 Job Advertisements}}},
  author = {Borchers, Conrad and Gala, Dalia Sara and Gilburt, Benjamin and Oravkin, Eduard and Bounsi, Wilfried and Asano, Yuki M. and Kirk, Hannah Rose},
  date = {2022-05-23},
  eprint = {2205.11374},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2205.11374},
  urldate = {2023-11-24},
  abstract = {The growing capability and availability of generative language models has enabled a wide range of new downstream tasks. Academic research has identified, quantified and mitigated biases present in language models but is rarely tailored to downstream tasks where wider impact on individuals and society can be felt. In this work, we leverage one popular generative language model, GPT-3, with the goal of writing unbiased and realistic job advertisements. We first assess the bias and realism of zero-shot generated advertisements and compare them to real-world advertisements. We then evaluate prompt-engineering and fine-tuning as debiasing methods. We find that prompt-engineering with diversity-encouraging prompts gives no significant improvement to bias, nor realism. Conversely, fine-tuning, especially on unbiased real advertisements, can improve realism and reduce bias.},
  pubstate = {prepublished},
  file = {/home/ral/Zotero/storage/B9BBPCEQ/Borchers et al_2022_Looking for a Handsome Carpenter.pdf;/home/ral/Zotero/storage/RBNZAC2Y/2205.html}
}

@thesis{botnarenco23,
  type = {B.S. thesis},
  title = {Automating {{Scientific Paper Screening}} with {{ChatGPT}}: {{An Evaluation}} of {{Efficiency}} and {{Accuracy}}},
  shorttitle = {Automating {{Scientific Paper Screening}} with {{ChatGPT}}},
  author = {Botnarenco, Daniel},
  date = {2023},
  institution = {University of Twente},
  url = {http://essay.utwente.nl/95944/},
  urldate = {2023-09-27},
  file = {/home/ral/Zotero/storage/YRWDHQG9/Botnarenco - 2023 - Automating Scientific Paper Screening with ChatGPT An Evaluation of Efficiency and Accuracy.pdf}
}

@online{bowman23,
  title = {Eight {{Things}} to {{Know}} about {{Large Language Models}}},
  author = {Bowman, Samuel R.},
  date = {2023-04-02},
  eprint = {2304.00612},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2304.00612},
  url = {http://arxiv.org/abs/2304.00612},
  urldate = {2024-01-08},
  abstract = {The widespread public deployment of large language models (LLMs) in recent months has prompted a wave of new attention and engagement from advocates, policymakers, and scholars from many fields. This attention is a timely response to the many urgent questions that this technology raises, but it can sometimes miss important considerations. This paper surveys the evidence for eight potentially surprising such points: 1. LLMs predictably get more capable with increasing investment, even without targeted innovation. 2. Many important LLM behaviors emerge unpredictably as a byproduct of increasing investment. 3. LLMs often appear to learn and use representations of the outside world. 4. There are no reliable techniques for steering the behavior of LLMs. 5. Experts are not yet able to interpret the inner workings of LLMs. 6. Human performance on a task isn't an upper bound on LLM performance. 7. LLMs need not express the values of their creators nor the values encoded in web text. 8. Brief interactions with LLMs are often misleading.},
  pubstate = {prepublished},
  file = {/home/ral/Zotero/storage/7GNA72Z5/Bowman_2023_Eight Things to Know about Large Language Models.pdf;/home/ral/Zotero/storage/EA6ALRXK/2304.html}
}

@book{bradburn_etal04,
  title = {Asking Questions: The Definitive Guide to Questionnaire Design - for Market Research, Political Polls, and Social and Health Questionnaires},
  shorttitle = {Asking Questions},
  author = {Bradburn, Norman M. and Sudman, Seymour and Wansink, Brian},
  date = {2004},
  edition = {Rev. ed},
  publisher = {Jossey-Bass},
  location = {San Francisco, Calif},
  isbn = {978-0-7879-7088-8},
  langid = {english},
  pagetotal = {426},
  file = {/home/ral/Zotero/storage/3IZ7JYQ8/N M Bradburn Et Al Asking Questions The De - Unknown.pdf}
}

@book{brady_collier10,
  title = {Rethinking {{Social Inquiry}}. {{Diverse Tools}}, {{Shared Standards}}},
  editor = {Brady, Henry E. and Collier, David},
  date = {2010},
  edition = {2},
  publisher = {Rowman \& Littlefield Publishers},
  location = {Maryland},
  file = {/home/ral/Zotero/storage/EVDBRYUT/Brady and Collier - 2010 - Rethinking Social Inquiry. Diverse Tools, Shared Standards.pdf}
}

@incollection{brighton_gigerenzer12,
  title = {How {{Heuristics Handle Uncertainty}}},
  booktitle = {Ecological {{Rationality}}: {{Intelligence}} in the {{World}}},
  author = {Brighton, Henry and Gigerenzer, Gerd},
  editor = {Todd, Peter M. and Gigerenzer, Gerd},
  date = {2012-03-19},
  pages = {0},
  publisher = {Oxford University Press},
  doi = {10.1093/acprof:oso/9780195315448.003.0014},
  url = {https://doi.org/10.1093/acprof:oso/9780195315448.003.0014},
  urldate = {2023-10-26},
  abstract = {Traditionally, it is assumed that a trade-off exists between effort and accuracy: The more effort we put in, the more accurate our inferences. This chapter shows how this trade-off does not hold in general, or even typically, by explaining how simple heuristics that ignore information can outperform more sophisticated inference strategies. Explanations of such “less-is-more” effects are given using statistical learning theory applied to situations where organisms face what is referred to as the bias–variance dilemma. Under conditions of uncertainty, it is argued, heuristics can both be more accurate and consume fewer resources than typical “rational” models of cognitive processing.},
  isbn = {978-0-19-531544-8},
  file = {/home/ral/Zotero/storage/4I4VAAAT/Brighton et Gigerenzer - 2012 - How Heuristics Handle Uncertainty.pdf;/home/ral/Zotero/storage/PPFPH2TT/148518167.html}
}

@online{brown_etal20,
  title = {Language {{Models}} Are {{Few-Shot Learners}}},
  author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  date = {2020-07-22},
  eprint = {2005.14165},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2005.14165},
  url = {http://arxiv.org/abs/2005.14165},
  urldate = {2024-01-24},
  abstract = {Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  annotation = {73 citations (INSPIRE-HEP/arXiv) [2024-10-14]\\
73 citations (INSPIRE-HEP/arXiv) [2024-10-14]},
  file = {/home/ral/Zotero/storage/XXM5LT8T/Brown et al_2020_Language Models are Few-Shot Learners.pdf;/home/ral/Zotero/storage/CH7463ES/2005.html}
}

@online{brown21,
  title = {Machine Learning, Explained},
  author = {Brown, Sara},
  date = {2021},
  url = {https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained},
  urldate = {2024-10-26},
  langid = {english},
  organization = {MIT Sloan},
  file = {/home/ral/Zotero/storage/9M6N5XP7/machine-learning-explained.html}
}

@online{brynjolfsson_etal19,
  title = {How {{Will Machine Learning Transform}} the {{Labor Market}}?},
  author = {Brynjolfsson, Erik and Rock, Daniel and Tambe, Prasanna},
  date = {2019},
  url = {https://www.hoover.org/research/how-will-machine-learning-transform-labor-market},
  urldate = {2023-10-03},
  abstract = {The twenty-first century will be the century of intelligent machines. Artificial intelligence (AI) has begun to transform the economy as it as enables machines to do more and more of the cognitive tasks that were once done only by humans. In the coming decade, many existing tasks will be replaced by machines, while new ones will emerge. Almost every job will be affected in some way and most will need to be redesigned. Businesses will rise and fall depending on how well they understand, foster and harness the changing skills that are needed to be productive. Economies will thrive if they can create and update the institutions needed to create these skills.},
  langid = {english}
}

@article{brynjolfsson_mitchell17,
  title = {What Can Machine Learning Do? {{Workforce}} Implications},
  shorttitle = {What Can Machine Learning Do?},
  author = {Brynjolfsson, Erik and Mitchell, Tom},
  date = {2017-12-22},
  journaltitle = {Science},
  shortjournal = {Science},
  volume = {358},
  number = {6370},
  pages = {1530--1534},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aap8062},
  url = {https://www.science.org/doi/10.1126/science.aap8062},
  urldate = {2023-10-03},
  abstract = {Profound change is coming, but roles for humans remain , Digital computers have transformed work in almost every sector of the economy over the past several decades ( 1 ). We are now at the beginning of an even larger and more rapid transformation due to recent advances in machine learning (ML), which is capable of accelerating the pace of automation itself. However, although it is clear that ML is a “general purpose technology,” like the steam engine and electricity, which spawns a plethora of additional innovations and capabilities ( 2 ), there is no widely shared agreement on the tasks where ML systems excel, and thus little agreement on the specific expected impacts on the workforce and on the economy more broadly. We discuss what we see to be key implications for the workforce, drawing on our rubric of what the current generation of ML systems can and cannot do [see the supplementary materials (SM)]. Although parts of many jobs may be “suitable for ML” (SML), other tasks within these same jobs do not fit the criteria for ML well; hence, effects on employment are more complex than the simple replacement and substitution story emphasized by some. Although economic effects of ML are relatively limited today, and we are not facing the imminent “end of work” as is sometimes proclaimed, the implications for the economy and the workforce going forward are profound.},
  langid = {english},
  annotation = {503 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/CZ6DV8IY/Brynjolfsson and Mitchell - 2017 - What can machine learning do Workforce implications.pdf}
}

@book{chalmers99,
  title = {What Is This Thing Called Science?},
  author = {Chalmers, A. F.},
  date = {1999},
  edition = {3rd ed},
  publisher = {Hackett Pub},
  location = {Indianapolis},
  isbn = {978-0-87220-452-2 978-0-87220-453-9},
  langid = {english},
  pagetotal = {266},
  keywords = {notion,Philosophy,Science}
}

@online{chan_etal23,
  title = {Hazards from {{Increasingly Accessible Fine-Tuning}} of {{Downloadable Foundation Models}}},
  author = {Chan, Alan and Bucknall, Ben and Bradley, Herbie and Krueger, David},
  date = {2023-12-22},
  eprint = {2312.14751},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2312.14751},
  url = {http://arxiv.org/abs/2312.14751},
  urldate = {2024-10-26},
  abstract = {Public release of the weights of pretrained foundation models, otherwise known as downloadable access \textbackslash citep\{solaiman\_gradient\_2023\}, enables fine-tuning without the prohibitive expense of pretraining. Our work argues that increasingly accessible fine-tuning of downloadable models may increase hazards. First, we highlight research to improve the accessibility of fine-tuning. We split our discussion into research that A) reduces the computational cost of fine-tuning and B) improves the ability to share that cost across more actors. Second, we argue that increasingly accessible fine-tuning methods may increase hazard through facilitating malicious use and making oversight of models with potentially dangerous capabilities more difficult. Third, we discuss potential mitigatory measures, as well as benefits of more accessible fine-tuning. Given substantial remaining uncertainty about hazards, we conclude by emphasizing the urgent need for the development of mitigations.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning},
  file = {/home/ral/Zotero/storage/MZR6NIGQ/Chan et al. - 2023 - Hazards from Increasingly Accessible Fine-Tuning of Downloadable Foundation Models.pdf;/home/ral/Zotero/storage/TIUGPY7M/2312.html}
}

@article{chen23,
  title = {{{ChatGPT}} and Other Artificial Intelligence Applications Speed up Scientific Writing},
  author = {Chen, Tzeng-Ji},
  date = {2023},
  journaltitle = {Journal of the Chinese Medical Association},
  volume = {86},
  number = {4},
  pages = {351--353},
  publisher = {LWW},
  url = {https://journals.lww.com/jcma/_layouts/15/oaks.journals/downloadpdf.aspx?an=02118582-202304000-00001},
  urldate = {2023-09-27}
}

@article{christen_etal24,
  title = {A {{Review}} of the {{F-Measure}}: {{Its History}}, {{Properties}}, {{Criticism}}, and {{Alternatives}}},
  shorttitle = {A {{Review}} of the {{F-Measure}}},
  author = {Christen, Peter and Hand, David J. and Kirielle, Nishadi},
  date = {2024-03-31},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  volume = {56},
  number = {3},
  pages = {1--24},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3606367},
  url = {https://dl.acm.org/doi/10.1145/3606367},
  urldate = {2024-06-06},
  abstract = {Methods to classify objects into two or more classes are at the core of various disciplines. When a set of objects with their true classes is available, a supervised classifier can be trained and employed to decide if, for example, a new patient has cancer or not. The choice of performance measure is critical in deciding which supervised method to use in any particular classification problem. Different measures can lead to very different choices, so the measure should match the objectives. Many performance measures have been developed, and one of them is the F-measure, the harmonic mean of precision and recall. Originally proposed in information retrieval, the F-measure has gained increasing interest in the context of classification. However, the rationale underlying this measure appears weak, and unlike other measures, it does not have a representational meaning. The use of the harmonic mean also has little theoretical justification. The F-measure also stresses one class, which seems inappropriate for general classification problems. We provide a history of the F-measure and its use in computational disciplines, describe its properties, and discuss criticism about the F-Measure. We conclude with alternatives to the F-measure, and recommendations of how to use it effectively.},
  langid = {english},
  annotation = {20 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/A4LUGJF9/Christen et al. - 2024 - A Review of the F-Measure Its History, Properties.pdf}
}

@article{chung_etal22,
  title = {Text-Mining Open-Ended Survey Responses Using Structural Topic Modeling: A Practical Demonstration to Understand Parents’ Coping Methods during the {{COVID-19}} Pandemic in Singapore},
  author = {Chung, Gerard and Chung, Gerard and Rodriguez, Maria Y. and Rodriguez, Maria Y. and Lanier, Paul and Lanier, Paul and Gibbs, Daniel and Gibbs, Daniel},
  date = {2022},
  journaltitle = {Journal of Technology in Human Services},
  eprint = {null},
  eprinttype = {pmid},
  doi = {10.1080/15228835.2022.2036301},
  abstract = {Open-ended survey questions crucially contribute to researchers’ understandings of respondents’ experiences. However, analyzing open-ended responses using human coders is labor-intensive. Structural topic modeling (STM) is a text mining method that discover topics from textual data. We demonstrate the use of STM to analyze open-ended survey responses to understand how parents coped during the COVID-19 lock-down in Singapore. We administered online surveys to 199 parents in Singapore during the COVID-19 lock-down. To show a STM analysis, we demonstrated a workflow that includes steps in data preprocessing, model estimation, model selection, and model interpretation. An 18-topic model best fit the data based on model diagnostics and researchers’ expertise. Prevalent coping methods described by respondents include “Spousal Support,” “Routines/Schedules,” and “Managing Expectations.” Topic prevalence for some topics varied with respondents’ levels of parenting stress and whether parents were fathers or mothers. STM offers an efficient, valid, and replicable way to analyze textual data such as open-ended survey responses and case notes that can complement researchers’ knowledge and skills. STM can be used as part of a multistage research process or to support other analyses such as clarifying quantitative findings and identifying preliminary themes from qualitative data.Supplemental data for this article is available online at https://doi.org/10.1080/15228835.2022.2036301 .},
  mag_id = {4213091819},
  pmcid = {null},
  annotation = {7 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/98BUVFV5/Chung et al_2022_Text-mining open-ended survey responses using structural topic modeling.pdf}
}

@article{clark_etal20,
  title = {A Full Systematic Review Was Completed in 2 Weeks Using Automation Tools: A Case Study},
  shorttitle = {A Full Systematic Review Was Completed in 2 Weeks Using Automation Tools},
  author = {Clark, Justin and Glasziou, Paul and Del Mar, Chris and Bannach-Brown, Alexandra and Stehlik, Paulina and Scott, Anna Mae},
  date = {2020-05-01},
  journaltitle = {Journal of Clinical Epidemiology},
  shortjournal = {Journal of Clinical Epidemiology},
  volume = {121},
  pages = {81--90},
  issn = {0895-4356},
  doi = {10.1016/j.jclinepi.2020.01.008},
  url = {https://www.sciencedirect.com/science/article/pii/S089543561930719X},
  urldate = {2023-09-26},
  abstract = {Background and Objectives Systematic reviews (SRs) are time and resource intensive, requiring approximately 1 year from protocol registration to submission for publication. Our aim was to describe the process, facilitators, and barriers to completing the first 2-week full SR. Study Design and Setting We systematically reviewed evidence of the impact of increased fluid intake, on urinary tract infection (UTI) recurrence, in individuals at risk for UTIs. The review was conducted by experienced systematic reviewers with complementary skills (two researcher clinicians, an information specialist, and an epidemiologist), using Systematic Review Automation tools, and blocked off time for the duration of the project. The outcomes were time to complete the SR, time to complete individual SR tasks, facilitators and barriers to progress, and peer reviewer feedback on the SR manuscript. Times to completion were analyzed quantitatively (minutes and calendar days); facilitators and barriers were mapped onto the Theoretical Domains Framework; and peer reviewer feedback was analyzed quantitatively and narratively. Results The SR was completed in 61 person-hours (9 workdays; 12 calendar days); accepted version of the manuscript required 71 person-hours. Individual SR tasks ranged from 16 person-minutes (deduplication of search results) to 461 person-minutes (data extraction). The least time-consuming SR tasks were obtaining full-texts, searches, citation analysis, data synthesis, and deduplication. The most time-consuming tasks were data extraction, write-up, abstract screening, full-text screening, and risk of bias. Facilitators and barriers mapped onto the following domains: knowledge; skills; memory, attention, and decision process; environmental context and resources; and technology and infrastructure. Two sets of peer reviewer feedback were received on the manuscript: the first included 34 comments requesting changes, 17 changes were made, requiring 173 person-minutes; the second requested 13 changes, and eight were made, requiring 121 person-minutes. Conclusion A small and experienced systematic reviewer team using Systematic Review Automation tools who have protected time to focus solely on the SR can complete a moderately sized SR in 2 weeks.},
  keywords = {2 week systematic review,2wSR,Automation,Barriers,Facilitators,Methods improvement,Systematic review accelerator,Systematic reviews},
  annotation = {281 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/XGSAGBGF/Clark et al. - 2020 - A full systematic review was completed in 2 weeks using automation tools a case study.pdf}
}

@unpublished{cloutier23,
  title = {Systématiser une revue de littérature},
  author = {Cloutier, Adrien},
  date = {2023},
  eventtitle = {École interdisciplinaire d'objets et méthodes},
  langid = {french},
  venue = {Université Laval, Québec}
}

@article{cohen_etal20,
  title = {A Constructive Role for Social Science in the Development of Automated Vehicles},
  author = {Cohen, Tom and Stilgoe, Jack and Stares, Sally and Akyelken, Nihan and Cavoli, Clemence and Day, Jennie and Dickinson, Janet and Fors, Vaike and Hopkins, Debbie and Lyons, Glenn},
  date = {2020},
  journaltitle = {Transportation Research Interdisciplinary Perspectives},
  volume = {6},
  pages = {100133},
  publisher = {Elsevier},
  url = {https://www.sciencedirect.com/science/article/pii/S2590198220300440},
  urldate = {2023-09-27},
  file = {/home/ral/Zotero/storage/6HABGU9B/Cohen et al. - 2020 - A constructive role for social science in the development of automated vehicles.pdf}
}

@article{cohn10,
  title = {Advances in Behavioral Science Using Automated Facial Image Analysis and Synthesis [Social Sciences]},
  author = {Cohn, Jeffrey F.},
  date = {2010},
  journaltitle = {IEEE Signal processing magazine},
  volume = {27},
  number = {6},
  pages = {128--133},
  publisher = {IEEE},
  url = {https://ieeexplore.ieee.org/abstract/document/5563099/?casa_token=20AAquYQ5nYAAAAA:cqWFo_GiFl2niimuCWJBbwblG7V8sXsTlyE0B-mh2elUjlzeXYYerxuIvoBE3rEBLcOc3CYpBw},
  urldate = {2023-09-27}
}

@article{collier_levitsky97,
  title = {Democracy with {{Adjectives}}: {{Conceptual Innovation}} in {{Comparative Research}}},
  shorttitle = {Democracy with {{Adjectives}}},
  author = {Collier, David and Levitsky, Steven},
  date = {1997-04},
  journaltitle = {World Politics},
  shortjournal = {World Pol.},
  volume = {49},
  number = {3},
  pages = {430--451},
  issn = {0043-8871, 1086-3338},
  doi = {10.1353/wp.1997.0009},
  url = {https://muse.jhu.edu/article/36375},
  urldate = {2023-01-27},
  abstract = {The recent trend toward democratization in countries across the globe has challenged scholars to pursue two potentially contradictory goals. On the one hand, they seek to increase analytic differentiation in order to capture the diverse forms of democracy that have emerged. On the other hand, they are concerned with conceptual validity. Specifically, they seek to avoid the problem of conceptual stretching that arises when the concept of democracy is applied to cases for which, by relevant scholarly standards, it is not appropriate. This article argues that the pursuit of these two goals has led to a proliferation of conceptual innovations, including numerous subtypes of democracy—that is to say, democracy “with adjectives.” The article explores the strengths and weaknesses of alternative strategies of conceptual innovation that have emerged: descending and climbing Sartori's ladder of generality, generating “diminished” subtypes of democracy, “precising” the definition of democracy by adding defining attributes, and shifting the overarching concept with which democracy is associated. The goal of the analysis is to make more comprehensible the complex structure of these strategies, as well as to explore trade-offs among the strategies. Even when scholars proceed intuitively, rather than self-consciously, they tend to operate within this structure. Yet it is far more desirable for them to do so selfconsciously, with a full awareness of these trade-offs.},
  langid = {english},
  keywords = {notion},
  file = {/home/ral/Zotero/storage/9XR55PHF/Collier and Levitsky - 1997 - Democracy with Adjectives Conceptual Innovation in Comparative Research.pdf}
}

@online{cory-wright_etal23,
  title = {{{AI Hilbert}}: {{A New Paradigm}} for {{Scientific Discovery}} by {{Unifying Data}} and {{Background Knowledge}}},
  shorttitle = {{{AI Hilbert}}},
  author = {Cory-Wright, Ryan and Khadir, Bachir El and Cornelio, Cristina and Dash, Sanjeeb and Horesh, Lior},
  date = {2023-09-23},
  eprint = {2308.09474},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2308.09474},
  urldate = {2023-09-27},
  abstract = {The discovery of scientific formulae that parsimoniously explain natural phenomena and align with existing background theory is a key goal in science. Historically, scientists have derived natural laws by manipulating equations based on existing knowledge, forming new equations, and verifying them experimentally. In recent years, data-driven scientific discovery has emerged as a viable competitor in settings with large amounts of experimental data. Unfortunately, data-driven methods often fail to discover valid laws when data is noisy or scarce. Accordingly, recent works combine regression and reasoning to eliminate formulae inconsistent with background theory. However, the problem of searching over the space of formulae consistent with background theory to find one that fits the data best is not well-solved. We propose a solution to this problem when all axioms and scientific laws are expressible via polynomial equalities and inequalities and argue that our approach is widely applicable. We further model notions of minimal complexity using binary variables and logical constraints, solve polynomial optimization problems via mixed-integer linear or semidefinite optimization, and prove the validity of our scientific discoveries in a principled manner using Positivestellensatz certificates. Remarkably, the optimization techniques leveraged in this paper allow our approach to run in polynomial time with fully correct background theory, or non-deterministic polynomial (NP) time with partially correct background theory. We demonstrate that some famous scientific laws, including Kepler's Third Law of Planetary Motion, the Hagen-Poiseuille Equation, and the Radiated Gravitational Wave Power equation, can be derived in a principled manner from background axioms and experimental data.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Symbolic Computation,Mathematics - Optimization and Control},
  file = {/home/ral/Zotero/storage/YJAS8XQ5/Cory-Wright et al. - 2023 - AI Hilbert A New Paradigm for Scientific Discovery by Unifying Data and Background Knowledge.pdf}
}

@article{costello_thomson08,
  title = {Election {{Pledges}} and {{Their Enactment}} in {{Coalition Governments}}: {{A Comparative Analysis}} of {{Ireland}}},
  shorttitle = {Election {{Pledges}} and {{Their Enactment}} in {{Coalition Governments}}},
  author = {Costello, Rory and Thomson, R.},
  date = {2008-08-01},
  journaltitle = {Journal of Elections, Public Opinion \& Parties},
  shortjournal = {Journal of Elections, Public Opinion \& Parties},
  volume = {18},
  doi = {10.1080/17457280802227652},
  abstract = {This paper examines election pledges and their enactment in a country where coalition governments are common: Ireland. The evidence is compared to other studies, including coalition governments in the Netherlands. Much previous research focussed on countries where single-party governments are the norm (the United Kingdom, Canada and Greece), and the presidential system of the United States with separation of powers. We measure election pledges and their enactment in the same way as previous research, which enables valid comparisons to be made. In addition to examining evidence from existing studies, the present paper adds new evidence on election pledges and their enactment in the most recent Irish government: the majority centre-right coalition of Fianna Fáil and the Progressive Democrats, 2002-2007. By addiing this new evidence, we are able to make stronger inferences on the impact of coalition governance on the types of pledges made and rates of pledge enactment. In addition, a comparison of the recent majority coalition of Fianna Fáil and the Progressive Democrats with the minority coalition of Fianna Fáil and the Progressive Democrats, 1997-2002, allows us to examine the impact of majority versus minority status on pledge enactment. We also study the impact of prominent mechanisms of coalition governance -government agreements and ministerial portfolio allocations -on the likelihood of pledge enactment. As in previous research, we identify election pledges from parties' election programmes or manifestos. In addition, in an effort to move beyond existing research, we also present evidence on the extent to which election pledges are featured in media reports during the election campaign. Paper (PP267) prepared for delivery at the ECPR general conference, Pisa, Italy, 6-8 September, 2007. Open section (PN414), 'Comparative research on election pledges and government actions', Saturday, 8 September, 11.00-12.40.},
  annotation = {69 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/GDCSZNMI/Costello et Thomson - 2008 - Election Pledges and Their Enactment in Coalition .pdf}
}

@article{cox90,
  title = {Centripetal and {{Centrifugal Incentives}} in {{Electoral Systems}}},
  author = {Cox, Gary W.},
  date = {1990},
  journaltitle = {American Journal of Political Science},
  volume = {34},
  number = {4},
  eprint = {2111465},
  eprinttype = {jstor},
  pages = {903--935},
  publisher = {[Midwest Political Science Association, Wiley]},
  issn = {0092-5853},
  doi = {10.2307/2111465},
  url = {https://www.jstor.org/stable/2111465},
  urldate = {2024-01-03},
  abstract = {This paper investigates how electoral laws affect the position-taking incentives of parties and candidates. It seeks to extend the finding presented in the classical "median voter theorem" to a wide class of electoral systems--or to show the limits of such extension. The factors examined are the district magnitude, the electoral formula, the number of votes each voter is allowed to cast, whether voters can cumulate their votes, and whether voters can "partially abstain." I suggest a crude division of electoral systems into those producing predominantly centripetal incentives and those producing predominantly centrifugal incentives. Among the factors found to produce centripetal incentives, at least in noncumulative systems, are the following: increases in the number of votes per voter; outlawry of "partial abstention"; and decreases in the district magnitude. In systems allowing the cumulation of votes, matters are a bit different.},
  annotation = {804 citations (Semantic Scholar/DOI) [2024-10-14]\\
408 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/Z4NCDZX2/Cox - 1990 - Centripetal and Centrifugal Incentives in Electora.pdf}
}

@book{cox97,
  title = {Making Votes Count: Strategic Coordination in the World's Electoral Systems},
  shorttitle = {Making Votes Count},
  author = {Cox, Gary W.},
  date = {1997},
  series = {Political Economy of Institutions and Decisions},
  publisher = {Cambridge University Press},
  location = {Cambridge, U.K. ; New York},
  isbn = {978-0-521-58516-3 978-0-521-58527-9},
  pagetotal = {340},
  keywords = {Comparative government,Elections,Voting},
  file = {/home/ral/Zotero/storage/8BLF9YMU/Gary W. Cox - Making Votes Count_ Strategic Coordination in the World's Electoral Systems-Cambridge University Press (1998).pdf}
}

@article{crosas_etal15,
  title = {Automating {{Open Science}} for {{Big Data}}},
  author = {Crosas, Mercè and King, Gary and Honaker, James and Sweeney, Latanya},
  date = {2015-05},
  journaltitle = {The ANNALS of the American Academy of Political and Social Science},
  shortjournal = {The ANNALS of the American Academy of Political and Social Science},
  volume = {659},
  number = {1},
  pages = {260--273},
  issn = {0002-7162, 1552-3349},
  doi = {10.1177/0002716215570847},
  url = {http://journals.sagepub.com/doi/10.1177/0002716215570847},
  urldate = {2023-09-27},
  abstract = {The vast majority of social science research uses small (megabyte- or gigabyte-scale) datasets. These fixed-scale datasets are commonly downloaded to the researcher’s computer where the analysis is performed. The data can be shared, archived, and cited with well-established technologies, such as the Dataverse Project, to support the published results. The trend toward big data—including large-scale streaming data—is starting to transform research and has the potential to impact policymaking as well as our understanding of the social, economic, and political problems that affect human societies. However, big data research poses new challenges to the execution of the analysis, archiving and reuse of the data, and reproduction of the results. Downloading these datasets to a researcher’s computer is impractical, leading to analyses taking place in the cloud, and requiring unusual expertise, collaboration, and tool development. The increased amount of information in these large datasets is an advantage, but at the same time it poses an increased risk of revealing personally identifiable sensitive information. In this article, we discuss solutions to these new challenges so that the social sciences can realize the potential of big data.},
  langid = {english},
  annotation = {20 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/7NZN8PJG/Crosas et al. - 2015 - Automating Open Science for Big Data.pdf}
}

@article{curini_hino12,
  title = {Missing {{Links}} in {{Party-System Polarization}}: {{How Institutions}} and {{Voters Matter}}},
  shorttitle = {Missing {{Links}} in {{Party-System Polarization}}},
  author = {Curini, Luigi and Hino, Airo},
  date = {2012-04},
  journaltitle = {The Journal of Politics},
  shortjournal = {The Journal of Politics},
  volume = {74},
  number = {2},
  pages = {460--473},
  issn = {0022-3816, 1468-2508},
  doi = {10.1017/S0022381611001721},
  url = {https://www.journals.uchicago.edu/doi/10.1017/S0022381611001721},
  urldate = {2024-01-03},
  langid = {english},
  annotation = {39 citations (Semantic Scholar/DOI) [2024-10-14]\\
63 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/WH5ICML6/Curini et Hino - 2012 - Missing Links in Party-System Polarization How In.pdf}
}

@book{dahl71,
  title = {Polyarchy: Participation and Opposition},
  shorttitle = {Polyarchy},
  author = {Dahl, Robert A.},
  date = {1971},
  series = {Political Science},
  publisher = {Yale university press},
  location = {New Haven (Conn.)},
  isbn = {978-0-300-01565-2},
  langid = {english},
  file = {/home/ral/Zotero/storage/5T8759BM/Dahl - 1971 - Polyarchy participation and opposition.pdf}
}

@online{dai_etal23,
  title = {{{AugGPT}}: {{Leveraging ChatGPT}} for {{Text Data Augmentation}}},
  shorttitle = {{{AugGPT}}},
  author = {Dai, Haixing and Liu, Zhengliang and Liao, Wenxiong and Huang, Xiaoke and Cao, Yihan and Wu, Zihao and Zhao, Lin and Xu, Shaochen and Liu, Wei and Liu, Ninghao and Li, Sheng and Zhu, Dajiang and Cai, Hongmin and Sun, Lichao and Li, Quanzheng and Shen, Dinggang and Liu, Tianming and Li, Xiang},
  date = {2023-03-20},
  eprint = {2302.13007},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2302.13007},
  urldate = {2023-09-27},
  abstract = {Text data augmentation is an effective strategy for overcoming the challenge of limited sample sizes in many natural language processing (NLP) tasks. This challenge is especially prominent in the few-shot learning scenario, where the data in the target domain is generally much scarcer and of lowered quality. A natural and widely-used strategy to mitigate such challenges is to perform data augmentation to better capture the data invariance and increase the sample size. However, current text data augmentation methods either can't ensure the correct labeling of the generated data (lacking faithfulness) or can't ensure sufficient diversity in the generated data (lacking compactness), or both. Inspired by the recent success of large language models, especially the development of ChatGPT, which demonstrated improved language comprehension abilities, in this work, we propose a text data augmentation approach based on ChatGPT (named AugGPT). AugGPT rephrases each sentence in the training samples into multiple conceptually similar but semantically different samples. The augmented samples can then be used in downstream model training. Experiment results on few-shot learning text classification tasks show the superior performance of the proposed AugGPT approach over state-of-the-art text data augmentation methods in terms of testing accuracy and distribution of the augmented samples.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  annotation = {100 citations (Semantic Scholar/arXiv) [2024-10-14]},
  file = {/home/ral/Zotero/storage/JRVSVJNP/Dai et al. - 2023 - AugGPT Leveraging ChatGPT for Text Data Augmentation.pdf}
}

@article{dale21,
  title = {{{GPT-3}}: {{What}}’s It Good for?},
  shorttitle = {{{GPT-3}}},
  author = {Dale, Robert},
  date = {2021-01},
  journaltitle = {Natural Language Engineering},
  volume = {27},
  number = {1},
  pages = {113--118},
  publisher = {Cambridge University Press},
  issn = {1351-3249, 1469-8110},
  doi = {10.1017/S1351324920000601},
  url = {https://www.cambridge.org/core/journals/natural-language-engineering/article/gpt3-whats-it-good-for/0E05CFE68A7AC8BF794C8ECBE28AA990},
  urldate = {2023-09-27},
  abstract = {GPT-3 made the mainstream media headlines this year, generating far more interest than we’d normally expect of a technical advance in NLP. People are fascinated by its ability to produce apparently novel text that reads as if it was written by a human. But what kind of practical applications can we expect to see, and can they be trusted?},
  langid = {english},
  annotation = {236 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/RWYSCBPW/Dale - 2021 - GPT-3 What’s it good for.pdf}
}

@article{dalton08,
  title = {The {{Quantity}} and the {{Quality}} of {{Party Systems}}},
  author = {Dalton, Russell},
  date = {2008-02-13},
  journaltitle = {Comparative Political Studies - COMP POLIT STUD},
  shortjournal = {Comparative Political Studies - COMP POLIT STUD},
  volume = {41},
  pages = {899--920},
  doi = {10.1177/0010414008315860},
  abstract = {Previous research claims that the number of parties affects the representation of social cleavages in voting behavior, election turnout, patterns of political conflict, and other party system effects. This article argues that research typically counts the quantity of parties and that often the more important property is the quality of party competition—the polarization of political parties within a party system. The author first discusses why polarization is important to study. Second, the author provides a new measurement of party system polarization based on voter perceptions of party positions in the Comparative Study of Electoral Systems, which includes more than 50 separate elections from established and developing democracies. Third, the author compares party polarization and party fractionalization as influences on cleavage-based and ideological voting and as predictors of turnout levels. The finding is that party polarization is empirically more important in explaining these outcomes.},
  annotation = {413 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/C753I357/Dalton - 2008 - The Quantity and the Quality of Party Systems.pdf}
}

@article{daoust_etal22,
  title = {Language {{Matters}}: {{The Study}} of {{Canadian Politics}} through an {{Exploration}} of {{Syllabi}} and {{Comprehensive Exams}}},
  shorttitle = {Language {{Matters}}},
  author = {Daoust, Jean-François and Gagnon, Alain-G. and Galipeau, Thomas},
  date = {2022-12},
  journaltitle = {Canadian Journal of Political Science},
  shortjournal = {Can J Pol Sci},
  volume = {55},
  number = {4},
  pages = {897--915},
  issn = {0008-4239, 1744-9324},
  doi = {10.1017/S0008423922000749},
  url = {https://www.cambridge.org/core/product/identifier/S0008423922000749/type/journal_article},
  urldate = {2024-09-04},
  abstract = {The representation of Canada’s two main linguistic groups in the teaching of Canadian politics is crucial, but we know little about it. In this article, we analyze the systemic underrepresentation of francophone authors in Canadian political science by examining the research that students are exposed to. Based on data from 351 syllabi across 42 Canadian universities, as well as data from the reading list of the doctoral qualifying field exams in Canadian politics, our findings show that francophone authors are systemically underrepresented (when not totally absent). About 38 per cent of Canadian politics courses include no francophone authors in their reading lists. Our findings suggest that Canadian politics is not an inclusive and comprehensive field. This result entails important implications not only for current professors and students but also for the profession more generally, given that the students who will make up tomorrow’s faculties in Canadian universities are shaped by these biases.},
  langid = {english},
  file = {/home/ral/Zotero/storage/JQ734DLL/Daoust et al. - 2022 - Language Matters The Study of Canadian Politics t.pdf}
}

@online{das_etal24,
  title = {Under the {{Surface}}: {{Tracking}} the {{Artifactuality}} of {{LLM-Generated Data}}},
  shorttitle = {Under the {{Surface}}},
  author = {Das, Debarati and Langis, Karin De and Martin-Boyle, Anna and Kim, Jaehyung and Lee, Minhwa and Kim, Zae Myung and Hayati, Shirley Anugrah and Owan, Risako and Hu, Bin and Parkar, Ritik and Koo, Ryan and Park, Jonginn and Tyagi, Aahan and Ferland, Libby and Roy, Sanjali and Liu, Vincent and Kang, Dongyeop},
  date = {2024-01-30},
  eprint = {2401.14698},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2401.14698},
  url = {http://arxiv.org/abs/2401.14698},
  urldate = {2024-10-26},
  abstract = {This work delves into the expanding role of large language models (LLMs) in generating artificial data. LLMs are increasingly employed to create a variety of outputs, including annotations, preferences, instruction prompts, simulated dialogues, and free text. As these forms of LLM-generated data often intersect in their application, they exert mutual influence on each other and raise significant concerns about the quality and diversity of the artificial data incorporated into training cycles, leading to an artificial data ecosystem. To the best of our knowledge, this is the first study to aggregate various types of LLM-generated text data, from more tightly constrained data like "task labels" to more lightly constrained "free-form text". We then stress test the quality and implications of LLM-generated artificial data, comparing it with human data across various existing benchmarks. Despite artificial data's capability to match human performance, this paper reveals significant hidden disparities, especially in complex tasks where LLMs often miss the nuanced understanding of intrinsic human-generated content. This study critically examines diverse LLM-generated data and emphasizes the need for ethical practices in data creation and when using LLMs. It highlights the LLMs' shortcomings in replicating human traits and behaviors, underscoring the importance of addressing biases and artifacts produced in LLM-generated content for future research and development. All data and code are available on our project page.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/ral/Zotero/storage/J6GTRRBW/Das et al. - 2024 - Under the Surface Tracking the Artifactuality of LLM-Generated Data.pdf;/home/ral/Zotero/storage/DIHQAFP6/2401.html}
}

@article{datta23,
  title = {Attempts at Automating Journal Subject Classification},
  author = {Datta, Esha},
  date = {2023},
  journaltitle = {Upstream},
  url = {https://upstream.force11.org/attempts-at-automating-journal-subject-classification/},
  urldate = {2023-09-27}
}

@article{dekker_remic19,
  title = {Two Types of Ecological Rationality: Or How to Best Combine Psychology and Economics},
  shorttitle = {Two Types of Ecological Rationality},
  author = {Dekker, Erwin and Remic, Blaž},
  date = {2019-10-02},
  journaltitle = {Journal of Economic Methodology},
  volume = {26},
  number = {4},
  pages = {291--306},
  publisher = {Routledge},
  issn = {1350-178X},
  doi = {10.1080/1350178X.2018.1560486},
  url = {https://doi.org/10.1080/1350178X.2018.1560486},
  urldate = {2023-10-26},
  abstract = {This paper argues that the notion of ‘ecological rationality’ as used in (behavioral) economics has two rival meanings. The first type of ecological rationality (ER1) as used by Gerd Gigerenzer, refers to the use of cognitive strategies, heuristics in particular, in real-world decisions. The second type of ecological rationality (ER2) as used in the work of Vernon Smith, refers to the rationality of cognitive systems consisting of multiple individuals, institutions, and social norms. We demonstrate in this paper that their use originates in different psychological (or cognitive) approaches: Brunswikian functionalism and distributed cognition respectively. By uncovering the different psychological underpinnings, we are able to analyze the methodological differences between the two types of ecological rationality, the different ways in which central concepts are employed, and the differences in resulting experimental practices. We conclude with the implications for the various ways in which psychology and economics can be combined.},
  annotation = {19 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/PDS3NT6F/Dekker et Remic - 2019 - Two types of ecological rationality or how to bes.pdf}
}

@book{dellaporta_keating08,
  title = {Approaches and Methodologies in the Social Sciences: A Pluralist Perspective},
  shorttitle = {Approaches and Methodologies in the Social Sciences},
  editor = {Della Porta, Donatella and Keating, Michael},
  date = {2008},
  publisher = {Cambridge University Press},
  location = {Cambridge , New York},
  isbn = {978-0-521-88322-1 978-0-521-70966-8},
  pagetotal = {365},
  keywords = {Research Methodology,Social sciences},
  annotation = {OCLC: ocn213400645},
  file = {/home/ral/Zotero/storage/B9ZRGJWI/Approaches and Methodologies in the Social Sciences A Pluralist Perspective.pdf}
}

@article{dellaporta01,
  title = {Social movements and new challenges to représentative democracy. . A perspective from Italy},
  author = {Della Porta, Donatella},
  date = {2001},
  journaltitle = {Politique européenne},
  volume = {4},
  number = {3},
  pages = {73--103},
  publisher = {L'Harmattan},
  issn = {1623-6297},
  doi = {10.3917/poeu.004.0073},
  url = {https://shs.cairn.info/revue-politique-europeenne-2001-3-page-73?lang=fr&tab=texte-integral},
  urldate = {2024-09-12},
  langid = {french},
  file = {/home/ral/Zotero/storage/QZN8DTJK/Della Porta - 2001 - Social movements and new challenges to représentative democracy. . A perspective from Italy.pdf}
}

@article{denney_tewksbury13,
  title = {How to {{Write}} a {{Literature Review}}},
  author = {Denney, Andrew S. and Tewksbury, Richard},
  date = {2013-06},
  journaltitle = {Journal of Criminal Justice Education},
  shortjournal = {Journal of Criminal Justice Education},
  volume = {24},
  number = {2},
  pages = {218--234},
  issn = {1051-1253, 1745-9117},
  doi = {10.1080/10511253.2012.730617},
  url = {http://www.tandfonline.com/doi/abs/10.1080/10511253.2012.730617},
  urldate = {2023-12-08},
  langid = {english},
  annotation = {84 citations (Crossref/DOI) [2024-10-14]}
}

@article{diamond02,
  title = {Elections {{Without Democracy}}: {{Thinking About Hybrid Regimes}}},
  shorttitle = {Elections {{Without Democracy}}},
  author = {Diamond, Larry},
  date = {2002-04},
  journaltitle = {Journal of Democracy},
  shortjournal = {jod},
  volume = {13},
  number = {2},
  pages = {21--35},
  issn = {1086-3214},
  doi = {10.1353/jod.2002.0025},
  url = {https://muse.jhu.edu/article/17195},
  urldate = {2024-09-12},
  langid = {english},
  file = {/home/ral/Zotero/storage/EETWBEXW/Diamond - 2002 - Elections Without Democracy Thinking About Hybrid Regimes.pdf}
}

@book{dillman_etal14,
  title = {Internet, {{Phone}}, {{Mail}}, and {{Mixed}}‐{{Mode Surveys}}: {{The Tailored Design Method}}},
  shorttitle = {Internet, {{Phone}}, {{Mail}}, and {{Mixed}}‐{{Mode Surveys}}},
  author = {Dillman, Don A and Smyth, Jolene D and Christian, Leah Melani},
  date = {2014-08-18},
  edition = {1},
  publisher = {Wiley},
  doi = {10.1002/9781394260645},
  url = {https://onlinelibrary.wiley.com/doi/book/10.1002/9781394260645},
  urldate = {2024-06-01},
  isbn = {978-1-394-26064-5},
  langid = {english},
  file = {/home/ral/Zotero/storage/GFY5Y8M9/Dillman et al. - 2014 - Internet, Phone, Mail, and Mixed‐Mode Surveys The.pdf}
}

@online{dong_etal23,
  title = {Probing {{Explicit}} and {{Implicit Gender Bias}} through {{LLM Conditional Text Generation}}},
  author = {Dong, Xiangjue and Wang, Yibo and Yu, Philip S. and Caverlee, James},
  date = {2023-11-01},
  eprint = {2311.00306},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2311.00306},
  url = {http://arxiv.org/abs/2311.00306},
  urldate = {2023-12-23},
  abstract = {Large Language Models (LLMs) can generate biased and toxic responses. Yet most prior work on LLM gender bias evaluation requires predefined gender-related phrases or gender stereotypes, which are challenging to be comprehensively collected and are limited to explicit bias evaluation. In addition, we believe that instances devoid of gender-related language or explicit stereotypes in inputs can still induce gender bias in LLMs. Thus, in this work, we propose a conditional text generation mechanism without the need for predefined gender phrases and stereotypes. This approach employs three types of inputs generated through three distinct strategies to probe LLMs, aiming to show evidence of explicit and implicit gender biases in LLMs. We also utilize explicit and implicit evaluation metrics to evaluate gender bias in LLMs under different strategies. Our experiments demonstrate that an increased model size does not consistently lead to enhanced fairness and all tested LLMs exhibit explicit and/or implicit gender bias, even when explicit gender stereotypes are absent in the inputs.},
  pubstate = {prepublished},
  file = {/home/ral/Zotero/storage/CVHIY5XZ/Dong et al. - 2023 - Probing Explicit and Implicit Gender Bias through .pdf;/home/ral/Zotero/storage/UWJVJ6TW/2311.html}
}

@article{dow01,
  title = {A Comparative Spatial Analysis of Majoritarian and Proportional Elections},
  author = {Dow, Jay K},
  date = {2001-03},
  journaltitle = {Electoral Studies},
  shortjournal = {Electoral Studies},
  volume = {20},
  number = {1},
  pages = {109--125},
  issn = {02613794},
  doi = {10.1016/S0261-3794(99)00041-4},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0261379499000414},
  urldate = {2024-01-03},
  abstract = {This study estimates spatial representations of recent elections in Canada, France, The Netherlands and Israel. Its purpose is to test whether there exist systematic differences in the extent of spatial dispersion among parties and candidates in the majoritarian and proportional electoral systems. Canada and France are majoritarian systems, while The Netherlands and Israel are highly proportional. The study uses a measure of central tendency developed by Kollman et al. (1992, 1993, 1998) [Kollman, K., Miller, J.H., Page, S.E., 1992. Adaptive parties in spatial elections. American Political Science Review, 86, 929–937; 1993. Adaptive parties and spatial voting theory. In: Grofman, B. (Ed.), Information, Participation \& Choice. University of Michigan Press, Ann Arbor, pp. 161–173; 1998. Political parties and electoral landscapes. British Journal of Political Science, 28, 139–158] and non-parametric statistical tests to compare the relative dispersion of parties and candidates across the maps. The analysis reveals that parties and candidates in the majoritarian systems are located significantly closer to the center of the distribution of voters than those in proportional systems. The estimated spatial maps also provide information useful for interpreting the bases of electoral politics in each country. © 2000 Elsevier Science Ltd. All rights reserved.},
  langid = {english},
  annotation = {92 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/QRAKC47Q/Dow - 2001 - A comparative spatial analysis of majoritarian and.pdf}
}

@book{downs57,
  title = {An {{Economic Theory}} of {{Democracy}}},
  author = {Downs, Anthony},
  date = {1957},
  edition = {1},
  publisher = {Harper \& Row},
  location = {New York},
  langid = {english},
  file = {/home/ral/Zotero/storage/2RFYYJL7/Downs - An Economic Theory of Democracy.pdf}
}

@unpublished{dufour23,
  title = {La Construction de La Bibliographie},
  author = {Dufour, Richard},
  date = {2023},
  eventtitle = {Plan de Formation},
  venue = {Université Laval, Québec}
}

@book{duverger81,
  title = {Les Partis Politiques},
  author = {Duverger, Maurice},
  date = {1981},
  publisher = {FeniXX}
}

@online{dziri_etal23,
  title = {Faith and {{Fate}}: {{Limits}} of {{Transformers}} on {{Compositionality}}},
  shorttitle = {Faith and {{Fate}}},
  author = {Dziri, Nouha and Lu, Ximing and Sclar, Melanie and Li, Xiang Lorraine and Jiang, Liwei and Lin, Bill Yuchen and West, Peter and Bhagavatula, Chandra and Bras, Ronan Le and Hwang, Jena D. and Sanyal, Soumya and Welleck, Sean and Ren, Xiang and Ettinger, Allyson and Harchaoui, Zaid and Choi, Yejin},
  date = {2023-06-01},
  eprint = {2305.18654},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2305.18654},
  url = {http://arxiv.org/abs/2305.18654},
  urldate = {2023-10-19},
  abstract = {Transformer large language models (LLMs) have sparked admiration for their exceptional performance on tasks that demand intricate multi-step reasoning. Yet, these models simultaneously show failures on surprisingly trivial problems. This begs the question: Are these errors incidental, or do they signal more substantial limitations? In an attempt to demystify Transformers, we investigate the limits of these models across three representative compositional tasks – multi-digit multiplication, logic grid puzzles, and a classic dynamic programming problem. These tasks require breaking problems down into sub-steps and synthesizing these steps into a precise answer. We formulate compositional tasks as computation graphs to systematically quantify the level of complexity, and break down reasoning steps into intermediate sub-procedures. Our empirical findings suggest that Transformers solve compositional tasks by reducing multi-step compositional reasoning into linearized subgraph matching, without necessarily developing systematic problem-solving skills. To round off our empirical study, we provide theoretical arguments on abstract multi-step reasoning problems that highlight how Transformers' performance will rapidly decay with increased task complexity.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/ral/Zotero/storage/3MH8CDIG/Dziri et al. - 2023 - Faith and Fate Limits of Transformers on Compositionality.pdf}
}

@article{easterbrook_etal91b,
  title = {Publication Bias in Clinical Research},
  author = {Easterbrook, P.J and Gopalan, R and Berlin, J.A and Matthews, D.R},
  date = {1991-04},
  journaltitle = {The Lancet},
  shortjournal = {The Lancet},
  volume = {337},
  number = {8746},
  pages = {867--872},
  issn = {01406736},
  doi = {10.1016/0140-6736(91)90201-Y},
  url = {https://linkinghub.elsevier.com/retrieve/pii/014067369190201Y},
  urldate = {2023-09-04},
  langid = {english},
  keywords = {notion},
  annotation = {2172 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/9Y29LQKQ/Easterbrook et al. - 1991 - Publication bias in clinical research.pdf}
}

@inproceedings{egersdoerfer_etal23,
  title = {Early {{Exploration}} of {{Using ChatGPT}} for {{Log-based Anomaly Detection}} on {{Parallel File Systems Logs}}},
  booktitle = {Proceedings of the 32nd {{International Symposium}} on {{High-Performance Parallel}} and {{Distributed Computing}}},
  author = {Egersdoerfer, Chris and Zhang, Di and Dai, Dong},
  date = {2023-08-07},
  pages = {315--316},
  publisher = {ACM},
  location = {Orlando FL USA},
  doi = {10.1145/3588195.3595943},
  url = {https://dl.acm.org/doi/10.1145/3588195.3595943},
  urldate = {2023-10-03},
  abstract = {Log-based anomaly detection has been extensively studied to help detect complex runtime anomalies in production systems. However, existing techniques exhibit several common issues. First, they rely heavily on expert-labeled logs to discern anomalous behavior patterns. But labelling enough log data manually to effectively train deep neural networks may take too long. Second, they rely on numeric model prediction based on numeric vector input which causes model decisions to be largely non-interpretable by humans which further rules out targeted error correction.},
  eventtitle = {{{HPDC}} '23: {{The}} 32nd {{International Symposium}} on {{High-Performance Parallel}} and {{Distributed Computing}}},
  langid = {english},
  annotation = {4 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/2MF9KBWP/Egersdoerfer et al. - 2023 - Early Exploration of Using ChatGPT for Log-based Anomaly Detection on Parallel File Systems Logs.pdf}
}

@article{egger_etal97,
  title = {Bias in Meta-Analysis Detected by a Simple, Graphical Test},
  author = {Egger, M. and Smith, G. D. and Schneider, M. and Minder, C.},
  date = {1997-09-13},
  journaltitle = {BMJ},
  shortjournal = {BMJ},
  volume = {315},
  number = {7109},
  pages = {629--634},
  issn = {0959-8138, 1468-5833},
  doi = {10.1136/bmj.315.7109.629},
  url = {https://www.bmj.com/lookup/doi/10.1136/bmj.315.7109.629},
  urldate = {2023-09-04},
  abstract = {Objective: Funnel plots (plots of effect estimates against sample size) may be useful to detect bias in meta-analyses that were later contradicted by large trials. We examined whether a simple test of asymmetry of funnel plots predicts discordance of results when meta-analyses are compared to large trials, and we assessed the prevalence of bias in published meta-analyses. Design: Medline search to identify pairs consisting of a meta-analysis and a single large trial (concordance of results was assumed if effects were in the same direction and the meta-analytic estimate was within 30\% of the trial); analysis of funnel plots from 37 meta-analyses identified from a hand search of four leading general medicine journals 1993-6 and 38 meta-analyses from the second 1996 issue of the Cochrane Database of Systematic Reviews. Main outcome measure: Degree of funnel plot asymmetry as measured by the intercept from regression of standard normal deviates against precision. Results: In the eight pairs of meta-analysis and large trial that were identified (five from cardiovascular medicine, one from diabetic medicine, one from geriatric medicine, one from perinatal medicine) there were four concordant and four discordant pairs. In all cases discordance was due to meta-analyses showing larger effects. Funnel plot asymmetry was present in three out of four discordant pairs but in none of concordant pairs. In 14 (38\%) journal meta-analyses and 5 (13\%) Cochrane reviews, funnel plot asymmetry indicated that there was bias. Conclusions: A simple analysis of funnel plots provides a useful test for the likely presence of bias in meta-analyses, but as the capacity to detect bias will be limited when meta-analyses are based on a limited number of small trials the results from such analyses should be treated with considerable caution.},
  langid = {english},
  keywords = {notion},
  annotation = {44276 citations (Semantic Scholar/DOI) [2024-10-14]\\
40035 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/FCMLU4X5/Egger et al. - 1997 - Bias in meta-analysis detected by a simple, graphi.pdf}
}

@online{eloundou_etal23,
  title = {{{GPTs}} Are {{GPTs}}: {{An Early Look}} at the {{Labor Market Impact Potential}} of {{Large Language Models}}},
  shorttitle = {{{GPTs}} Are {{GPTs}}},
  author = {Eloundou, Tyna and Manning, Sam and Mishkin, Pamela and Rock, Daniel},
  date = {2023-08-21},
  eprint = {2303.10130},
  eprinttype = {arXiv},
  eprintclass = {cs, econ, q-fin},
  url = {http://arxiv.org/abs/2303.10130},
  urldate = {2023-09-26},
  abstract = {We investigate the potential implications of large language models (LLMs), such as Generative Pretrained Transformers (GPTs), on the U.S. labor market, focusing on the increased capabilities arising from LLM-powered software compared to LLMs on their own. Using a new rubric, we assess occupations based on their alignment with LLM capabilities, integrating both human expertise and GPT-4 classifications. Our findings reveal that around 80\% of the U.S. workforce could have at least 10\% of their work tasks affected by the introduction of LLMs, while approximately 19\% of workers may see at least 50\% of their tasks impacted. We do not make predictions about the development or adoption timeline of such LLMs. The projected effects span all wage levels, with higher-income jobs potentially facing greater exposure to LLM capabilities and LLM-powered software. Significantly, these impacts are not restricted to industries with higher recent productivity growth. Our analysis suggests that, with access to an LLM, about 15\% of all worker tasks in the US could be completed significantly faster at the same level of quality. When incorporating software and tooling built on top of LLMs, this share increases to between 47 and 56\% of all tasks. This finding implies that LLM-powered software will have a substantial effect on scaling the economic impacts of the underlying models. We conclude that LLMs such as GPTs exhibit traits of general-purpose technologies, indicating that they could have considerable economic, social, and policy implications.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Economics - General Economics},
  file = {/home/ral/Zotero/storage/V4SUF9Z5/Eloundou et al. - 2023 - GPTs are GPTs An Early Look at the Labor Market Impact Potential of Large Language Models.pdf}
}

@article{erk10,
  title = {Is Nationalism Left or Right? {{Critical}} Junctures in {{Québécois}} Nationalism*: {{Is}} Nationalism Left or Right?},
  shorttitle = {Is Nationalism Left or Right?},
  author = {Erk, Jan},
  date = {2010-06-25},
  journaltitle = {Nations and Nationalism},
  volume = {16},
  number = {3},
  pages = {423--441},
  issn = {13545078, 14698129},
  doi = {10.1111/j.1469-8129.2010.00410.x},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1469-8129.2010.00410.x},
  urldate = {2023-12-07},
  abstract = {Sub-state nationalist parties of the industrialised West occupy different positions along the left–right political spectrum. Despite the similarities of their political agendas, these parties adopt different ideological identities. This paper seeks to explain the choice of party position and the long-term consistency of these positions by employing a path-dependent perspective. The focus is first, on the critical junctures during which such choices are made; and second, on the mechanisms of continuity ensuring the persistence of the left–right identities. The argument is explored within the empirical context of Que´ be´ cois nationalism.},
  langid = {english},
  annotation = {15 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/CH9KC7BG/Erk - 2010 - Is nationalism left or right Critical junctures i.pdf}
}

@article{ezrow08,
  title = {Parties' {{Policy Programmes}} and the {{Dog}} That {{Didn}}'t {{Bark}}: {{No Evidence}} That {{Proportional Systems Promote Extreme Party Positioning}}},
  shorttitle = {Parties' {{Policy Programmes}} and the {{Dog}} That {{Didn}}'t {{Bark}}},
  author = {Ezrow, Lawrence},
  date = {2008-07-01},
  journaltitle = {British Journal of Political Science},
  shortjournal = {British Journal of Political Science},
  volume = {38},
  pages = {479--497},
  doi = {10.1017/S0007123408000240},
  abstract = {There is extensive theoretical research that explores the linkages between parties' policy positions, on the one hand, and the characteristics of the political system (i.e. voting rules and the number of parties) on the other, but empirical research on this topic is less developed. Building on earlier work by Jay Dow, this article reports empirical analyses exploring the connections between the average party policy extremism in fifteen party systems (defined as the average party policy distance from the party system centre), and two important system-level variables: the proportionality of the electoral laws used to select representatives to the national legislature, and the number of political parties. Contrary to expectations – but consistent with recent theoretical work by Norman Schofield and his co-authors – no evidence is found that average party policy extremism increases under proportional representation, nor that policy extremism increases in countries that feature large numbers of parties. These findings have important implications for political representation and for understanding parties' election strategies.},
  annotation = {75 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/KIEYZHJ3/Ezrow - 2008 - Parties' Policy Programmes and the Dog that Didn't.pdf}
}

@article{fearon_laitin03,
  title = {Ethnicity, {{Insurgency}}, and {{Civil War}}},
  author = {Fearon, James D. and Laitin, David D.},
  date = {2003},
  journaltitle = {The American Political Science Review},
  volume = {97},
  number = {1},
  eprint = {3118222},
  eprinttype = {jstor},
  pages = {75--90},
  publisher = {[American Political Science Association, Cambridge University Press]},
  issn = {0003-0554},
  url = {https://www.jstor.org/stable/3118222},
  urldate = {2024-09-12},
  abstract = {An influential conventional wisdom holds that civil wars proliferated rapidly with the end of the Cold War and that the root cause of many or most of these has been ethnic and religious antagonisms. We show that the current prevalence of internal war is mainly the result of a steady accumulation of protracted conflicts since the 1950s and 1960s rather than a sudden change associated with a new, post-Cold War international system. We also find that after controlling for per capita income, more ethnically or religiously diverse countries have been no more likely to experience significant civil violence in this period. We argue for understanding civil war in this period in terms of insurgency or rural guerrilla warfare, a particular form of military practice that can be harnessed to diverse political agendas. The factors that explain which countries have been at risk for civil war are not their ethnic or religious characteristics but rather the conditions that favor insurgency. These include poverty-which marks financially and bureaucratically weak states and also favors rebel recruitment-political instability, rough terrain, and large populations.},
  file = {/home/ral/Zotero/storage/4VDCUT2J/Fearon and Laitin - 2003 - Ethnicity, Insurgency, and Civil War.pdf}
}

@article{fearon91,
  title = {Counterfactuals and {{Hypothesis Testing}} in {{Political Science}}},
  author = {Fearon, James D.},
  date = {1991-01},
  journaltitle = {World Politics},
  shortjournal = {World Pol.},
  volume = {43},
  number = {2},
  pages = {169--195},
  issn = {0043-8871, 1086-3338},
  doi = {10.2307/2010470},
  url = {https://www.cambridge.org/core/product/identifier/S0043887100010935/type/journal_article},
  urldate = {2024-09-12},
  abstract = {Scholars in comparative politics and international relations routinely evaluate causal hypotheses by referring to               counterfactual cases               where a hypothesized causal factor is supposed to have been absent. The methodological status and the viability of this very common procedure are unclear and are worth examining. How does the strategy of counterfactual argument relate, if at all, to methods of hypothesis testing based on the comparison of actual cases, such as regression analysis or Mill's Method of Difference? Are counterfactual thought experiments a viable means of assessing hypotheses about national and international outcomes, or are they methodologically invalid in principle? The paper addresses the first question in some detail and begins discussion of the second. Examples from work on the causes of World War I, the nonoccurrence of World War III, social revolutions, the breakdown of democratic regimes in Latin America, and the origins of fascism and corporatism in Europe illustrate the use, problems and potential of counterfactual argument in small-N-oriented political science research.},
  langid = {english},
  file = {/home/ral/Zotero/storage/CR3GB2U6/Fearon - 1991 - Counterfactuals and Hypothesis Testing in Political Science.pdf}
}

@inproceedings{figenio_etal24,
  title = {The {{Impact}} of {{Activation Patterns}} in the {{Explainability}} of {{Large Language Models}} – {{A Survey}} of Recent Advances},
  booktitle = {Escola {{Regional}} de {{Banco}} de {{Dados}} ({{ERBD}})},
  author = {Figênio, Mateus R. and Santanché, André and Gomes-Jr, Luiz},
  date = {2024-04-10},
  pages = {141--149},
  publisher = {SBC},
  issn = {2595-413X},
  doi = {10.5753/erbd.2024.238868},
  url = {https://sol.sbc.org.br/index.php/erbd/article/view/28501},
  urldate = {2024-10-26},
  abstract = {The performance benchmarks of Natural Language Processing (NLP) tasks have been overwhelmed by Large Language Models (LLMs), with their capabilities outshining many previous approaches to language modeling. But, despite the success in these tasks and the more ample and pervasive use of these models in many daily and specialized fields of application, little is known of how or why they reach the outputs they do. This study reviews the development of Language Models (LMs), the advances in their explainability approaches, and focuses on assessing methods to interpret and explain the neural network portion of LMs (specially of Transformer models) as means of better understanding them.},
  eventtitle = {Escola {{Regional}} de {{Banco}} de {{Dados}} ({{ERBD}})},
  langid = {english},
  annotation = {0 citations (Crossref/DOI) [2024-11-13]},
  file = {/home/ral/Zotero/storage/B7GY5A6H/Figênio et al. - 2024 - The Impact of Activation Patterns in the Explainability of Large Language Models – A Survey of recen.pdf}
}

@article{filippi_etal23,
  title = {Automation Technologies and Their Impact on Employment: {{A}} Review, Synthesis and Future Research Agenda},
  shorttitle = {Automation Technologies and Their Impact on Employment},
  author = {Filippi, Emilia and Bannò, Mariasole and Trento, Sandro},
  date = {2023},
  journaltitle = {Technological Forecasting and Social Change},
  volume = {191},
  pages = {122448},
  publisher = {Elsevier},
  url = {https://www.sciencedirect.com/science/article/pii/S0040162523001336},
  urldate = {2023-09-27},
  file = {/home/ral/Zotero/storage/IVXMQBZP/Filippi et al. - 2023 - Automation technologies and their impact on employment A review, synthesis and future research agen.pdf}
}

@article{fillieule01,
  title = {Propositions pour une analyse processuelle de l'engagement individuel. Post scriptum},
  author = {Fillieule, Olivier},
  date = {2001},
  journaltitle = {Revue française de science politique},
  volume = {51},
  number = {1},
  pages = {199--215},
  publisher = {Presses de Sciences Po},
  issn = {0035-2950},
  doi = {10.3917/rfsp.511.0199},
  url = {https://shs.cairn.info/revue-francaise-de-science-politique-2001-1-page-199?lang=fr&tab=resume},
  urldate = {2024-09-12},
  langid = {french},
  file = {/home/ral/Zotero/storage/X7T83462/Fillieule - 2001 - Propositions pour une analyse processuelle de l'engagement individuel. Post scriptum.pdf}
}

@article{fink_etal23,
  title = {Potential of {{ChatGPT}} and {{GPT-4}} for {{Data Mining}} of {{Free-Text CT Reports}} on {{Lung Cancer}}},
  author = {Fink, Matthias A. and Bischoff, Arved and Fink, Christoph A. and Moll, Martin and Kroschke, Jonas and Dulz, Luca and Heußel, Claus Peter and Kauczor, Hans-Ulrich and Weber, Tim F.},
  date = {2023-09-01},
  journaltitle = {Radiology},
  shortjournal = {Radiology},
  volume = {308},
  number = {3},
  pages = {e231362},
  issn = {0033-8419, 1527-1315},
  doi = {10.1148/radiol.231362},
  url = {http://pubs.rsna.org/doi/10.1148/radiol.231362},
  urldate = {2023-09-27},
  langid = {english},
  annotation = {77 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/J9TTPBBU/Fink et al. - 2023 - Potential of ChatGPT and GPT-4 for Data Mining of Free-Text CT Reports on Lung Cancer.pdf}
}

@unpublished{fischer_etal23,
  title = {What Does {{ChatGPT}} Return about Human Values? {{Exploring}} Value Bias in {{ChatGPT}} Using a Descriptive Value Theory},
  author = {Fischer, Ronald and Luczak-Roesch, Markus and Karl, Johannes A},
  date = {2023},
  eprint = {2304.03612},
  eprinttype = {arXiv},
  file = {/home/ral/Zotero/storage/N47TC6H8/Fischer et al_2023_What does ChatGPT return about human values.pdf}
}

@article{floridi_chiriatti20,
  title = {{{GPT-3}}: {{Its Nature}}, {{Scope}}, {{Limits}}, and {{Consequences}}},
  shorttitle = {{{GPT-3}}},
  author = {Floridi, Luciano and Chiriatti, Massimo},
  date = {2020-12-01},
  journaltitle = {Minds and Machines},
  shortjournal = {Minds \& Machines},
  volume = {30},
  number = {4},
  pages = {681--694},
  issn = {1572-8641},
  doi = {10.1007/s11023-020-09548-1},
  url = {https://doi.org/10.1007/s11023-020-09548-1},
  urldate = {2024-09-12},
  abstract = {In this commentary, we discuss the nature of reversible and irreversible questions, that is, questions that may enable one to identify the nature of the source of their answers. We then introduce GPT-3, a third-generation, autoregressive language model that uses deep learning to produce human-like texts, and use the previous distinction to analyse it. We expand the analysis to present three tests based on mathematical, semantic (that is, the Turing Test), and ethical questions and show that GPT-3 is not designed to pass any of them. This is a reminder that GPT-3 does not do what it is not supposed to do, and that any interpretation of GPT-3 as the beginning of the emergence of a general form of artificial intelligence is merely uninformed science fiction. We conclude by outlining some of the significant consequences of the industrialisation of automatic and cheap production of good, semantic artefacts.},
  langid = {english},
  keywords = {Artificial Intelligence,Automation,GPT-3,Irreversibility,Semantics,Turing Test},
  file = {/home/ral/Zotero/storage/HNSY7MFN/Floridi and Chiriatti - 2020 - GPT-3 Its Nature, Scope, Limits, and Consequences.pdf}
}

@book{fowler14,
  title = {Survey Research Methods},
  author = {Fowler, Floyd J.},
  date = {2014},
  series = {Applied Social Research Methods Series},
  edition = {Fifth edition},
  publisher = {SAGE},
  location = {Los Angeles},
  isbn = {978-1-4522-5900-0 978-1-4833-1240-8},
  langid = {english},
  pagetotal = {171},
  keywords = {Social surveys},
  file = {/home/ral/Zotero/storage/FDJ8Z26T/Fowler - 2014 - Survey research methods.pdf}
}

@incollection{fried67,
  title = {Cleavage {{Structures}}, {{Party Systems}} and {{Voter Alignments}}},
  shorttitle = {Party {{Systems}} and {{Voter Alignments}}},
  booktitle = {Party {{Systems}} and {{Voter Alignments}}: {{Cross-National Perspectives}}},
  author = {Fried, Robert C.},
  editor = {Lipset, Seymour Martin and Rokkan, Stein},
  date = {1967},
  pages = {3--64},
  publisher = {The Free Press},
  location = {New York},
  url = {https://www.cambridge.org/core/product/identifier/S0003055400203250/type/journal_article},
  urldate = {2023-12-26},
  langid = {english}
}

@online{fujimoto_takemoto23,
  title = {Revisiting the {{Political Biases}} of {{ChatGPT}}},
  author = {Fujimoto, Sasuke and Takemoto, Kazuhiro},
  date = {2023},
  eprinttype = {Preprints},
  url = {https://www.preprints.org/manuscript/202305.1540},
  urldate = {2023-11-24},
  pubstate = {prepublished},
  file = {/home/ral/Zotero/storage/JHZPQH23/Fujimoto_Takemoto_2023_Revisiting the Political Biases of ChatGPT.pdf}
}

@book{gallagher_mitchell05,
  title = {The {{Politics}} of {{Electoral Systems}}},
  author = {Gallagher, Michael and Mitchell, Paul},
  date = {2005-09-15},
  eprint = {Igdj1P4vBwMC},
  eprinttype = {googlebooks},
  publisher = {OUP Oxford},
  abstract = {Electoral systems matter. They are a crucial link in the chain connecting the preferences of citizens to the policy choices made by governments. They are chosen by political actors and, once in existence, have political consequences for those actors. They are an important object of study for anyone interested in the political process, and in this book we subject them to systematic analysis. In addition to some comparative chapters, the book contains full accounts of the operation of electoral systems in 22 countries: France, the UK, Germany, Italy, Israel, Spain, Austria, Belgium, Denmark, Finland, The Netherlands, Ireland, Hungary, Russia, Australia, Canada, India, the USA, Japan, New Zealand, Chile, and South Africa. The book provides detailed analyses of the operation of a diverse set of electoral systems in their national context. Each chapter explains how the electoral system really works in the given country, examining the strategic incentives the system provides to voters, candidates, and parties. All country chapters have a common format and structure. Successive sections analyse: the institutional context; how each electoral system was chosen historically; how the current electoral system operates (the rules, mechanics, and ballot structure); and the political consequences of the current system (the impact on the party system, the internal life of parties, and the impact on parliament and government formation). Each country chapter then contains a final section which focuses on the politicization of electoral institutions. In recent years many countries have changed their electoral systems, either entirely or in part so there is a strong focus on the processes of electoral reform, both historically and prospectively. The book concentrates on the real world 'politics', as well as the 'political science' of electoral systems. The book will be of interest to those concerned with the practical political business of electoral reform. The book contains a wealth of evidence about the performance of various kinds of proportional representation and of non-PR systems. This will be invaluable for anyone interested in the question: 'What would be the best electoral system for my country?'},
  isbn = {978-0-19-153151-4},
  langid = {english},
  pagetotal = {689}
}

@article{garzia_marschall12,
  title = {Voting {{Advice Applications}} under Review: The State of Research},
  shorttitle = {Voting {{Advice Applications}} under Review},
  author = {Garzia, Diego and Marschall, Stefan},
  date = {2012},
  journaltitle = {International Journal of Electronic Governance},
  shortjournal = {IJEG},
  volume = {5},
  number = {3/4},
  pages = {203},
  abstract = {In recent years, Voting Advice Applications (VAAs) have become a relevant object of political science research. The aim of this paper is to develop a map of the existing literature and to outline a research agenda for this increasingly relevant tool and its role within modern democracies. Starting point of the paper is the dissemination of VAAs in Europe, focusing on the differences and similarities between the main types of VAAs. After having outlined the reasons for the dramatic spread of VAAs among European countries and voters, we provide an overview on the existing VAA literature. We then present a comparative research agenda for the VAAs by identifying questions that could be posed to the tools and their role out of different analytical perspectives. In the conclusion, we bring forward the argument that VAAs might matter even more in the future, indicating the need for a coordinated research effort.},
  langid = {english},
  file = {/home/ral/Zotero/storage/NPN22YB5/Garzia et Marschall - 2012 - Voting Advice Applications under review the state.pdf}
}

@inbook{garzia_marschall19,
  title = {Voting {{Advice Applications}}},
  booktitle = {Oxford {{Research Encyclopedia}} of {{Politics}}},
  author = {Garzia, Diego and Marschall, Stefan},
  date = {2019},
  publisher = {Oxford University Press},
  abstract = {Voting Advice Applications (VAAs) are online tools that assist citizens with their voting decisions. They are offered to voters before elections in many countries and have experienced remarkable success. Recently flourishing research on VAAs addresses this phenomenon and provides explanations for the dissemination and popularity of these tools. Moreover, VAAs have been analyzed regarding their effects on political parties, candidates, and on voters in regard to their electoral behavior. Research shows that using a VAA indeed makes a difference, while the effect depends strongly on the way a VAA is designed and by whom it is used. The abundance of data generated by VAAs bears potential for comparative studies of public opinion and party systems over time and across countries, and thereby bridges research on VAAs to general questions of political science research.},
  bookauthor = {Garzia, Diego and Marschall, Stefan},
  langid = {english},
  file = {/home/ral/Zotero/storage/TNTVLI2K/Garzia et Marschall - 2019 - Voting Advice Applications.pdf}
}

@article{geddes90,
  title = {How the {{Cases You Choose Affect}} the {{Answers You Get}}: {{Selection Bias}} in {{Comparative Politics}}},
  shorttitle = {How the {{Cases You Choose Affect}} the {{Answers You Get}}},
  author = {Geddes, Barbara},
  date = {1990-01},
  journaltitle = {Political Analysis},
  volume = {2},
  pages = {131--150},
  issn = {1047-1987, 1476-4989},
  doi = {10.1093/pan/2.1.131},
  url = {https://www.cambridge.org/core/journals/political-analysis/article/how-the-cases-you-choose-affect-the-answers-you-get-selection-bias-in-comparative-politics/05E854AA55C1BF090B56CEC73ACEFC6B},
  urldate = {2024-09-12},
  abstract = {This article demonstrates how the selection of cases for study on the basis of outcomes on the dependent variable biases conclusions. It first lays out the logic of explanation and shows how it is violated when only cases that have achieved the outcome of interest are studied. It then examines three well-known and highly regarded studies in the field of comparative politics, comparing the conclusions reached in the original work with a test of the arguments on cases selected without regard for their position on the dependent variable. In each instance, conclusions based on the uncorrelated sample differ from the original conclusions.},
  langid = {english},
  file = {/home/ral/Zotero/storage/G5STWGHQ/Geddes - 1990 - How the Cases You Choose Affect the Answers You Get Selection Bias in Comparative Politics.pdf}
}

@article{gentzkow_etal19,
  title = {Text as Data},
  author = {Gentzkow, Matthew and Kelly, Bryan and Taddy, Matt},
  date = {2019},
  journaltitle = {Journal of Economic Literature},
  volume = {57},
  number = {3},
  pages = {535--574},
  publisher = {American Economic Association 2014 Broadway, Suite 305, Nashville, TN 37203-2425},
  isbn = {0022-0515}
}

@article{gigerenzer_gaissmaier11,
  title = {Heuristic {{Decision Making}}},
  author = {Gigerenzer, Gerd and Gaissmaier, Wolfgang},
  date = {2011},
  journaltitle = {Annual Review of Psychology},
  shortjournal = {Annu. Rev. Psychol.},
  volume = {62},
  number = {1},
  pages = {451--482},
  abstract = {As reflected in the amount of controversy, few areas in psychology have undergone such dramatic conceptual changes in the past decade as the emerging science of heuristics. Heuristics are efficient cognitive processes, conscious or unconscious, that ignore part of the information. Because using heuristics saves effort, the classical view has been that heuristic decisions imply greater errors than do “rational” decisions as defined by logic or statistical models. However, for many decisions, the assumptions of rational models are not met, and it is an empirical rather than an a priori issue how well cognitive heuristics function in an uncertain world. To answer both the descriptive question (“Which heuristics do people use in which situations?”) and the prescriptive question (“When should people rely on a given heuristic rather than a complex strategy to make better judgments?”), formal models are indispensable. We review research that tests formal models of heuristic inference, including in business organizations, health care, and legal institutions. This research indicates that (a) individuals and organizations often rely on simple heuristics in an adaptive way, and (b) ignoring part of the information can lead to more accurate judgments than weighting and adding all information, for instance for low predictability and small samples. The big future challenge is to develop a systematic theory of the building blocks of heuristics as well as the core capacities and environmental structures these exploit.},
  langid = {english},
  file = {/home/ral/Zotero/storage/86XVDFDJ/Gigerenzer et Gaissmaier - 2011 - Heuristic Decision Making.pdf}
}

@report{gimpel_etal23,
  title = {Unlocking the Power of Generative {{AI}} Models and Systems Such as {{GPT-4}} and {{ChatGPT}} for Higher Education: {{A}} Guide for Students and Lecturers},
  shorttitle = {Unlocking the Power of Generative {{AI}} Models and Systems Such as {{GPT-4}} and {{ChatGPT}} for Higher Education},
  author = {Gimpel, Henner and Hall, Kristina and Decker, Stefan and Eymann, Torsten and Lämmermann, Luis and Mädche, Alexander and Röglinger, Maximilian and Ruiner, Caroline and Schoch, Manfred and Schoop, Mareike},
  date = {2023},
  institution = {{Hohenheim Discussion Papers in Business, Economics and Social Sciences}},
  url = {https://www.econstor.eu/handle/10419/270970},
  urldate = {2023-09-27},
  file = {/home/ral/Zotero/storage/MBCM574A/Gimpel et al. - 2023 - Unlocking the power of generative AI models and systems such as GPT-4 and ChatGPT for higher educati.pdf}
}

@online{github23,
  title = {{{GitHub Copilot}} · {{Your AI}} Pair Programmer},
  author = {{GitHub}},
  date = {2023},
  url = {https://github.com/features/copilot},
  urldate = {2024-01-08},
  abstract = {GitHub Copilot works alongside you directly in your editor, suggesting whole lines or entire functions for you.},
  langid = {english},
  organization = {GitHub},
  file = {/home/ral/Zotero/storage/DJ79Z6EP/copilot.html}
}

@online{gitlin24,
  title = {Volkswagen Is Adding {{ChatGPT}} to Its Infotainment System},
  author = {Gitlin, Jonathan M.},
  date = {2024-01-08T16:00:29+00:00},
  url = {https://arstechnica.com/cars/2024/01/volkswagen-is-adding-chatgpt-to-its-infotainment-system/},
  urldate = {2024-01-08},
  abstract = {VW is using Cerence's Chat Pro, which now incorporates ChatGPT.},
  langid = {american},
  organization = {Ars Technica},
  file = {/home/ral/Zotero/storage/E7GFVX4R/volkswagen-is-adding-chatgpt-to-its-infotainment-system.html}
}

@article{gjerdevik_heuch14,
  title = {Improving the Error Rates of the {{Begg}} and {{Mazumdar}} Test for Publication Bias in Fixed Effects Meta-Analysis},
  author = {Gjerdevik, Miriam and Heuch, Ivar},
  date = {2014-09-22},
  journaltitle = {BMC Medical Research Methodology},
  shortjournal = {BMC Medical Research Methodology},
  volume = {14},
  number = {1},
  pages = {109},
  issn = {1471-2288},
  doi = {10.1186/1471-2288-14-109},
  url = {https://doi.org/10.1186/1471-2288-14-109},
  urldate = {2023-10-06},
  abstract = {The rank correlation test introduced by Begg and Mazumdar is extensively used in meta-analysis to test for publication bias in clinical and epidemiological studies. It is based on correlating the standardized treatment effect with the variance of the treatment effect using Kendall’s tau as the measure of association. To our knowledge, the operational characteristics regarding the significance level of the test have not, however, been fully assessed.},
  keywords = {Error rates,Kendall’s tau,Meta-analysis,Publication bias,Rank correlation,Spearman’s rho},
  annotation = {49 citations (Semantic Scholar/DOI) [2024-10-14]\\
43 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/RWBBF6HK/Gjerdevik and Heuch - 2014 - Improving the error rates of the Begg and Mazumdar test for publication bias in fixed effects meta-a.pdf}
}

@article{goddard_etal12,
  title = {Automation Bias: A Systematic Review of Frequency, Effect Mediators, and Mitigators},
  shorttitle = {Automation Bias},
  author = {Goddard, Kate and Roudsari, Abdul and Wyatt, Jeremy C},
  date = {2012-01-01},
  journaltitle = {Journal of the American Medical Informatics Association},
  shortjournal = {Journal of the American Medical Informatics Association},
  volume = {19},
  number = {1},
  pages = {121--127},
  issn = {1067-5027},
  doi = {10.1136/amiajnl-2011-000089},
  url = {https://doi.org/10.1136/amiajnl-2011-000089},
  urldate = {2023-09-26},
  abstract = {Automation bias (AB)—the tendency to over-rely on automation—has been studied in various academic fields. Clinical decision support systems (CDSS) aim to benefit the clinical decision-making process. Although most research shows overall improved performance with use, there is often a failure to recognize the new errors that CDSS can introduce. With a focus on healthcare, a systematic review of the literature from a variety of research fields has been carried out, assessing the frequency and severity of AB, the effect mediators, and interventions potentially mitigating this effect. This is discussed alongside automation-induced complacency, or insufficient monitoring of automation output. A mix of subject specific and freetext terms around the themes of automation, human–automation interaction, and task performance and error were used to search article databases. Of 13,821 retrieved papers, 74 met the inclusion criteria. User factors such as cognitive style, decision support systems (DSS), and task specific experience mediated AB, as did attitudinal driving factors such as trust and confidence. Environmental mediators included workload, task complexity, and time constraint, which pressurized cognitive resources. Mitigators of AB included implementation factors such as training and emphasizing user accountability, and DSS design factors such as the position of advice on the screen, updated confidence levels attached to DSS output, and the provision of information versus recommendation. By uncovering the mechanisms by which AB operates, this review aims to help optimize the clinical decision-making process for CDSS developers and healthcare practitioners.},
  annotation = {300 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/T5B7ZCH3/Goddard et al. - 2012 - Automation bias a systematic review of frequency, effect mediators, and mitigators.pdf}
}

@article{goldberg12,
  title = {What {{Is Automation}}?},
  author = {Goldberg, Ken},
  date = {2012-01},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  volume = {9},
  number = {1},
  pages = {1--2},
  issn = {1558-3783},
  doi = {10.1109/TASE.2011.2178910},
  url = {https://ieeexplore.ieee.org/abstract/document/6104197},
  urldate = {2023-12-06},
  abstract = {It is argued that automation has expanded beyond its roots in Manufacturing to include applications in Healthcare, Security, Transportation, Agriculture, Construction, Energy, and many other areas. Both Robotics and Automation explore the frontiers of automated and semi-automated machines. Both fields are increasingly concerned with the role of humans and human interfaces, and with the potential of the Internet and Cloud Computing. So what is the difference between Robotics and Automation? There are many possible distinctions. Here is the summary from our Society's Field of Interest Statement: "...Robotics focuses on systems incorporating sensors and actuators that operate autonomously or semi-autonomously in cooperation with humans. Robotics research emphasizes intelligence and adaptability to cope with unstructured environments. Automation research emphasizes efficiency, productivity, quality, and reliability, focusing on systems that operate autonomously, often in structured environments over extended periods, and on the explicit structuring of such environments." This statement emphasizes how Automation emphasizes structured versus unstructured environments, reliability versus adaptability, and efficiency versus exploratory operations. These are valuable distinctions and the author would like to propose another one. In his view, research in Robotics emphasizes Feasibility. Feasibility focuses on proof-of-concept, demonstrating how a new functionality can be achieved. On the other hand, he feels, research in Automation emphasizes Quality. The author wishes to dispel the myth of the excluded middle: Robotics and Automation are not disjoint. Feasibility and Quality are closely related.},
  eventtitle = {{{IEEE Transactions}} on {{Automation Science}} and {{Engineering}}},
  annotation = {26 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/II4UWEBA/Goldberg - 2012 - What Is Automation.pdf}
}

@article{gonzalez_etal16,
  title = {Recent Advances and Emerging Applications in Text and Data Mining for Biomedical Discovery},
  author = {Gonzalez, Graciela H. and Tahsin, Tasnia and Goodale, Britton C. and Greene, Anna C. and Greene, Casey S.},
  date = {2016},
  journaltitle = {Briefings in bioinformatics},
  volume = {17},
  number = {1},
  pages = {33--42},
  publisher = {Oxford University Press},
  url = {https://academic.oup.com/bib/article-abstract/17/1/33/2240575},
  urldate = {2023-09-27},
  file = {/home/ral/Zotero/storage/2RIDI4NG/Gonzalez et al. - 2016 - Recent advances and emerging applications in text and data mining for biomedical discovery.pdf}
}

@book{gough_etal12,
  title = {An Introduction to Systematic Reviews},
  editor = {Gough, David and Oliver, Sandy and Thomas, James},
  date = {2012},
  publisher = {SAGE},
  location = {London ; Thousand Oaks, Calif},
  isbn = {978-1-84920-180-3 978-1-84920-181-0},
  langid = {english},
  pagetotal = {288},
  keywords = {Decision making,Research},
  annotation = {OCLC: ocn785989104},
  file = {/home/ral/Zotero/storage/XD26A4UR/Gough et al. - 2012 - An introduction to systematic reviews.pdf}
}

@online{goyal_etal23,
  title = {{{ChatGPT}} and {{Bard Responses}} to {{Polarizing Questions}}},
  author = {Goyal, Abhay and Siddique, Muhammad and Parekh, Nimay and Schwitzky, Zach and Broekaert, Clara and Michelotti, Connor and Wong, Allie and Cheung, Lam Yin and Hanlon, Robin O. and Cheung, Lam Yin and De Choudhury, Munmun and Lee, Roy Ka-Wei and Kumar, Navin},
  date = {2023-07-13},
  eprint = {2307.12402},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2307.12402},
  urldate = {2023-11-29},
  abstract = {Recent developments in natural language processing have demonstrated the potential of large language models (LLMs) to improve a range of educational and learning outcomes. Of recent chatbots based on LLMs, ChatGPT and Bard have made it clear that artificial intelligence (AI) technology will have significant implications on the way we obtain and search for information. However, these tools sometimes produce text that is convincing, but often incorrect, known as hallucinations. As such, their use can distort scientific facts and spread misinformation. To counter polarizing responses on these tools, it is critical to provide an overview of such responses so stakeholders can determine which topics tend to produce more contentious responses -- key to developing targeted regulatory policy and interventions. In addition, there currently exists no annotated dataset of ChatGPT and Bard responses around possibly polarizing topics, central to the above aims. We address the indicated issues through the following contribution: Focusing on highly polarizing topics in the US, we created and described a dataset of ChatGPT and Bard responses. Broadly, our results indicated a left-leaning bias for both ChatGPT and Bard, with Bard more likely to provide responses around polarizing topics. Bard seemed to have fewer guardrails around controversial topics, and appeared more willing to provide comprehensive, and somewhat human-like responses. Bard may thus be more likely abused by malicious actors. Stakeholders may utilize our findings to mitigate misinformative and/or polarizing responses from LLMs},
  langid = {english},
  pubstate = {prepublished},
  file = {/home/ral/Zotero/storage/53Y6MWUM/Goyal et al. - 2023 - ChatGPT and Bard Responses to Polarizing Questions.pdf}
}

@article{greif_laitin04,
  title = {A {{Theory}} of {{Endogenous Institutional Change}}},
  author = {Greif, Avner and Laitin, David D.},
  date = {2004-11},
  journaltitle = {American Political Science Review},
  volume = {98},
  number = {4},
  pages = {633--652},
  issn = {1537-5943, 0003-0554},
  doi = {10.1017/S0003055404041395},
  url = {https://www.cambridge.org/core/journals/american-political-science-review/article/theory-of-endogenous-institutional-change/161BF12CD6B8AA93F80EDA25CCDE12A9},
  urldate = {2024-09-12},
  abstract = {This paper asks (a) why and how institutions change, (b) how an institution persists in a changing environment, and (c) how processes that it unleashes lead to its own demise. The paper shows that the game-theoretic notion of self-enforcing equilibrium and the historical institutionalist focus on process are both inadequate to answer these questions. Building on a game-theoretic foundation, but responding to the critique of it by historical institutionalists, the paper introduces the concepts of quasi-parameters and self reinforcement. With these concepts, and building on repeated game theory, a dynamic approach to institutions is offered, one that can account for endogenous change (and stability) of institutions. Contextual accounts of formal governing institutions in early modern Europe and the informal institution of cleavage structure in the contemporary world provide illustrations of the approach.},
  langid = {english},
  file = {/home/ral/Zotero/storage/83SE99BK/Greif and Laitin - 2004 - A Theory of Endogenous Institutional Change.pdf}
}

@book{grimmer_etal22,
  title = {Text as Data: A New Framework for Machine Learning and the Social Sciences},
  shorttitle = {Text as Data},
  author = {Grimmer, Justin and Roberts, Margaret E. and Stewart, Brandon M.},
  date = {2022},
  publisher = {Princeton University Press},
  location = {Princeton},
  abstract = {"From social media posts and text messages to digital government documents and archives, researchers are bombarded with a deluge of text reflecting the social world. This textual data gives unprecedented insights into fundamental questions in the social sciences, humanities, and industry. Meanwhile new machine learning tools are rapidly transforming the way science and business are conducted. Text as Data shows how to combine new sources of data, machine learning tools, and social science research design to develop and evaluate new insights.Text as Data is organized around the core tasks in research projects using text–representation, discovery, measurement, prediction, and causal inference. The authors offer a sequential, iterative, and inductive approach to research design. Each research task is presented complete with real-world applications, example methods, and a distinct style of task-focused research. Bridging many divides–computer science and social science, the qualitative and the quantitative, and industry and academia–Text as Data is an ideal resource for anyone wanting to analyze large collections of text in an era when data is abundant and computation is cheap, but the enduring challenges of social science remain." –Page 4 of cover},
  isbn = {978-0-691-20754-4 978-0-691-20755-1},
  pagetotal = {336},
  keywords = {Apprentissage automatique,Data processing,Informatique,Machine learning,Sciences sociales,Social sciences,Text data mining}
}

@article{grimmer_stewart13,
  title = {Text as {{Data}}: {{The Promise}} and {{Pitfalls}} of {{Automatic Content Analysis Methods}} for {{Political Texts}}},
  shorttitle = {Text as {{Data}}},
  author = {Grimmer, Justin and Stewart, Brandon M.},
  date = {2013},
  journaltitle = {Political Analysis},
  shortjournal = {Polit. anal.},
  volume = {21},
  number = {3},
  pages = {267--297},
  issn = {1047-1987, 1476-4989},
  doi = {10.1093/pan/mps028},
  url = {https://www.cambridge.org/core/product/identifier/S1047198700013401/type/journal_article},
  urldate = {2023-09-03},
  abstract = {Politics and political conflict often occur in the written and spoken word. Scholars have long recognized this, but the massive costs of analyzing even moderately sized collections of texts have hindered their use in political science research. Here lies the promise of automated text analysis: it substantially reduces the costs of analyzing large collections of text. We provide a guide to this exciting new area of research and show how, in many instances, the methods have already obtained part of their promise. But there are pitfalls to using automated methods—they are no substitute for careful thought and close reading and require extensive and problem-specific validation. We survey a wide range of new methods, provide guidance on how to validate the output of the models, and clarify misconceptions and errors in the literature. To conclude, we argue that for automated text methods to become a standard tool for political scientists, methodologists must contribute new methods and new methods of validation.},
  langid = {english},
  keywords = {notion},
  annotation = {1681 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/979U33UL/Grimmer and Stewart - 2013 - Text as Data The Promise and Pitfalls of Automati.pdf}
}

@article{gross_sigelman84,
  title = {Comparing Party Systems: {{A}} Multidimensional Approach},
  shorttitle = {Comparing Party Systems},
  author = {Gross, Donald A. and Sigelman, Lee},
  date = {1984},
  journaltitle = {Comparative politics},
  volume = {16},
  number = {4},
  eprint = {421950},
  eprinttype = {jstor},
  pages = {463--479},
  publisher = {JSTOR},
  url = {https://www.jstor.org/stable/421950},
  urldate = {2023-11-16},
  file = {/home/ral/Zotero/storage/X789HCSA/link.html}
}

@online{gruber_weber24,
  title = {Rollama: {{An R}} Package for Using Generative Large Language Models through {{Ollama}}},
  shorttitle = {Rollama},
  author = {Gruber, Johannes B. and Weber, Maximilian},
  date = {2024-04-11},
  eprint = {2404.07654},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2404.07654},
  urldate = {2024-06-01},
  abstract = {rollama is an R package that wraps the Ollama API, which allows you to run different Generative Large Language Models (GLLM) locally. The package and learning material focus on making it easy to use Ollama for annotating textual or imagine data with open-source models as well as use these models for document embedding. But users can use or extend rollama to do essentially anything else that is possible through OpenAI's API, yet more private, reproducible and for free.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/home/ral/Zotero/storage/HM4JSXJH/Gruber and Weber - 2024 - rollama An R package for using generative large l.pdf}
}

@report{guha23,
  type = {preprint},
  title = {Fine-Tuning Human for {{LLM}} Projects},
  author = {Guha, Rehan},
  date = {2023-09-20},
  institution = {Open Science Framework},
  doi = {10.31219/osf.io/9js3b},
  url = {https://osf.io/9js3b},
  urldate = {2023-10-03},
  abstract = {In recent years after emerging of LLM in the space of NLP, tools like ChatGPT, BARD, DALL-E, took over the market and daily lives. We will be focusing on the human like output capability from LLM’s . There is a huge reservation of this technology due to multiple scenarios like security, accuracy, relevance, etc... In this paper, I will talk about a method which I have designed to fine tune a human being to lower the expectation from LLM outputs and increase the acceptance rate of the final product. This technique is more of a psychological method than a technological way to improve the models output to be more human like.},
  file = {/home/ral/Zotero/storage/QEX52WCV/Guha - 2023 - Fine-tuning human for LLM projects.pdf}
}

@inproceedings{guimbretiere_winograd00,
  title = {{{FlowMenu}}: {{Combining}} Command, Text, and Data Entry},
  shorttitle = {{{FlowMenu}}},
  booktitle = {Proceedings of the 13th Annual {{ACM}} Symposium on {{User}} Interface Software and Technology - {{UIST}} '00},
  author = {Guimbretiére, François and Winograd, Terry},
  date = {2000},
  pages = {213--216},
  publisher = {ACM Press},
  location = {San Diego, California, United States},
  doi = {10.1145/354401.354778},
  url = {http://portal.acm.org/citation.cfm?doid=354401.354778},
  urldate = {2023-09-27},
  eventtitle = {The 13th Annual {{ACM}} Symposium},
  isbn = {978-1-58113-212-0},
  langid = {english},
  annotation = {110 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/B4ZAC32V/Guimbretiére and Winograd - 2000 - FlowMenu Combining command, text, and data entry.pdf}
}

@inproceedings{guo_caliskan21,
  title = {Detecting {{Emergent Intersectional Biases}}: {{Contextualized Word Embeddings Contain}} a {{Distribution}} of {{Human-like Biases}}},
  shorttitle = {Detecting {{Emergent Intersectional Biases}}},
  booktitle = {Proceedings of the 2021 {{AAAI}}/{{ACM Conference}} on {{AI}}, {{Ethics}}, and {{Society}}},
  author = {Guo, Wei and Caliskan, Aylin},
  date = {2021-07-21},
  pages = {122--133},
  publisher = {ACM},
  location = {Virtual Event USA},
  doi = {10.1145/3461702.3462536},
  url = {https://dl.acm.org/doi/10.1145/3461702.3462536},
  urldate = {2023-11-24},
  eventtitle = {{{AIES}} '21: {{AAAI}}/{{ACM Conference}} on {{AI}}, {{Ethics}}, and {{Society}}},
  isbn = {978-1-4503-8473-5},
  langid = {english},
  annotation = {56 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/S8YQBHDV/Guo_Caliskan_2021_Detecting Emergent Intersectional Biases.pdf}
}

@online{guo23,
  title = {{{GPT Agents}} in {{Game Theory Experiments}}},
  author = {Guo, Fulin},
  date = {2023-05-09},
  eprint = {2305.05516},
  eprinttype = {arXiv},
  eprintclass = {econ, q-fin},
  url = {http://arxiv.org/abs/2305.05516},
  urldate = {2023-09-27},
  abstract = {This paper explores the potential of using Generative Pre-trained Transformer (GPT)-based agents as participants in strategic game experiments. Specifically, I focus on the finitely repeated ultimatum and prisoner's dilemma games, two well-studied games in economics. I develop prompts to enable GPT agents to understand the game rules and play the games. The results indicate that, given well-crafted prompts, GPT can generate realistic outcomes and exhibit behavior consistent with human behavior in certain important aspects, such as positive relationship between acceptance rates and offered amounts in the ultimatum game and positive cooperation rates in the prisoner's dilemma game. Some differences between the behavior of GPT and humans are observed in aspects like the evolution of choices over rounds. I also study two treatments in which the GPT agents are prompted to either have social preferences or not. The treatment effects are evident in both games. This preliminary exploration indicates that GPT agents can exhibit realistic performance in simple strategic games and shows the potential of using GPT as a valuable tool in social science research.},
  pubstate = {prepublished},
  keywords = {Economics - General Economics},
  file = {/home/ral/Zotero/storage/7C6PMEQQ/Guo - 2023 - GPT Agents in Game Theory Experiments.pdf}
}

@article{hall_taylor96,
  title = {Political {{Science}} and the {{Three New Institutionalisms}}},
  author = {Hall, Peter A. and Taylor, Rosemary C. R.},
  date = {1996-12},
  journaltitle = {Political Studies},
  shortjournal = {Political Studies},
  volume = {44},
  number = {5},
  pages = {936--957},
  issn = {0032-3217, 1467-9248},
  doi = {10.1111/j.1467-9248.1996.tb00343.x},
  url = {https://journals.sagepub.com/doi/10.1111/j.1467-9248.1996.tb00343.x},
  urldate = {2024-09-12},
  langid = {english},
  file = {/home/ral/Zotero/storage/3BTE7NXC/Hall and Taylor - 1996 - Political Science and the Three New Institutionalisms.pdf}
}

@online{haller_etal23,
  title = {{{OpinionGPT}}: {{Modelling Explicit Biases}} in {{Instruction-Tuned LLMs}}},
  shorttitle = {{{OpinionGPT}}},
  author = {Haller, Patrick and Aynetdinov, Ansar and Akbik, Alan},
  date = {2023-09-07},
  eprint = {2309.03876},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2309.03876},
  url = {http://arxiv.org/abs/2309.03876},
  urldate = {2024-01-02},
  abstract = {Instruction-tuned Large Language Models (LLMs) have recently showcased remarkable ability to generate fitting responses to natural language instructions. However, an open research question concerns the inherent biases of trained models and their responses. For instance, if the data used to tune an LLM is dominantly written by persons with a specific political bias, we might expect generated answers to share this bias. Current research work seeks to de-bias such models, or suppress potentially biased answers. With this demonstration, we take a different view on biases in instruction-tuning: Rather than aiming to suppress them, we aim to make them explicit and transparent. To this end, we present OpinionGPT, a web demo in which users can ask questions and select all biases they wish to investigate. The demo will answer this question using a model fine-tuned on text representing each of the selected biases, allowing side-by-side comparison. To train the underlying model, we identified 11 different biases (political, geographic, gender, age) and derived an instruction-tuning corpus in which each answer was written by members of one of these demographics. This paper presents OpinionGPT, illustrates how we trained the bias-aware model and showcases the web application (available at https://opiniongpt.informatik.hu-berlin.de).},
  pubstate = {prepublished},
  file = {/home/ral/Zotero/storage/ZL2G7EME/Haller et al. - 2023 - OpinionGPT Modelling Explicit Biases in Instructi.pdf;/home/ral/Zotero/storage/84MICUI5/2309.html}
}

@inproceedings{hamborg20,
  title = {Media Bias, the Social Sciences, and {{NLP}}: {{Automating}} Frame Analyses to Identify Bias by Word Choice and Labeling},
  shorttitle = {Media Bias, the Social Sciences, and {{NLP}}},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: {{Student}} Research Workshop},
  author = {Hamborg, Felix},
  date = {2020},
  pages = {79--87},
  url = {https://aclanthology.org/2020.acl-srw.12/},
  urldate = {2023-09-27},
  file = {/home/ral/Zotero/storage/AF6H2DDL/Hamborg - 2020 - Media bias, the social sciences, and NLP Automating frame analyses to identify bias by word choice.pdf}
}

@online{hamilton23,
  title = {Blind {{Judgement}}: {{Agent-Based Supreme Court Modelling With GPT}}},
  shorttitle = {Blind {{Judgement}}},
  author = {Hamilton, Sil},
  date = {2023-01-12},
  eprint = {2301.05327},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2301.05327},
  urldate = {2023-09-27},
  abstract = {We present a novel Transformer-based multi-agent system for simulating the judicial rulings of the 2010-2016 Supreme Court of the United States. We train nine separate models with the respective authored opinions of each supreme justice active ca. 2015 and test the resulting system on 96 real-world cases. We find our system predicts the decisions of the real-world Supreme Court with better-than-random accuracy. We further find a correlation between model accuracy with respect to individual justices and their alignment between legal conservatism \& liberalism. Our methods and results hold significance for researchers interested in using language models to simulate politically-charged discourse between multiple agents.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/home/ral/Zotero/storage/7YKN9MUP/Hamilton - 2023 - Blind Judgement Agent-Based Supreme Court Modelling With GPT.pdf}
}

@article{hansen_etal22,
  title = {How to Conduct a Meta-Analysis in Eight Steps: A Practical Guide},
  shorttitle = {How to Conduct a Meta-Analysis in Eight Steps},
  author = {Hansen, Christopher and Steinmetz, Holger and Block, Jörn},
  date = {2022-02-01},
  journaltitle = {Management Review Quarterly},
  shortjournal = {Manag Rev Q},
  volume = {72},
  number = {1},
  pages = {1--19},
  issn = {2198-1639},
  doi = {10.1007/s11301-021-00247-4},
  url = {https://doi.org/10.1007/s11301-021-00247-4},
  urldate = {2023-10-06},
  langid = {english},
  annotation = {65 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/6BY9FXDM/Hansen et al. - 2022 - How to conduct a meta-analysis in eight steps a practical guide.pdf}
}

@article{hartmann_etal23,
  title = {The Political Ideology of Conversational {{AI}}: {{Converging}} Evidence on {{ChatGPT}}’s pro-Environmental, Left-Libertarian Orientation},
  shorttitle = {The Political Ideology of Conversational {{AI}}},
  author = {Hartmann, Jochen and Schwenzow, Jasper and Witte, Maximilian},
  date = {2023},
  journaltitle = {SSRN Electronic Journal},
  langid = {english},
  file = {/home/ral/Zotero/storage/F3AKXZPX/Hartmann et al_2023_The political ideology of conversational AI.pdf}
}

@article{heyde_etal24,
  title = {Assessing {{Bias}} in {{LLM-Generated Synthetic Datasets}}: {{The Case}} of {{German Voter Behavior}}},
  shorttitle = {Assessing {{Bias}} in {{LLM-Generated Synthetic Datasets}}},
  author = {family=Heyde, given=Leah, prefix=von der, useprefix=false and Haensch, Anna-Carolina and Wenz, Alexander},
  date = {2024-01-02},
  publisher = {OSF},
  doi = {10.31235/osf.io/97r8s},
  url = {https://osf.io/97r8s},
  urldate = {2024-01-02},
  abstract = {The rise of large language models (LLMs) like GPT-3 has sparked interest in their potential for creating synthetic datasets, particularly in the realm of privacy research. This study critically evaluates the use of LLMs in generating synthetic public opinion data, pointing out the biases inherent in the data generation process. While LLMs, trained on vast internet datasets, can mimic societal attitudes and behaviors, their application in synthesizing data poses significant privacy and accuracy challenges. We investigate these issues using the case of vote choice prediction in the 2017 German federal elections. Employing GPT-3, we construct synthetic personas based on the German Longitudinal Election Study, prompting the LLM to predict voting behavior. Our analysis compares these LLM-generated predictions with actual survey data, focusing on the implications of using such synthetic data and the biases it may contain. The results demonstrate GPT-3’s propensity to inaccurately predict voter choices, with biases favoring certain political groups and more predictable voter profiles. This outcome raises critical questions about the reliability and ethical use of LLMs in generating synthetic data.},
  langid = {american},
  annotation = {0 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/66SHKSMT/Heyde et al. - 2024 - Assessing Bias in LLM-Generated Synthetic Datasets.pdf;/home/ral/Zotero/storage/UB7D8FRX/97r8s.html}
}

@book{higgins_etal24,
  title = {Cochrane {{Handbook}} for {{Systematic Reviews}} of {{Interventions}}},
  author = {Higgins, Julian P. T. and Thomas, James and Chandler, Jacqueline and Cumpston, Miranda and Li, Tianjing and Page, Matthew J. and Welch, Vivian A.},
  date = {2024},
  series = {Wiley {{Cochrane}}},
  edition = {2nd ed},
  publisher = {John Wiley \& Sons, Incorporated},
  location = {Newark},
  abstract = {"Systematic reviews summarise primary research. They are central to the evidence- based medicine movement and are widely acknowledged as the best form of evidence on which to base healthcare decisions. The Cochrane Collaboration exists to produce systematic reviews of healthcare treatments. To be reliable, systematic reviews should be conducted to the highest level of scientific rigour. This book enables Cochrane and other systematic review authors to do this and to ensure their review is of the highest quality and avoid methodological pitfalls"--},
  isbn = {978-1-119-53662-8 978-1-119-53661-1},
  langid = {english},
  pagetotal = {1},
  file = {/home/ral/Zotero/storage/YUAV6335/Higgins et al. - 2024 - Cochrane Handbook for Systematic Reviews of Interventions.pdf}
}

@article{hill-yardin_etal23,
  title = {A {{Chat}}({{GPT}}) about the Future of Scientific Publishing},
  author = {Hill-Yardin, Elisa L. and Hutchinson, Mark R. and Laycock, Robin and Spencer, Sarah J.},
  date = {2023-05},
  journaltitle = {Brain, Behavior, and Immunity},
  shortjournal = {Brain, Behavior, and Immunity},
  volume = {110},
  pages = {152--154},
  issn = {08891591},
  doi = {10.1016/j.bbi.2023.02.022},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0889159123000533},
  urldate = {2023-09-26},
  langid = {english},
  annotation = {137 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/CPAVMKAG/Hill-Yardin et al. - 2023 - A Chat(GPT) about the future of scientific publishing.pdf}
}

@article{hopkins_king10,
  title = {A {{Method}} of {{Automated Nonparametric Content Analysis}} for {{Social Science}}},
  author = {Hopkins, Daniel J. and King, Gary},
  date = {2010-01},
  journaltitle = {American Journal of Political Science},
  volume = {54},
  number = {1},
  pages = {229--247},
  issn = {00925853, 15405907},
  doi = {10.1111/j.1540-5907.2009.00428.x},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1540-5907.2009.00428.x},
  urldate = {2023-09-27},
  langid = {english},
  annotation = {460 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/U5SIVVHY/Hopkins and King - 2010 - A Method of Automated Nonparametric Content Analysis for Social Science.pdf}
}

@article{horton_etal22,
  title = {The {{Growing Importance}} of {{Reproducibility}} and {{Responsible Workflow}} in the {{Data Science}} and {{Statistics Curriculum}}},
  author = {Horton, Nicholas J. and Alexander, Rohan and Parker, Micaela and Piekut, Aneta and Rundel, Colin},
  date = {2022-11-18},
  journaltitle = {Journal of Statistics and Data Science Education},
  volume = {30},
  number = {3},
  pages = {207--208},
  publisher = {Taylor \& Francis},
  issn = {null},
  doi = {10.1080/26939169.2022.2141001},
  url = {https://doi.org/10.1080/26939169.2022.2141001},
  urldate = {2024-12-18},
  file = {/home/ral/Zotero/storage/73YM3QPI/Horton et al. - 2022 - The Growing Importance of Reproducibility and Responsible Workflow in the Data Science and Statistic.pdf}
}

@online{hou_etal23,
  title = {Large {{Language Models}} for {{Software Engineering}}: {{A Systematic Literature Review}}},
  shorttitle = {Large {{Language Models}} for {{Software Engineering}}},
  author = {Hou, Xinyi and Zhao, Yanjie and Liu, Yue and Yang, Zhou and Wang, Kailong and Li, Li and Luo, Xiapu and Lo, David and Grundy, John and Wang, Haoyu},
  date = {2023-09-12},
  eprint = {2308.10620},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2308.10620},
  urldate = {2023-09-27},
  abstract = {Large Language Models (LLMs) have significantly impacted numerous domains, including Software Engineering (SE). Many recent publications have explored LLMs applied to various SE tasks. Nevertheless, a comprehensive understanding of the application, effects, and possible limitations of LLMs on SE is still in its early stages. To bridge this gap, we conducted a systematic literature review on LLM4SE, with a particular focus on understanding how LLMs can be exploited to optimize processes and outcomes. We collect and analyze 229 research papers from 2017 to 2023 to answer four key research questions (RQs). In RQ1, we categorize different LLMs that have been employed in SE tasks, characterizing their distinctive features and uses. In RQ2, we analyze the methods used in data collection, preprocessing, and application highlighting the role of well-curated datasets for successful LLM for SE implementation. RQ3 investigates the strategies employed to optimize and evaluate the performance of LLMs in SE. Finally, RQ4 examines the specific SE tasks where LLMs have shown success to date, illustrating their practical contributions to the field. From the answers to these RQs, we discuss the current state-of-the-art and trends, identifying gaps in existing research, and flagging promising areas for future study.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Software Engineering},
  file = {/home/ral/Zotero/storage/IAYUB5HK/Hou et al. - 2023 - Large Language Models for Software Engineering A Systematic Literature Review.pdf}
}

@article{hu23,
  entrysubtype = {newspaper},
  title = {{{ChatGPT}} Sets Record for Fastest-Growing User Base - Analyst Note},
  author = {Hu, Krystal},
  date = {2023},
  journaltitle = {Reuters},
  url = {https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/},
  abstract = {ChatGPT, the popular chatbot from OpenAI, is estimated to have reached 100 million monthly active users in January, just two months after launch, making it the fastest-growing consumer application in history, according to a UBS study on Wednesday.},
  journalsubtitle = {Technology},
  langid = {english},
  keywords = {notion},
  file = {/home/ral/Zotero/storage/DSKE6M4G/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01.html}
}

@article{imran_almusharraf23,
  title = {Analyzing the Role of {{ChatGPT}} as a Writing Assistant at Higher Education Level: {{A}} Systematic Review of the Literature},
  shorttitle = {Analyzing the Role of {{ChatGPT}} as a Writing Assistant at Higher Education Level},
  author = {Imran, Muhammad and Almusharraf, Norah},
  date = {2023},
  journaltitle = {Contemporary Educational Technology},
  volume = {15},
  number = {4},
  pages = {ep464},
  publisher = {Bastas},
  url = {https://www.cedtech.net/article/analyzing-the-role-of-chatgpt-as-a-writing-assistant-at-higher-education-level-a-systematic-review-13605},
  urldate = {2023-09-27},
  file = {/home/ral/Zotero/storage/MXEKKANQ/Imran and Almusharraf - 2023 - Analyzing the role of ChatGPT as a writing assistant at higher education level A systematic review.pdf}
}

@article{irving_askell19,
  title = {{{AI Safety Needs Social Scientists}}},
  author = {Irving, Geoffrey and Askell, Amanda},
  date = {2019-02-19},
  journaltitle = {Distill},
  shortjournal = {Distill},
  volume = {4},
  number = {2},
  pages = {e14},
  issn = {2476-0757},
  doi = {10.23915/distill.00014},
  url = {https://distill.pub/2019/safety-needs-social-scientists},
  urldate = {2023-09-26},
  abstract = {If we want to train AI to do what humans want, we need to study humans.},
  langid = {english},
  annotation = {23 citations (Crossref/DOI) [2024-10-14]}
}

@article{iyengar96,
  title = {Framing {{Responsibility}} for {{Political Issues}}},
  author = {Iyengar, Shanto},
  date = {1996-07-01},
  journaltitle = {The ANNALS of the American Academy of Political and Social Science},
  volume = {546},
  number = {1},
  pages = {59--70},
  publisher = {SAGE Publications Inc},
  issn = {0002-7162},
  doi = {10.1177/0002716296546001006},
  url = {https://doi.org/10.1177/0002716296546001006},
  urldate = {2024-06-06},
  abstract = {This article examines the influence of television news on viewers' attributions of responsibility for political issues. Television's systematic reliance on episodic as opposed to thematic depictions of political life elicits individualistic attributions of responsibility for national problems such as poverty and terrorism. These attributions emphasize the actions of private rather than governmental actors. By obscuring the connections between political problems and the actions or inactions of political leaders, television news trivializes political discourse and weakens the accountability of elected officials.},
  langid = {english},
  annotation = {268 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/FMP7EUZR/Iyengar - 1996 - Framing Responsibility for Political Issues.pdf}
}

@online{j_etal24,
  title = {Fine {{Tuning LLM}} for {{Enterprise}}: {{Practical Guidelines}} and {{Recommendations}}},
  shorttitle = {Fine {{Tuning LLM}} for {{Enterprise}}},
  author = {J, Mathav Raj and Vm, Kushala and Warrier, Harikrishna and Gupta, Yogesh},
  date = {2024-03-23},
  url = {https://arxiv.org/abs/2404.10779v1},
  urldate = {2024-10-26},
  abstract = {There is a compelling necessity from enterprises for fine tuning LLMs (Large Language Models) o get them trained on proprietary domain knowledge. The challenge is to imbibe the LLMs with domain specific knowledge using the most optimial resource and cost and in the best possible time. Many enterprises rely on RAG (Retrieval Augmented Generation) which does not need LLMs to be ine-tuned but they are limited by the quality of vector databases and their retrieval capabilities rather than the intrinsic capabilities of the LLMs themselves. In our current work we focus on fine tuning LLaMA, an open source LLM using proprietary documents and code from an enterprise repository and use the fine tuned models to evaluate the quality of responses. As part of this work, we aim to guide beginners on how to start with fine tuning an LLM for documentation and code by making educated guesses on size of GPU required and options that are available for formatting the data. We also propose pre processing recipes for both documentation and code to prepare dataset in different formats. The proposed methods of data preparation for document datasets are forming paragraph chunks, forming question and answer pairs and forming keyword and paragraph chunk pairs. For code dataset we propose forming summary and function pairs. Further, we qualitatively evaluate the results of the models for domain specific queries. Finally, we also propose practical guidelines and recommendations for fine tuning LLMs.},
  langid = {english},
  organization = {arXiv.org},
  file = {/home/ral/Zotero/storage/IZQ8HRFB/J et al. - 2024 - Fine Tuning LLM for Enterprise Practical Guidelines and Recommendations.pdf}
}

@online{jenny_etal23,
  title = {Navigating the {{Ocean}} of {{Biases}}: {{Political Bias Attribution}} in {{Language Models}} via {{Causal Structures}}},
  shorttitle = {Navigating the {{Ocean}} of {{Biases}}},
  author = {Jenny, David F. and Billeter, Yann and Sachan, Mrinmaya and Schölkopf, Bernhard and Jin, Zhijing},
  date = {2023-11-14},
  eprint = {2311.08605},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2311.08605},
  url = {http://arxiv.org/abs/2311.08605},
  urldate = {2023-12-23},
  abstract = {The rapid advancement of Large Language Models (LLMs) has sparked intense debate regarding their ability to perceive and interpret complex socio-political landscapes. In this study, we undertake an exploration of decision-making processes and inherent biases within LLMs, exemplified by ChatGPT, specifically contextualizing our analysis within political debates. We aim not to critique or validate LLMs' values, but rather to discern how they interpret and adjudicate "good arguments." By applying Activity Dependency Networks (ADNs), we extract the LLMs' implicit criteria for such assessments and illustrate how normative values influence these perceptions. We discuss the consequences of our findings for human-AI alignment and bias mitigation. Our code and data at https://github.com/david-jenny/LLM-Political-Study.},
  pubstate = {prepublished},
  file = {/home/ral/Zotero/storage/BE6ATGE3/Jenny et al. - 2023 - Navigating the Ocean of Biases Political Bias Att.pdf;/home/ral/Zotero/storage/ES8IDBAZ/2311.html}
}

@article{jerzak_etal23,
  title = {An Improved Method of Automated Nonparametric Content Analysis for Social Science},
  author = {Jerzak, Connor T. and King, Gary and Strezhnev, Anton},
  date = {2023},
  journaltitle = {Political Analysis},
  volume = {31},
  number = {1},
  pages = {42--58},
  publisher = {Cambridge University Press},
  url = {https://www.cambridge.org/core/journals/political-analysis/article/an-improved-method-of-automated-nonparametric-content-analysis-for-social-science/D3C7441B17313F6E33A7BF2E781B5086},
  urldate = {2023-09-27}
}

@online{jiang_etal23,
  title = {Mistral {{7B}}},
  author = {Jiang, Albert Q. and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and family=Casas, given=Diego, prefix=de las, useprefix=false and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and Lavaud, Lélio Renard and Lachaux, Marie-Anne and Stock, Pierre and Scao, Teven Le and Lavril, Thibaut and Wang, Thomas and Lacroix, Timothée and Sayed, William El},
  date = {2023-10-10},
  eprint = {2310.06825},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2310.06825},
  url = {http://arxiv.org/abs/2310.06825},
  urldate = {2024-06-04},
  abstract = {We introduce Mistral 7B v0.1, a 7-billion-parameter language model engineered for superior performance and efficiency. Mistral 7B outperforms Llama 2 13B across all evaluated benchmarks, and Llama 1 34B in reasoning, mathematics, and code generation. Our model leverages grouped-query attention (GQA) for faster inference, coupled with sliding window attention (SWA) to effectively handle sequences of arbitrary length with a reduced inference cost. We also provide a model fine-tuned to follow instructions, Mistral 7B -- Instruct, that surpasses the Llama 2 13B -- Chat model both on human and automated benchmarks. Our models are released under the Apache 2.0 license.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/ral/Zotero/storage/C6G277ZT/Jiang et al_2023_Mistral 7B.pdf;/home/ral/Zotero/storage/KT9ICMPL/2310.html}
}

@online{johnson_etal22,
  title = {The {{Ghost}} in the {{Machine}} Has an {{American}} Accent: Value Conflict in {{GPT-3}}},
  shorttitle = {The {{Ghost}} in the {{Machine}} Has an {{American}} Accent},
  author = {Johnson, Rebecca L. and Pistilli, Giada and Menédez-González, Natalia and Duran, Leslye Denisse Dias and Panai, Enrico and Kalpokiene, Julija and Bertulfo, Donald Jay},
  date = {2022-03-15},
  eprint = {2203.07785},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2203.07785},
  urldate = {2023-11-24},
  abstract = {The alignment problem in the context of large language models must consider the plurality of human values in our world. Whilst there are many resonant and overlapping values amongst the world's cultures, there are also many conflicting, yet equally valid, values. It is important to observe which cultural values a model exhibits, particularly when there is a value conflict between input prompts and generated outputs. We discuss how the co-creation of language and cultural value impacts large language models (LLMs). We explore the constitution of the training data for GPT-3 and compare that to the world's language and internet access demographics, as well as to reported statistical profiles of dominant values in some Nation-states. We stress tested GPT-3 with a range of value-rich texts representing several languages and nations; including some with values orthogonal to dominant US public opinion as reported by the World Values Survey. We observed when values embedded in the input text were mutated in the generated outputs and noted when these conflicting values were more aligned with reported dominant US values. Our discussion of these results uses a moral value pluralism (MVP) lens to better understand these value mutations. Finally, we provide recommendations for how our work may contribute to other current work in the field.},
  pubstate = {prepublished},
  file = {/home/ral/Zotero/storage/IJFBFY4J/Johnson et al_2022_The Ghost in the Machine has an American accent.pdf;/home/ral/Zotero/storage/FTPUZFGS/2203.html}
}

@book{johnston17,
  title = {The {{Canadian}} Party System: {{An}} Analytic History},
  author = {Johnston, Richard},
  date = {2017},
  publisher = {UBC Press},
  file = {/home/ral/Zotero/storage/9UIVGNV9/Johnston - 2017 - The Canadian party system an analytic history.pdf}
}

@article{joshi_etal15,
  title = {Likert {{Scale}}: {{Explored}} and {{Explained}}},
  shorttitle = {Likert {{Scale}}},
  author = {Joshi, Ankur and Kale, Saket and Chandel, Satish and Pal, D.},
  date = {2015-01-10},
  journaltitle = {British Journal of Applied Science \& Technology},
  shortjournal = {BJAST},
  volume = {7},
  number = {4},
  pages = {396--403},
  issn = {22310843},
  doi = {10.9734/BJAST/2015/14975},
  url = {https://journalcjast.com/index.php/CJAST/article/view/381},
  urldate = {2024-06-01},
  abstract = {Likert scale is applied as one of the most fundamental and frequently used psychometric tools in educational and social sciences research. Simultaneously, it is also subjected to a lot of debates and controversies in regards with the analysis and inclusion of points on the scale. With this context, through reviewing the available literature and then clubbing the received information with coherent scientific thinking, this paper attempts to gradually build a construct around Likert scale. This analytical review begins with the necessity of psychometric tools like Likert scale andits variants and focuses on some convoluted issues like validity, reliability and analysis of the scale.},
  langid = {english},
  annotation = {1283 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/T2CIRCMG/Joshi et al. - 2015 - Likert Scale Explored and Explained.pdf}
}

@article{karimi_etal15,
  title = {Text and {{Data Mining Techniques}} in {{Adverse Drug Reaction Detection}}},
  author = {Karimi, Sarvnaz and Wang, Chen and Metke-Jimenez, Alejandro and Gaire, Raj and Paris, Cecile},
  date = {2015-07-21},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  volume = {47},
  number = {4},
  pages = {1--39},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/2719920},
  url = {https://dl.acm.org/doi/10.1145/2719920},
  urldate = {2023-09-27},
  abstract = {We review data mining and related computer science techniques that have been studied in the area of drug safety to identify signals of adverse drug reactions from different data sources, such as spontaneous reporting databases, electronic health records, and medical literature. Development of such techniques has become more crucial for public heath, especially with the growth of data repositories that include either reports of adverse drug reactions, which require fast processing for discovering signals of adverse reactions, or data sources that may contain such signals but require data or text mining techniques to discover them. In order to highlight the importance of contributions made by computer scientists in this area so far, we categorize and review the existing approaches, and most importantly, we identify areas where more research should be undertaken.},
  langid = {english},
  annotation = {128 citations (Semantic Scholar/DOI) [2024-10-14]\\
92 citations (Crossref/DOI) [2024-10-14]}
}

@online{kibbee23,
  title = {A {{Guide}} to {{Evidence Synthesis}}:},
  shorttitle = {{{LibGuides}}},
  author = {Kibbee, Matthew},
  date = {2023},
  url = {https://guides.library.cornell.edu/evidence-synthesis/service},
  urldate = {2023-10-06},
  abstract = {LibGuides: A Guide to Evidence Synthesis: Cornell University Library Evidence Synthesis Service},
  langid = {english},
  organization = {Cornell University Library Evidence Synthesis Service},
  file = {/home/ral/Zotero/storage/M95P5VUK/ld.pdf;/home/ral/Zotero/storage/IYEDR5V2/service.html}
}

@article{kim_etal10,
  title = {Electoral Systems, Party Systems, and Ideological Representation: An Analysis of Distortion in Western Democracies},
  shorttitle = {Electoral Systems, Party Systems, and Ideological Representation},
  author = {Kim, HeeMin and Powell Jr, G. Bingham and Fording, Richard C.},
  date = {2010},
  journaltitle = {Comparative Politics},
  volume = {42},
  number = {2},
  pages = {167--185},
  publisher = {City University of New York},
  url = {https://www.ingentaconnect.com/content/cuny/cp/2010/00000042/00000002/art00003},
  urldate = {2023-11-16},
  file = {/home/ral/Zotero/storage/WTHNHVHC/Kim et al. - 2010 - Electoral systems, party systems, and ideological .pdf}
}

@online{kim_etal24,
  title = {Aligning {{Language Models}} to {{Explicitly Handle Ambiguity}}},
  author = {Kim, Hyuhng Joon and Kim, Youna and Park, Cheonbok and Kim, Junyeob and Park, Choonghyun and Yoo, Kang Min and Lee, Sang-goo and Kim, Taeuk},
  date = {2024-10-04},
  eprint = {2404.11972},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2404.11972},
  url = {http://arxiv.org/abs/2404.11972},
  urldate = {2024-10-26},
  abstract = {In interactions between users and language model agents, user utterances frequently exhibit ellipsis (omission of words or phrases) or imprecision (lack of exactness) to prioritize efficiency. This can lead to varying interpretations of the same input based on different assumptions or background knowledge. It is thus crucial for agents to adeptly handle the inherent ambiguity in queries to ensure reliability. However, even state-of-the-art large language models (LLMs) still face challenges in such scenarios, primarily due to the following hurdles: (1) LLMs are not explicitly trained to deal with ambiguous utterances; (2) the degree of ambiguity perceived by the LLMs may vary depending on the possessed knowledge. To address these issues, we propose Alignment with Perceived Ambiguity (APA), a novel pipeline that aligns LLMs to manage ambiguous queries by leveraging their own assessment of ambiguity (i.e., perceived ambiguity). Experimental results on question-answering datasets demonstrate that APA empowers LLMs to explicitly detect and manage ambiguous queries while retaining the ability to answer clear questions. Furthermore, our finding proves that APA excels beyond training with gold-standard labels, especially in out-of-distribution scenarios. The data and code are available at https://github.com/heyjoonkim/APA.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/home/ral/Zotero/storage/XEQAXNIX/Kim et al. - 2024 - Aligning Language Models to Explicitly Handle Ambiguity.pdf;/home/ral/Zotero/storage/9YRVH85S/2404.html}
}

@article{kim_lee23,
  title = {How Does {{ChatGPT Introduce Transport Problems}} and {{Solutions}} in {{North America}}?},
  author = {Kim, Junghwan and Lee, Jinhyung},
  date = {2023},
  journaltitle = {Findings},
  abstract = {How does ChatGPT introduce transport problems and solutions in North America? By analyzing ChatGPT’s answers to four prompts related to transport issues and solutions in the United States and Canada, our results reveal that ChatGPT’s answers generally align well with transport researchers’ expectations. However, ChatGPT’s capability may be limited in providing trustworthy or sound solutions because of the potential issues (e.g., geographic biases, inaccuracy) in its training data. ChatGPT might be a decent starting point for discussing transport issues and solutions, but one should be aware of its limitations.},
  langid = {english},
  file = {/home/ral/Zotero/storage/C3LH3S47/Kim_Lee_2023_How does ChatGPT Introduce Transport Problems and Solutions in North America.pdf}
}

@article{king_etal09,
  title = {The {{Automation}} of {{Science}}},
  author = {King, Ross D. and Rowland, Jem and Oliver, Stephen G. and Young, Michael and Aubrey, Wayne and Byrne, Emma and Liakata, Maria and Markham, Magdalena and Pir, Pinar and Soldatova, Larisa N. and Sparkes, Andrew and Whelan, Kenneth E. and Clare, Amanda},
  date = {2009-04-03},
  journaltitle = {Science},
  shortjournal = {Science},
  volume = {324},
  number = {5923},
  pages = {85--89},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1165620},
  url = {https://www.science.org/doi/10.1126/science.1165620},
  urldate = {2023-12-06},
  abstract = {The basis of science is the hypothetico-deductive method and the recording of experiments in sufficient detail to enable reproducibility. We report the development of Robot Scientist “Adam,” which advances the automation of both. Adam has autonomously generated functional genomics hypotheses about the yeast Saccharomyces cerevisiae and experimentally tested these hypotheses by using laboratory automation. We have confirmed Adam's conclusions through manual experiments. To describe Adam's research, we have developed an ontology and logical language. The resulting formalization involves over 10,000 different research units in a nested treelike structure, 10 levels deep, that relates the 6.6 million biomass measurements to their logical description. This formalization describes how a machine contributed to scientific knowledge.},
  langid = {english},
  annotation = {411 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/4DEEXCN8/King et al. - 2009 - The Automation of Science.pdf}
}

@book{king_etal94,
  title = {Designing Social Inquiry: Scientific Inference in Qualitative Research},
  shorttitle = {Designing Social Inquiry},
  author = {King, Gary and Keohane, Robert O. and Verba, Sidney},
  date = {1994},
  publisher = {Princeton University Press},
  location = {Princeton, N.J},
  isbn = {978-0-691-03470-6 978-0-691-03471-3},
  langid = {english},
  pagetotal = {245},
  keywords = {Inference,Methodology,notion,Qualitative research,Research,Social sciences},
  file = {/home/ral/Zotero/storage/U8GSWMQP/King et al. - 1994 - Designing social inquiry scientific inference in .pdf}
}

@article{knopf06,
  title = {Doing a {{Literature Review}}},
  author = {Knopf, Jeffrey W.},
  date = {2006-01},
  journaltitle = {PS: Political Science \& Politics},
  shortjournal = {APSC},
  volume = {39},
  number = {1},
  pages = {127--132},
  issn = {1049-0965, 1537-5935},
  doi = {10.1017/S1049096506060264},
  url = {https://www.cambridge.org/core/product/identifier/S1049096506060264/type/journal_article},
  urldate = {2023-09-14},
  abstract = {Students entering a graduate program often encounter a new type of assignment that differs from the papers they had to write in high school or as college undergraduates: the literature review (also known as a critical review essay). Put briefly, a literature review summarizes and evaluates a body of writings about a specific topic. The need to conduct such reviews is by no means limited to graduate students; scholarly researchers generally carry out literature reviews throughout their research careers. In a world where the Internet has broadened the range of potentially relevant sources, however, doing a literature review can pose challenges even to an experienced researcher. In drafting this overview, I have incorporated some points made by Paul Pitman in a lecture delivered to students at the Naval Postgraduate School. I have also incorporated some suggestions contained in a handout prepared by John Odell for students in the School of International Relations at the University of Southern California.},
  langid = {english},
  annotation = {81 citations (Crossref/DOI) [2024-10-14]}
}

@online{kojima_etal23,
  title = {Large {{Language Models}} Are {{Zero-Shot Reasoners}}},
  author = {Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  date = {2023-01-29},
  eprint = {2205.11916},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2205.11916},
  url = {http://arxiv.org/abs/2205.11916},
  urldate = {2024-01-07},
  abstract = {Pretrained large language models (LLMs) are widely used in many sub-fields of natural language processing (NLP) and generally known as excellent few-shot learners with task-specific exemplars. Notably, chain of thought (CoT) prompting, a recent technique for eliciting complex multi-step reasoning through step-by-step answer examples, achieved the state-of-the-art performances in arithmetics and symbolic reasoning, difficult system-2 tasks that do not follow the standard scaling laws for LLMs. While these successes are often attributed to LLMs' ability for few-shot learning, we show that LLMs are decent zero-shot reasoners by simply adding "Let's think step by step" before each answer. Experimental results demonstrate that our Zero-shot-CoT, using the same single prompt template, significantly outperforms zero-shot LLM performances on diverse benchmark reasoning tasks including arithmetics (MultiArith, GSM8K, AQUA-RAT, SVAMP), symbolic reasoning (Last Letter, Coin Flip), and other logical reasoning tasks (Date Understanding, Tracking Shuffled Objects), without any hand-crafted few-shot examples, e.g. increasing the accuracy on MultiArith from 17.7\% to 78.7\% and GSM8K from 10.4\% to 40.7\% with large InstructGPT model (text-davinci-002), as well as similar magnitudes of improvements with another off-the-shelf large model, 540B parameter PaLM. The versatility of this single prompt across very diverse reasoning tasks hints at untapped and understudied fundamental zero-shot capabilities of LLMs, suggesting high-level, multi-task broad cognitive capabilities may be extracted by simple prompting. We hope our work not only serves as the minimal strongest zero-shot baseline for the challenging reasoning benchmarks, but also highlights the importance of carefully exploring and analyzing the enormous zero-shot knowledge hidden inside LLMs before crafting finetuning datasets or few-shot exemplars.},
  pubstate = {prepublished},
  file = {/home/ral/Zotero/storage/FHF2YFJK/Kojima et al_2023_Large Language Models are Zero-Shot Reasoners.pdf;/home/ral/Zotero/storage/PVX3N5UU/2205.html}
}

@article{koo23,
  title = {The {{Importance}} of {{Proper Use}} of {{ChatGPT}} in {{Medical Writing}}},
  author = {Koo, Malcolm},
  date = {2023-05-01},
  journaltitle = {Radiology},
  shortjournal = {Radiology},
  volume = {307},
  number = {3},
  pages = {e230312},
  issn = {0033-8419, 1527-1315},
  doi = {10.1148/radiol.230312},
  url = {http://pubs.rsna.org/doi/10.1148/radiol.230312},
  urldate = {2023-09-27},
  langid = {english},
  annotation = {30 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/EKES5P2X/Koo - 2023 - The Importance of Proper Use of ChatGPT in Medical Writing.pdf}
}

@article{krippendorff04,
  title = {Measuring the Reliability of Qualitative Text Analysis Data},
  author = {Krippendorff, Klaus},
  date = {2004},
  journaltitle = {Quality and quantity},
  volume = {38},
  pages = {787--800},
  publisher = {Springer},
  url = {https://idp.springer.com/authorize/casa?redirect_uri=https://link.springer.com/article/10.1007/s11135-004-8107-7&casa_token=YCPBwHn5Nr0AAAAA:tEZ7fHij2wA4kNIIu98rf1N5J7CRbHU1oIt9WryvOn-NX2MDV6LUIBPUbehofL1YzX2Wz_m9Z5xVASu9},
  urldate = {2023-09-27}
}

@unpublished{krugel_etal23,
  title = {The Moral Authority of {{ChatGPT}}},
  author = {Krügel, Sebastian and {ostermaier}, Andreas and Uhl, Matthias},
  date = {2023},
  eprint = {2301.07098},
  eprinttype = {arXiv},
  file = {/home/ral/Zotero/storage/NQAT3UF8/Krügel et al_2023_The moral authority of ChatGPT.pdf}
}

@book{kuhn_hacking12,
  title = {The Structure of Scientific Revolutions},
  author = {Kuhn, Thomas S. and Hacking, Ian},
  date = {2012},
  edition = {Fourth edition},
  publisher = {The University of Chicago Press},
  location = {Chicago ; London},
  isbn = {978-0-226-45811-3 978-0-226-45812-0},
  pagetotal = {217},
  keywords = {History,Philosophy,Science}
}

@article{kureha23,
  title = {Implications of {{Automating Science}}: {{The Possibility}} of {{Artificial Creativity}} and the {{Future}} of {{Science}}},
  shorttitle = {Implications of {{Automating Science}}},
  author = {Kureha, Makoto},
  date = {2023},
  url = {https://philpapers.org/rec/KURIOA-2},
  urldate = {2023-09-27}
}

@book{lagroye_etal12,
  title = {Sociologie politique},
  author = {Lagroye, Jacques and François, Bastien and Sawicki, Frédéric},
  date = {2012},
  series = {Amphi},
  edition = {6e éd. revue et augmentée},
  publisher = {Presses de Sciences po Dalloz},
  location = {Paris},
  isbn = {978-2-7246-1251-6 978-2-247-11207-4},
  langid = {fre}
}

@article{lau19,
  title = {Editorial: {{Systematic}} Review Automation Thematic Series},
  shorttitle = {Editorial},
  author = {Lau, Joseph},
  date = {2019-03-11},
  journaltitle = {Systematic Reviews},
  shortjournal = {Syst Rev},
  volume = {8},
  number = {1},
  pages = {70},
  issn = {2046-4053},
  doi = {10.1186/s13643-019-0974-z},
  url = {https://doi.org/10.1186/s13643-019-0974-z},
  urldate = {2023-09-26},
  langid = {english},
  annotation = {15 citations (Semantic Scholar/DOI) [2024-10-14]\\
18 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/QFM84HCK/Lau - 2019 - Editorial Systematic review automation thematic series.pdf}
}

@book{lees-marshment01,
  title = {Political {{Marketing}} and {{British Political Parties}}: {{The Party}}'s {{Just Begun}}},
  shorttitle = {Political {{Marketing}} and {{British Political Parties}}},
  author = {Lees-Marshment, Jennifer},
  date = {2001},
  eprint = {U7DnfqMdmUYC},
  eprinttype = {googlebooks},
  publisher = {Manchester University Press},
  abstract = {This work demonstrates how British political parties now have to use sophisticated political marketing techniques in order to gain electoral success. By conducting focus groups and opinion polls, parties attempt to find out what it is that voters want from them - they then change their behaviour and political stance in order to reflect their findings. The summer of 2000 provided classic examples of this type of behaviour in action, with William Hague and Tony Blair sending out conflicting and confusing soundbites in an attempt to capture the popular imagination on issues such as pensions, asylum seekers and the pound.},
  isbn = {978-0-7190-6017-5},
  langid = {english},
  pagetotal = {270}
}

@book{lemieux05,
  title = {Les partis et leurs transformations: le dilemme de la participation},
  shorttitle = {Les partis et leurs transformations},
  author = {Lemieux, Vincent},
  date = {2005},
  publisher = {Les Presses de l'Université de Laval},
  location = {Québec},
  isbn = {978-2-7637-8126-6},
  langid = {fre},
  file = {/home/ral/Zotero/storage/AKAD7FDS/Lemieux_2005_Les partis et leurs transformations.pdf}
}

@article{levin_etal23,
  title = {Identifying {{ChatGPT-written OBGYN}} Abstracts Using a Simple Tool},
  author = {Levin, Gabriel and Meyer, Raanan and Kadoch, Eva and Brezinov, Yoav},
  date = {2023},
  journaltitle = {American Journal of Obstetrics \& Gynecology MFM},
  volume = {5},
  number = {6},
  publisher = {Elsevier},
  url = {https://www.ajogmfm.org/article/S2589-9333(23)00078-2/abstract},
  urldate = {2023-09-27}
}

@book{lichbach_zuckerman97,
  title = {Comparative Politics: Rationality, Culture, and Structure},
  shorttitle = {Comparative Politics},
  author = {Lichbach, Mark Irving and Zuckerman, Alan S.},
  date = {1997},
  edition = {2nd ed},
  publisher = {Cambridge University Press},
  location = {Cambridge},
  abstract = {This collection of essays reassesses rational choice theory, culturalist analysis, and structuralist approaches to comparative politics},
  isbn = {978-1-139-12967-1},
  langid = {english},
  annotation = {OCLC: 774691645},
  file = {/home/ral/Zotero/storage/C2JCLBQY/Lichbach and Zuckerman - Comparative Politics.pdf}
}

@article{lichtenstein_rucks-ahidiana23,
  title = {Contextual {{Text Coding}}: {{A Mixed-methods Approach}} for {{Large-scale Textual Data}}},
  shorttitle = {Contextual {{Text Coding}}},
  author = {Lichtenstein, Matty and Rucks-Ahidiana, Zawadi},
  date = {2023-05},
  journaltitle = {Sociological Methods \& Research},
  shortjournal = {Sociological Methods \& Research},
  volume = {52},
  number = {2},
  pages = {606--641},
  issn = {0049-1241, 1552-8294},
  doi = {10.1177/0049124120986191},
  url = {http://journals.sagepub.com/doi/10.1177/0049124120986191},
  urldate = {2023-09-27},
  abstract = {With the growing availability of large-scale text-based data sets, there is an increasing need for an accessible and systematic way to analyze qualitative texts. This article introduces and details the contextual text coding (CTC) method as a mixed-methods approach to large-scale qualitative data analysis. The method is particularly useful for complex text, textual data characterized by context-specific meanings and a lack of consistent terminology. CTC provides an alternative to current approaches to analyzing large textual data sets, specifically computational text analysis and hand coding, neither of which capture both the qualitative and quantitative analytical potential of large-scale textual data sets. Building on hand coding techniques and systematic sampling methods, CTC provides a clear six-step process to produce both quantitative and qualitative analyses of large-scale complex textual data sources. This article includes two examples, using projects focusing on journal and interview data, respectively, to illustrate the method’s versatility.},
  langid = {english},
  annotation = {11 citations (Crossref/DOI) [2024-10-14]}
}

@article{liebrenz_etal23,
  title = {Generating Scholarly Content with {{ChatGPT}}: {{Ethical}} Challenges for Medical Publishing},
  shorttitle = {Generating Scholarly Content with {{ChatGPT}}},
  author = {Liebrenz, Michael and Schleifer, Roman and Buadze, Anna and Bhugra, Dinesh and Smith, Alexander},
  date = {2023-03},
  journaltitle = {The Lancet Digital Health},
  shortjournal = {The Lancet Digital Health},
  volume = {5},
  number = {3},
  pages = {e105-e106},
  issn = {25897500},
  doi = {10.1016/S2589-7500(23)00019-5},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2589750023000195},
  urldate = {2023-09-26},
  langid = {english},
  annotation = {299 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/VZYLIDY3/Liebrenz et al. - 2023 - Generating scholarly content with ChatGPT Ethical challenges for medical publishing.pdf}
}

@online{liffiton_etal23,
  title = {{{CodeHelp}}: {{Using Large Language Models}} with {{Guardrails}} for {{Scalable Support}} in {{Programming Classes}}},
  shorttitle = {{{CodeHelp}}},
  author = {Liffiton, Mark and Sheese, Brad and Savelka, Jaromir and Denny, Paul},
  date = {2023-08-13},
  eprint = {2308.06921},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2308.06921},
  urldate = {2023-09-26},
  abstract = {Computing educators face significant challenges in providing timely support to students, especially in large class settings. Large language models (LLMs) have emerged recently and show great promise for providing on-demand help at a large scale, but there are concerns that students may over-rely on the outputs produced by these models. In this paper, we introduce CodeHelp, a novel LLM-powered tool designed with guardrails to provide on-demand assistance to programming students without directly revealing solutions. We detail the design of the tool, which incorporates a number of useful features for instructors, and elaborate on the pipeline of prompting strategies we use to ensure generated outputs are suitable for students. To evaluate CodeHelp, we deployed it in a first-year computer and data science course with 52 students and collected student interactions over a 12-week period. We examine students’ usage patterns and perceptions of the tool, and we report reflections from the course instructor and a series of recommendations for classroom use. Our findings suggest that CodeHelp is well-received by students who especially value its availability and help with resolving errors, and that for instructors it is easy to deploy and complements, rather than replaces, the support that they provide to students.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computers and Society},
  file = {/home/ral/Zotero/storage/DEIDKK43/Liffiton et al. - 2023 - CodeHelp Using Large Language Models with Guardrails for Scalable Support in Programming Classes.pdf}
}

@book{lijphart12,
  title = {Patterns of Democracy: Government Forms and Performance in Thirty-Six Countries},
  shorttitle = {Patterns of Democracy},
  author = {Lijphart, Arend},
  date = {2012},
  edition = {2nd ed},
  publisher = {Yale university press},
  location = {New Haven},
  isbn = {978-0-300-17202-7},
  langid = {english},
  file = {/home/ral/Zotero/storage/KRPNXA8L/Lijphart - 2012 - Patterns of democracy government forms and performance in thirty-six countries.pdf}
}

@article{lijphart71,
  title = {Comparative {{Politics}} and the {{Comparative Method}}},
  author = {Lijphart, Arend},
  date = {1971-09},
  journaltitle = {American Political Science Review},
  volume = {65},
  number = {3},
  pages = {682--693},
  issn = {0003-0554, 1537-5943},
  doi = {10.2307/1955513},
  url = {https://www.cambridge.org/core/journals/american-political-science-review/article/comparative-politics-and-the-comparative-method/A326138E114805EF7E1B72F60EBD4295},
  urldate = {2024-09-12},
  abstract = {This paper is a systematic analysis of the comparative method. Its emphasis is on both the limitations of the method and the ways in which, despite these limitations, it can be used to maximum advantage.The comparative method is defined and analyzed in terms of its similarities and differences vis-à-vis the experimental and statistical methods. The principal difficulty facing the comparative method is that it must generalize on the basis of relatively few empirical cases. Four specific ways in which this difficulty may be resolved are discussed and illustrated: (1) increasing the number of cases as much as possible by means of longitudinal extension and a global range of analysis, (2) reducing the property space of the analysis, (3) focusing the comparative analysis on “comparable” cases (e.g., by means of area, diachronic, or intranation comparisons), and (4) focusing on the key variables.It is argued that the case study method is closely related to the comparative method. Six types of case studies (the atheoretical, interpretative, hypothesis-generating, theory-confirming, theory-infirming, and deviant case analyses) are distinguished, and their theoretical value is analyzed.},
  langid = {english},
  keywords = {Religion Quebec/ROC},
  file = {/home/ral/Zotero/storage/UVWDV3CT/Lijphart - 1971 - Comparative Politics and the Comparative Method.pdf}
}

@book{likert32,
  title = {A Technique for the Measurement of Attitudes},
  author = {Likert, R.},
  date = {1932},
  series = {A Technique for the Measurement of Attitudes},
  number = {nos. 136-165},
  publisher = {Archives of Psychology},
  url = {https://books.google.ca/books?id=9rotAAAAYAAJ},
  lccn = {33012634},
  file = {/home/ral/Zotero/storage/HQKV2UCI/Likert_1932.pdf}
}

@incollection{lipset_rokkan90,
  title = {Cleavages {{Structures}}, {{Party Systems}}, and {{Voter Alignments}}},
  booktitle = {The {{West European}} Party System},
  author = {Lipset, Seymour Martin and Rokkan, Stein},
  editor = {Mair, Peter},
  date = {1990},
  series = {Oxford Readings in Politics and Government},
  publisher = {Oxford University Press},
  location = {Oxford [England] ; New York},
  isbn = {978-0-19-827584-8 978-0-19-827583-1},
  keywords = {Europe,Political parties,Politics and government},
  file = {/home/ral/Zotero/storage/Y2FLI4I2/The West European party system.pdf}
}

@article{liu_etal22,
  title = {Quantifying and Alleviating Political Bias in Language Models},
  author = {Liu, Ruibo and Jia, Chenyan and Wei, Jason and Xu, Guangxuan and Vosoughi, Soroush},
  date = {2022},
  journaltitle = {Artificial Intelligence},
  volume = {304},
  pages = {103654},
  publisher = {Elsevier},
  url = {https://www.sciencedirect.com/science/article/pii/S0004370221002058},
  urldate = {2023-11-24},
  file = {/home/ral/Zotero/storage/C99E6HUA/Liu et al_2022_Quantifying and alleviating political bias in language models.pdf}
}

@article{LLMs_final,
  title = {Generative {{AI}} for {{Economic Research}}:{{Use Cases}} and {{Implications}} for {{Economists}}},
  author = {Korinek, Anton},
  date = {2023},
  journaltitle = {Journal of Economic Literature},
  pages = {65}
}

@inproceedings{luccioni_viviano21,
  title = {What's in the {{Box}}? {{An Analysis}} of {{Undesirable Content}} in the {{Common Crawl Corpus}}},
  shorttitle = {What's in the {{Box}}?},
  booktitle = {Proceedings of the 59th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} and the 11th {{International Joint Conference}} on {{Natural Language Processing}} ({{Volume}} 2: {{Short Papers}})},
  author = {Luccioni, Alexandra and Viviano, Joseph},
  editor = {Zong, Chengqing and Xia, Fei and Li, Wenjie and Navigli, Roberto},
  date = {2021-08},
  pages = {182--189},
  publisher = {Association for Computational Linguistics},
  location = {Online},
  doi = {10.18653/v1/2021.acl-short.24},
  url = {https://aclanthology.org/2021.acl-short.24},
  urldate = {2024-10-26},
  abstract = {Whereas much of the success of the current generation of neural language models has been driven by increasingly large training corpora, relatively little research has been dedicated to analyzing these massive sources of textual data. In this exploratory analysis, we delve deeper into the Common Crawl, a colossal web corpus that is extensively used for training language models. We find that it contains a significant amount of undesirable content, including hate speech and sexually explicit content, even after filtering procedures. We discuss the potential impacts of this content on language models and conclude with future research directions and a more mindful approach to corpus collection and analysis.},
  eventtitle = {{{ACL-IJCNLP}} 2021},
  annotation = {17 citations (Crossref/DOI) [2024-11-13]},
  file = {/home/ral/Zotero/storage/FYJ94NBI/Luccioni and Viviano - 2021 - What's in the Box An Analysis of Undesirable Content in the Common Crawl Corpus.pdf}
}

@article{lund_wang23,
  title = {Chatting about {{ChatGPT}}: {{How}} May {{AI}} and {{GPT}} Impact Academia and Libraries?},
  shorttitle = {Chatting about {{ChatGPT}}},
  author = {Lund, Brady D. and Wang, Ting},
  date = {2023-01-01},
  journaltitle = {Library Hi Tech News},
  volume = {40},
  number = {3},
  pages = {26--29},
  publisher = {Emerald Publishing Limited},
  issn = {0741-9058},
  doi = {10.1108/LHTN-01-2023-0009},
  url = {https://doi.org/10.1108/LHTN-01-2023-0009},
  urldate = {2023-09-27},
  abstract = {Purpose This paper aims to provide an overview of key definitions related to ChatGPT, a public tool developed by OpenAI, and its underlying technology, Generative Pretrained Transformer (GPT). Design/methodology/approach This paper includes an interview with ChatGPT on its potential impact on academia and libraries. The interview discusses the benefits of ChatGPT such as improving search and discovery, reference and information services; cataloging and metadata generation; and content creation, as well as the ethical considerations that need to be taken into account, such as privacy and bias. Findings ChatGPT has considerable power to advance academia and librarianship in both anxiety-provoking and exciting new ways. However, it is important to consider how to use this technology responsibly and ethically, and to uncover how we, as professionals, can work alongside this technology to improve our work, rather than to abuse it or allow it to abuse us in the race to create new scholarly knowledge and educate future professionals. Originality/value This paper discusses the history and technology of GPT, including its generative pretrained transformer model, its ability to perform a wide range of language-based tasks and how ChatGPT uses this technology to function as a sophisticated chatbot.},
  keywords = {Academia,AI,ChatGPT,Generative pretrained transformer,GPT-3,Libraries},
  annotation = {419 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/Z2GGL5FW/Lund and Wang - 2023 - Chatting about ChatGPT How may AI and GPT impact academia and libraries.pdf}
}

@article{lyell_coiera17,
  title = {Automation Bias and Verification Complexity: A Systematic Review},
  shorttitle = {Automation Bias and Verification Complexity},
  author = {Lyell, David and Coiera, Enrico},
  date = {2017-03-01},
  journaltitle = {Journal of the American Medical Informatics Association},
  shortjournal = {Journal of the American Medical Informatics Association},
  volume = {24},
  number = {2},
  pages = {423--431},
  issn = {1067-5027},
  doi = {10.1093/jamia/ocw105},
  url = {https://doi.org/10.1093/jamia/ocw105},
  urldate = {2023-09-26},
  abstract = {Introduction: While potentially reducing decision errors, decision support systems can introduce new types of errors. Automation bias (AB) happens when users become overreliant on decision support, which reduces vigilance in information seeking and processing. Most research originates from the human factors literature, where the prevailing view is that AB occurs only in multitasking environments.Objectives: This review seeks to compare the human factors and health care literature, focusing on the apparent association of AB with multitasking and task complexity.Data sources: EMBASE, Medline, Compendex, Inspec, IEEE Xplore, Scopus, Web of Science, PsycINFO, and Business Source Premiere from 1983 to 2015.Study selection: Evaluation studies where task execution was assisted by automation and resulted in errors were included. Participants needed to be able to verify automation correctness and perform the task manually.Methods: Tasks were identified and grouped. Task and automation type and presence of multitasking were noted. Each task was rated for its verification complexity.Results: Of 890 papers identified, 40 met the inclusion criteria; 6 were in health care. Contrary to the prevailing human factors view, AB was found in single tasks, typically involving diagnosis rather than monitoring, and with high verification complexity.Limitations: The literature is fragmented, with large discrepancies in how AB is reported. Few studies reported the statistical significance of AB compared to a control condition.Conclusion: AB appears to be associated with the degree of cognitive load experienced in decision tasks, and appears to not be uniquely associated with multitasking. Strategies to minimize AB might focus on cognitive load reduction.},
  annotation = {146 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/TRYUKU32/Lyell and Coiera - 2017 - Automation bias and verification complexity a systematic review.pdf}
}

@book{mace17,
  title = {Guide d'elaboration d'un Projet de Recherche. 3e Edition Revue et Augmentee},
  author = {Mace, Gordon},
  date = {2017},
  publisher = {Pr de l'université Laval},
  location = {Quebec},
  isbn = {978-2-7637-3181-0},
  langid = {english},
  keywords = {notion}
}

@online{maeda_bolanos23,
  title = {What Are {{Tokens}}?},
  author = {Maeda, John and Bolanos, Matthew},
  date = {2023},
  url = {https://learn.microsoft.com/en-us/semantic-kernel/prompt-engineering/tokens},
  urldate = {2023-07-23},
  abstract = {Tokens},
  langid = {american},
  file = {/home/ral/Zotero/storage/NQTA9JSQ/tokens.html}
}

@article{maiden_etal23,
  title = {Automating {{Science Journalism Tasks}}: {{Emerging Opportunities}}},
  shorttitle = {Automating {{Science Journalism Tasks}}},
  author = {Maiden, Neil and Zachos, Konstantinos and Franks, Suzanne and Nyre, Lars and Linden, Carl-Gustav},
  date = {2023-06-26},
  journaltitle = {Journalism Practice},
  shortjournal = {Journalism Practice},
  pages = {1--21},
  issn = {1751-2786, 1751-2794},
  doi = {10.1080/17512786.2023.2226116},
  url = {https://www.tandfonline.com/doi/full/10.1080/17512786.2023.2226116},
  urldate = {2023-09-27},
  langid = {english},
  annotation = {2 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/DEMKPNHP/Maiden et al. - 2023 - Automating Science Journalism Tasks Emerging Opportunities.pdf}
}

@article{mallett_etal12,
  title = {The Benefits and Challenges of Using Systematic Reviews in International Development Research},
  author = {Mallett, Richard and Hagen-Zanker, Jessica and Slater, Rachel and Duvendack, Maren},
  date = {2012-09-01},
  journaltitle = {Journal of Development Effectiveness},
  volume = {4},
  number = {3},
  pages = {445--455},
  publisher = {Routledge},
  issn = {1943-9342},
  doi = {10.1080/19439342.2012.711342},
  url = {https://doi.org/10.1080/19439342.2012.711342},
  urldate = {2024-10-27},
  abstract = {Although first applied in the medical sciences in the 1970s, systematic reviews have been recently, and increasingly, used in the field of international development to examine the impacts of a range of development and humanitarian interventions. However, to date, there has been only limited critical reflection on their application within this field. Drawing on the authors' first-hand experiences of conducting eight systematic reviews, this article reflects upon the use of systematic reviews in international development research. It is concluded that although using systematic review principles can help researchers improve the rigour and breadth of literature reviews, conducting a full systematic review is a resource-intensive process which involves a number of practical challenges. Further, it raises a series of fundamental concerns for those working in international development, as well as the social sciences more broadly. Ultimately, systematic reviews should be viewed as a means to finding a robust and sensible answer to a focused research question, but not as an end in themselves.},
  keywords = {evidence-based policymaking,international development research,systematic reviews},
  annotation = {350 citations (Crossref/DOI) [2024-11-13]},
  file = {/home/ral/Zotero/storage/8RRSH63E/Mallett et al. - 2012 - The benefits and challenges of using systematic reviews in international development research.pdf}
}

@article{manohar_prasad23,
  title = {Use of {{ChatGPT}} in {{Academic Publishing}}: {{A Rare Case}} of {{Seronegative Systemic Lupus Erythematosus}} in a {{Patient With HIV Infection}}},
  shorttitle = {Use of {{ChatGPT}} in {{Academic Publishing}}},
  author = {Manohar, Naveen and Prasad, Shruthi S},
  date = {2023-02-04},
  journaltitle = {Curēus},
  shortjournal = {Cureus},
  issn = {2168-8184},
  doi = {10.7759/cureus.34616},
  url = {https://www.cureus.com/articles/136411-use-of-chatgpt-in-academic-publishing-a-rare-case-of-seronegative-systemic-lupus-erythematosus-in-a-patient-with-hiv-infection},
  urldate = {2023-09-26},
  abstract = {Diagnosing systemic lupus erythematosus (SLE) may be difficult in cases of negative results for antinuclear antibodies (ANAs) and anti-double stranded DNA (dsDNA) antibodies, which is known as seronegative SLE. Additionally, in patients with HIV infection, the diagnosis of SLE is made complicated by the overlap of symptoms and the possibility of false negative results on antibody tests. Herein, we report the case of a 24year-old female with HIV infection on anti-retroviral therapy who presented with vesicles and plaques over the malar area and ulcers over the roof of the mouth. Antibody tests for ANAs and dsDNA were negative. She was initially treated for herpes simplex with a secondary infection, but the symptoms did not improve. She ultimately died from acute myocardial infarction while awaiting results of direct immunofluorescence, which revealed the deposition of immunoglobulin (Ig) M, IgG, and C3 along the basement membrane, thus enabling a diagnosis of SLE. Therefore, SLE can be difficult to diagnose in patients with HIV, and other diagnostic criteria should be considered when suspecting SLE and treating these patients. Additionally, we also present our experience with ChatGPT (OpenAI LP, OpenAI Inc., San Francisco, CA, USA) in academic publishing and its pros and cons.},
  langid = {english},
  annotation = {41 citations (Semantic Scholar/DOI) [2024-10-14]\\
24 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/A5LW3A4X/Manohar and Prasad - 2023 - Use of ChatGPT in Academic Publishing A Rare Case of Seronegative Systemic Lupus Erythematosus in a.pdf}
}

@online{mao_etal23,
  title = {{{GPTEval}}: {{A Survey}} on {{Assessments}} of {{ChatGPT}} and {{GPT-4}}},
  shorttitle = {{{GPTEval}}},
  author = {Mao, Rui and Chen, Guanyi and Zhang, Xulang and Guerin, Frank and Cambria, Erik},
  date = {2023-08-23},
  eprint = {2308.12488},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2308.12488},
  urldate = {2023-09-27},
  abstract = {The emergence of ChatGPT has generated much speculation in the press about its potential to disrupt social and economic systems. Its astonishing language ability has aroused strong curiosity among scholars about its performance in different domains. There have been many studies evaluating the ability of ChatGPT and GPT-4 in different tasks and disciplines. However, a comprehensive review summarizing the collective assessment findings is lacking. The objective of this survey is to thoroughly analyze prior assessments of ChatGPT and GPT-4, focusing on its language and reasoning abilities, scientific knowledge, and ethical considerations. Furthermore, an examination of the existing evaluation methods is conducted, offering several recommendations for future research in evaluating large language models.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  annotation = {62 citations (Semantic Scholar/arXiv) [2024-10-14]},
  file = {/home/ral/Zotero/storage/S2BXCULK/Mao et al. - 2023 - GPTEval A Survey on Assessments of ChatGPT and GPT-4.pdf}
}

@online{marcus_davis20,
  title = {{{GPT-3}}, {{Bloviator}}: {{OpenAI}}’s Language Generator Has No Idea What It’s Talking about},
  shorttitle = {{{GPT-3}}, {{Bloviator}}},
  author = {Marcus, Gary and Davis, Ernest},
  date = {2020},
  url = {https://www.technologyreview.com/2020/08/22/1007539/gpt3-openai-language-generator-artificial-intelligence-ai-opinion/},
  urldate = {2024-09-12},
  abstract = {Tests show that the popular AI still has a poor grasp of reality.},
  langid = {english},
  organization = {MIT Technology Review},
  file = {/home/ral/Zotero/storage/34GCPPQ9/gpt3-openai-language-generator-artificial-intelligence-ai-opinion.html}
}

@article{marshall_wallace19,
  title = {Toward Systematic Review Automation: A Practical Guide to Using Machine Learning Tools in Research Synthesis},
  shorttitle = {Toward Systematic Review Automation},
  author = {Marshall, Iain J. and Wallace, Byron C.},
  date = {2019-07-11},
  journaltitle = {Systematic Reviews},
  shortjournal = {Syst Rev},
  volume = {8},
  number = {1},
  pages = {163},
  issn = {2046-4053},
  doi = {10.1186/s13643-019-1074-9},
  url = {https://doi.org/10.1186/s13643-019-1074-9},
  urldate = {2023-09-26},
  abstract = {Technologies and methods to speed up the production of systematic reviews by reducing the manual labour involved have recently emerged. Automation has been proposed or used to expedite most steps of the systematic review process, including search, screening, and data extraction. However, how these technologies work in practice and when (and when not) to use them is often not clear to practitioners. In this practical guide, we provide an overview of current machine learning methods that have been proposed to expedite evidence synthesis. We also offer guidance on which of these are ready for use, their strengths and weaknesses, and how a systematic review team might go about using them in practice.},
  langid = {english},
  keywords = {Evidence synthesis,Machine learning,Natural language processing},
  annotation = {276 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/GMEBPCWN/Marshall and Wallace - 2019 - Toward systematic review automation a practical guide to using machine learning tools in research s.pdf}
}

@book{mcadam_etal01,
  title = {Dynamics of Contention},
  author = {McAdam, Doug and Tarrow, Sidney G. and Tilly, Charles},
  date = {2001},
  series = {Cambridge Studies in Contentious Politics},
  publisher = {Cambridge University Press},
  location = {Cambridge ; New York},
  isbn = {978-0-521-80588-9 978-0-521-01187-7},
  pagetotal = {387},
  keywords = {Collective behavior,Democratization,Revolutions,Social movements},
  file = {/home/ral/Zotero/storage/JI5T9G65/Mcadam et al. - Dynamics of Contention.pdf}
}

@online{mcgee23,
  type = {SSRN Scholarly Paper},
  title = {Is {{Chat Gpt Biased Against Conservatives}}? {{An Empirical Study}}},
  shorttitle = {Is {{Chat Gpt Biased Against Conservatives}}?},
  author = {McGee, Robert W.},
  date = {2023-02-15},
  number = {4359405},
  location = {Rochester, NY},
  doi = {10.2139/ssrn.4359405},
  url = {https://papers.ssrn.com/abstract=4359405},
  urldate = {2023-11-24},
  abstract = {This paper used Chat GPT to create Irish Limericks. During the creation process, a pattern was observed that seemed to create positive Limericks for liberal politicians and negative Limericks for conservative politicians. Upon identifying this pattern, the sample size was expanded to 80 and some mathematical calculations were made to determine whether the actual results were different from what probability theory would suggest. It was found that, at least in some cases, the AI was biased to favor liberal politicians and disfavor conservatives.},
  langid = {english},
  pubstate = {prepublished},
  annotation = {51 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/EMFK85D9/McGee_2023_Is Chat Gpt Biased Against Conservatives.pdf}
}

@incollection{mead_etal11,
  title = {Proxemic {{Feature Recognition}} for {{Interactive Robots}}: {{Automating Metrics}} from the {{Social Sciences}}},
  shorttitle = {Proxemic {{Feature Recognition}} for {{Interactive Robots}}},
  booktitle = {Social {{Robotics}}},
  author = {Mead, Ross and Atrash, Amin and Matarić, Maja J.},
  editor = {Mutlu, Bilge and Bartneck, Christoph and Ham, Jaap and Evers, Vanessa and Kanda, Takayuki},
  date = {2011},
  volume = {7072},
  pages = {52--61},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-25504-5_6},
  url = {http://link.springer.com/10.1007/978-3-642-25504-5_6},
  urldate = {2023-09-27},
  isbn = {978-3-642-25503-8 978-3-642-25504-5}
}

@online{meisenbacher_norlander23,
  title = {Transforming {{Unstructured Text}} into {{Data}} with {{Context Rule Assisted Machine Learning}} ({{CRAML}})},
  author = {Meisenbacher, Stephen and Norlander, Peter},
  date = {2023-01-20},
  eprint = {2301.08549},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2301.08549},
  urldate = {2023-09-27},
  abstract = {We describe a method and new no-code software tools enabling domain experts to build custom structured, labeled datasets from the unstructured text of documents and build niche machine learning text classification models traceable to expert-written rules. The Context Rule Assisted Machine Learning (CRAML) method allows accurate and reproducible labeling of massive volumes of unstructured text. CRAML enables domain experts to access uncommon constructs buried within a document corpus, and avoids limitations of current computational approaches that often lack context, transparency, and interpetability. In this research methods paper, we present three use cases for CRAML: we analyze recent management literature that draws from text data, describe and release new machine learning models from an analysis of proprietary job advertisement text, and present findings of social and economic interest from a public corpus of franchise documents. CRAML produces document-level coded tabular datasets that can be used for quantitative academic research, and allows qualitative researchers to scale niche classification schemes over massive text data. CRAML is a low-resource, flexible, and scalable methodology for building training data for supervised ML. We make available as open-source resources: the software, job advertisement text classifiers, a novel corpus of franchise documents, and a fully replicable start-to-finish trained example in the context of no poach clauses.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/home/ral/Zotero/storage/BR5WP6WW/Meisenbacher and Norlander - 2023 - Transforming Unstructured Text into Data with Context Rule Assisted Machine Learning (CRAML).pdf}
}

@article{mesko23,
  title = {Prompt {{Engineering}} as an {{Important Emerging Skill}} for {{Medical Professionals}}: {{Tutorial}}},
  shorttitle = {Prompt {{Engineering}} as an {{Important Emerging Skill}} for {{Medical Professionals}}},
  author = {Meskó, Bertalan},
  date = {2023-10-04},
  journaltitle = {Journal of Medical Internet Research},
  volume = {25},
  number = {1},
  pages = {e50638},
  publisher = {JMIR Publications Inc., Toronto, Canada},
  doi = {10.2196/50638},
  url = {https://www.jmir.org/2023/1/e50638},
  urldate = {2024-01-07},
  abstract = {Prompt engineering is a relatively new field of research that refers to the practice of designing, refining, and implementing prompts or instructions that guide the output of large language models (LLMs) to help in various tasks. With the emergence of LLMs, the most popular one being ChatGPT that has attracted the attention of over a 100 million users in only 2 months, artificial intelligence (AI), especially generative AI, has become accessible for the masses. This is an unprecedented paradigm shift not only because of the use of AI becoming more widespread but also due to the possible implications of LLMs in health care. As more patients and medical professionals use AI-based tools, LLMs being the most popular representatives of that group, it seems inevitable to address the challenge to improve this skill. This paper summarizes the current state of research about prompt engineering and, at the same time, aims at providing practical recommendations for the wide range of health care professionals to improve their interactions with LLMs.},
  langid = {english},
  annotation = {155 citations (Semantic Scholar/DOI) [2024-10-14]\\
123 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/N4V7WM9W/Meskó_2023_Prompt Engineering as an Important Emerging Skill for Medical Professionals.pdf;/home/ral/Zotero/storage/DXYV9TGC/e50638.html}
}

@online{meta24,
  title = {Introducing {{Meta Llama}} 3: {{The}} Most Capable Openly Available {{LLM}} to Date},
  shorttitle = {Introducing {{Meta Llama}} 3},
  author = {{Meta}},
  date = {2024},
  url = {https://ai.meta.com/blog/meta-llama-3/},
  urldate = {2024-06-05},
  abstract = {Today, we’re introducing Meta Llama 3, the next generation of our state-of-the-art open source large language model. In the coming months, we expect to share new capabilities, additional model sizes, and more.},
  langid = {english},
  organization = {Meta AI}
}

@article{meyer_etal23,
  title = {{{ChatGPT}} and Large Language Models in Academia: Opportunities and Challenges},
  shorttitle = {{{ChatGPT}} and Large Language Models in Academia},
  author = {Meyer, Jesse G. and Urbanowicz, Ryan J. and Martin, Patrick C. N. and O’Connor, Karen and Li, Ruowang and Peng, Pei-Chen and Bright, Tiffani J. and Tatonetti, Nicholas and Won, Kyoung Jae and Gonzalez-Hernandez, Graciela and Moore, Jason H.},
  date = {2023-07-13},
  journaltitle = {BioData Mining},
  shortjournal = {BioData Mining},
  volume = {16},
  number = {1},
  pages = {20},
  issn = {1756-0381},
  doi = {10.1186/s13040-023-00339-9},
  url = {https://doi.org/10.1186/s13040-023-00339-9},
  urldate = {2023-12-23},
  abstract = {The introduction of large language models~(LLMs) that allow iterative “chat” in late 2022 is a paradigm shift that enables generation of text often indistinguishable from that written by humans. LLM-based chatbots have immense potential to improve academic~work efficiency, but the ethical implications of their fair use and inherent bias must be considered. In this editorial, we discuss this technology from the academic’s perspective with regard to its limitations and utility for academic writing, education, and programming. We end with our stance with regard to using LLMs and chatbots in academia, which is summarized as (1) we must find ways to effectively use them, (2) their use does not constitute plagiarism (although they may produce plagiarized text), (3) we must quantify their bias, (4) users must be cautious of their poor accuracy, and (5) the future is bright for their application to research and as an academic tool.},
  langid = {english},
  annotation = {151 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/U3E2YCID/Meyer et al. - 2023 - ChatGPT and large language models in academia opp.pdf}
}

@online{microsoft23,
  type = {Blog},
  title = {Confirmed: The New {{Bing}} Runs on {{OpenAI}}’s {{GPT-4}}},
  shorttitle = {Confirmed},
  author = {{Microsoft}},
  date = {2023-03-14},
  url = {https://blogs.bing.com/search/march_2023/Confirmed-the-new-Bing-runs-on-OpenAI’s-GPT-4/},
  urldate = {2024-01-08},
  abstract = {Congratulations to our partners at Open AI for their release of GPT-4 today.~We are happy to confirm that the new Bing is running on GPT-4, which we’ve customized for search. If you’ve used the new Bing preview at any time in the last five weeks, you’ve already experienced an early version of this powerful model. As OpenAI makes updates to GPT-4 and beyond, Bing benefits…},
  organization = {Bing Blogs},
  file = {/home/ral/Zotero/storage/G3IDFVJB/Confirmed-the-new-Bing-runs-on-OpenAI’s-GPT-4.html}
}

@article{moher_etal15,
  title = {Preferred Reporting Items for Systematic Review and Meta-Analysis Protocols ({{PRISMA-P}}) 2015 Statement},
  author = {Moher, David and Shamseer, Larissa and Clarke, Mike and Ghersi, Davina and Liberati, Alessandro and Petticrew, Mark and Shekelle, Paul and Stewart, Lesley A},
  date = {2015-12},
  journaltitle = {Systematic Reviews},
  shortjournal = {Syst Rev},
  volume = {4},
  number = {1},
  pages = {1},
  issn = {2046-4053},
  doi = {10.1186/2046-4053-4-1},
  url = {https://systematicreviewsjournal.biomedcentral.com/articles/10.1186/2046-4053-4-1},
  urldate = {2024-10-27},
  abstract = {Systematic reviews should build on a protocol that describes the rationale, hypothesis, and planned methods of the review; few reviews report whether a protocol exists. Detailed, well-described protocols can facilitate the understanding and appraisal of the review methods, as well as the detection of modifications to methods and selective reporting in completed reviews. We describe the development of a reporting guideline, the Preferred Reporting Items for Systematic reviews and Meta-Analyses for Protocols 2015 (PRISMA-P 2015). PRISMA-P consists of a 17-item checklist intended to facilitate the preparation and reporting of a robust protocol for the systematic review. Funders and those commissioning reviews might consider mandating the use of the checklist to facilitate the submission of relevant protocol information in funding applications. Similarly, peer reviewers and editors can use the guidance to gauge the completeness and transparency of a systematic review protocol submitted for publication in a journal or other medium.},
  langid = {english},
  annotation = {16576 citations (Crossref/DOI) [2024-11-13]},
  file = {/home/ral/Zotero/storage/IZ3GVAPS/PRISMA-P Group et al. - 2015 - Preferred reporting items for systematic review and meta-analysis protocols (PRISMA-P) 2015 statemen.pdf}
}

@online{moller_etal23,
  title = {Is a Prompt and a Few Samples All You Need? {{Using GPT-4}} for Data Augmentation in Low-Resource Classification Tasks},
  shorttitle = {Is a Prompt and a Few Samples All You Need?},
  author = {Møller, Anders Giovanni and Dalsgaard, Jacob Aarup and Pera, Arianna and Aiello, Luca Maria},
  date = {2023-04-26},
  eprint = {2304.13861},
  eprinttype = {arXiv},
  eprintclass = {physics},
  url = {http://arxiv.org/abs/2304.13861},
  urldate = {2023-09-27},
  abstract = {Obtaining and annotating data can be expensive and time-consuming, especially in complex, low-resource domains. We use GPT-4 and ChatGPT to augment small labeled datasets with synthetic data via simple prompts, in three different classification tasks with varying complexity. For each task, we randomly select a base sample of 500 texts to generate 5,000 new synthetic samples. We explore two augmentation strategies: one that preserves original label distribution and another that balances the distribution. Using a progressively larger training sample size, we train and evaluate a 110M parameter multilingual language model on the real and synthetic data separately. We also test GPT-4 and ChatGPT in a zero-shot setting on the test sets. We observe that GPT-4 and ChatGPT have strong zero-shot performance across all tasks. We find that data augmented with synthetic samples yields a good downstream performance, and particularly aids in low-resource settings, such as in identifying rare classes. Human-annotated data exhibits a strong predictive power, overtaking synthetic data in two out of the three tasks. This finding highlights the need for more complex prompts for synthetic datasets to consistently surpass human-generated ones.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Computers and Society,Physics - Physics and Society},
  file = {/home/ral/Zotero/storage/BMJE2TSI/Møller et al. - 2023 - Is a prompt and a few samples all you need Using GPT-4 for data augmentation in low-resource classi.pdf}
}

@article{motoki_etal23,
  title = {More Human than Human: {{Measuring}} Chatgpt Political Bias},
  shorttitle = {More Human than Human},
  author = {Motoki, Fabio and Pinho Neto, Valdemar and Rodrigues, Victor},
  date = {2023},
  journaltitle = {Available at SSRN 4372349},
  url = {https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4372349},
  urldate = {2023-11-24},
  file = {/home/ral/Zotero/storage/YGEW39VN/Motoki et al_2023_More human than human.pdf}
}

@online{movva_etal24,
  title = {Topics, {{Authors}}, and {{Institutions}} in {{Large Language Model Research}}: {{Trends}} from {{17K arXiv Papers}}},
  shorttitle = {Topics, {{Authors}}, and {{Institutions}} in {{Large Language Model Research}}},
  author = {Movva, Rajiv and Balachandar, Sidhika and Peng, Kenny and Agostini, Gabriel and Garg, Nikhil and Pierson, Emma},
  date = {2024-04-28},
  eprint = {2307.10700},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2307.10700},
  urldate = {2024-10-26},
  abstract = {Large language models (LLMs) are dramatically influencing AI research, spurring discussions on what has changed so far and how to shape the field’s future. To clarify such questions, we analyze a new dataset of 16,979 LLMrelated arXiv papers, focusing on recent trends in 2023 vs. 2018-2022. First, we study disciplinary shifts: LLM research increasingly considers societal impacts, evidenced by 20× growth in LLM submissions to the Computers and Society sub-arXiv. An influx of new authors – half of all first authors in 2023 – are entering from non-NLP fields of CS, driving disciplinary expansion. Second, we study industry and academic publishing trends. Surprisingly, industry accounts for a smaller publication share in 2023, largely due to reduced output from Google and other Big Tech companies; universities in Asia are publishing more. Third, we study institutional collaboration: while industry-academic collaborations are common, they tend to focus on the same topics that industry focuses on rather than bridging differences. The most prolific institutions are all US- or China-based, but there is very little cross-country collaboration. We discuss implications around (1) how to support the influx of new authors, (2) how industry trends may affect academics, and (3) possible effects of (the lack of) collaboration.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Computers and Society,Computer Science - Digital Libraries},
  file = {/home/ral/Zotero/storage/EVUU6JUH/Movva et al. - 2024 - Topics, Authors, and Institutions in Large Language Model Research Trends from 17K arXiv Papers.pdf}
}

@article{muka_etal20,
  title = {A 24-Step Guide on How to Design, Conduct, and Successfully Publish a Systematic Review and Meta-Analysis in Medical Research},
  author = {Muka, Taulant and Glisic, Marija and Milic, Jelena and Verhoog, Sanne and Bohlius, Julia and Bramer, Wichor and Chowdhury, Rajiv and Franco, Oscar H.},
  date = {2020-01},
  journaltitle = {European Journal of Epidemiology},
  shortjournal = {Eur J Epidemiol},
  volume = {35},
  number = {1},
  pages = {49--60},
  issn = {0393-2990, 1573-7284},
  doi = {10.1007/s10654-019-00576-5},
  url = {http://link.springer.com/10.1007/s10654-019-00576-5},
  urldate = {2023-10-06},
  abstract = {To inform evidence-based practice in health care, guidelines and policies require accurate identification, collation, and integration of all available evidence in a comprehensive, meaningful, and time-efficient manner. Approaches to evidence synthesis such as carefully conducted systematic reviews and meta-analyses are essential tools to summarize specific topics. Unfortunately, not all systematic reviews are truly systematic, and their quality can vary substantially. Since well-conducted evidence synthesis typically involves a complex set of steps, we believe formulating a cohesive, step-by-step guide on how to conduct a systemic review and meta-analysis is essential. While most of the guidelines on systematic reviews focus on how to report or appraise systematic reviews, they lack guidance on how to synthesize evidence efficiently. To facilitate the design and development of evidence syntheses, we provide a clear and concise, 24-step guide on how to perform a systematic review and meta-analysis of observational studies and clinical trials. We describe each step, illustrate it with concrete examples, and provide relevant references for further guidance. The 24-step guide (1) simplifies the methodology of conducting a systematic review, (2) provides healthcare professionals and researchers with methodologically sound tools for conducting systematic reviews and meta-analyses, and (3) it can enhance the quality of existing evidence synthesis efforts. This guide will help its readers to better understand the complexity of the process, appraise the quality of published systematic reviews, and better comprehend (and use) evidence from medical literature.},
  langid = {english},
  annotation = {303 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/VKLFX9U2/Muka et al. - 2020 - A 24-step guide on how to design, conduct, and successfully publish a systematic review and meta-ana.pdf}
}

@online{naveed_etal23,
  title = {A {{Comprehensive Overview}} of {{Large Language Models}}},
  author = {Naveed, Humza and Khan, Asad Ullah and Qiu, Shi and Saqib, Muhammad and Anwar, Saeed and Usman, Muhammad and Akhtar, Naveed and Barnes, Nick and Mian, Ajmal},
  date = {2023-12-27},
  eprint = {2307.06435},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2307.06435},
  urldate = {2024-01-08},
  abstract = {Large Language Models (LLMs) have recently demonstrated remarkable capabilities in natural language processing tasks and beyond. This success of LLMs has led to a large influx of research contributions in this direction. These works encompass diverse topics such as architectural innovations, better training strategies, context length improvements, fine-tuning, multi-modal LLMs, robotics, datasets, benchmarking, efficiency, and more. With the rapid development of techniques and regular breakthroughs in LLM research, it has become considerably challenging to perceive the bigger picture of the advances in this direction. Considering the rapidly emerging plethora of literature on LLMs, it is imperative that the research community is able to benefit from a concise yet comprehensive overview of the recent developments in this field. This article provides an overview of the existing literature on a broad range of LLM-related concepts. Our selfcontained comprehensive overview of LLMs discusses relevant background concepts along with covering the advanced topics at the frontier of research in LLMs. This review article is intended to not only provide a systematic survey but also a quick comprehensive reference for the researchers and practitioners to draw insights from extensive informative summaries of the existing works to advance the LLM research.},
  langid = {english},
  pubstate = {prepublished},
  file = {/home/ral/Zotero/storage/CVM588Y6/Naveed et al. - 2023 - A Comprehensive Overview of Large Language Models.pdf}
}

@incollection{neth_gigerenzer15,
  title = {Heuristics: {{Tools}} for an {{Uncertain World}}},
  shorttitle = {Heuristics},
  booktitle = {Emerging {{Trends}} in the {{Social}} and {{Behavioral Sciences}}},
  author = {Neth, Hansjörg and Gigerenzer, Gerd},
  editor = {Scott, Robert A and Kosslyn, Stephan M},
  date = {2015},
  edition = {1},
  pages = {1--18},
  publisher = {Wiley},
  abstract = {We distinguish between situations of risk, where all options, consequences, and probabilities are known, and situations of uncertainty, where they are not. Probability theory and statistics are the best tools for deciding under risk but not under uncertainty, which characterizes most relevant problems that humans have to solve. Uncertainty requires simple heuristics that are robust rather than optimal. We propose to think of the mind as an adaptive toolbox and introduce the descriptive study of heuristics, their building blocks, and the core capacities they exploit. The question of which heuristic to select for which class of problems is the topic of the normative study of ecological rationality. We discuss earlier views on the nature of heuristics that maintained that heuristics are always less accurate because they ignore information and demand less effort. Contrary to this accuracy–effort trade-off view, heuristics can lead to more accurate inferences—under uncertainty—than strategies that use more information and computation. The study of heuristics opens up a new perspective on the nature of both cognition and rationality. In a world of uncertainty, Homo sapiens might well be called Homo heuristicus.},
  langid = {english},
  file = {/home/ral/Zotero/storage/VCI5TGE3/Neth et Gigerenzer - 2015 - Heuristics Tools for an Uncertain World.pdf}
}

@book{neveu96,
  title = {Sociologie des mouvements sociaux},
  author = {Neveu, Erik},
  date = {1996},
  series = {Repères},
  edition = {4. éd},
  number = {207},
  publisher = {La Découverte},
  location = {Paris},
  isbn = {978-2-7071-4537-6},
  langid = {french},
  pagetotal = {126},
  file = {/home/ral/Zotero/storage/4Y9R9EVM/Neveu - 2006 - Sociologie des mouvements sociaux.pdf}
}

@article{ng_etal21,
  title = {A Systematic Literature Review on Intelligent Automation: {{Aligning}} Concepts from Theory, Practice, and Future Perspectives},
  shorttitle = {A Systematic Literature Review on Intelligent Automation},
  author = {Ng, Kam K. H. and Chen, Chun-Hsien and Lee, C. K. M. and Jiao, Jianxin (Roger) and Yang, Zhi-Xin},
  date = {2021-01-01},
  journaltitle = {Advanced Engineering Informatics},
  shortjournal = {Advanced Engineering Informatics},
  volume = {47},
  pages = {101246},
  issn = {1474-0346},
  doi = {10.1016/j.aei.2021.101246},
  url = {https://www.sciencedirect.com/science/article/pii/S147403462100001X},
  urldate = {2023-09-26},
  abstract = {With the recent developments in robotic process automation (RPA) and artificial intelligence (AI), academics and industrial practitioners are now pursuing robust and adaptive decision making (DM) in real-life engineering applications and automated business workflows and processes to accommodate context awareness, adaptation to environment and customisation. The emerging research via RPA, AI and soft computing offers sophisticated decision analysis methods, data-driven DM and scenario analysis with regard to the consideration of decision choices and provides benefits in numerous engineering applications. The emerging intelligent automation (IA) – the combination of RPA, AI and soft computing – can further transcend traditional DM to achieve unprecedented levels of operational efficiency, decision quality and system reliability. RPA allows an intelligent agent to eliminate operational errors and mimic manual routine decisions, including rule-based, well-structured and repetitive decisions involving enormous data, in a digital system, while AI has the cognitive capabilities to emulate the actions of human behaviour and process unstructured data via machine learning, natural language processing and image processing. Insights from IA drive new opportunities in providing automated DM processes, fault diagnosis, knowledge elicitation and solutions under complex decision environments with the presence of context-aware data, uncertainty and customer preferences. This sophisticated review attempts to deliver the relevant research directions and applications from the selected literature to the readers and address the key contributions of the selected literature, IA’s benefits, implementation considerations, challenges and potential IA applications to foster the relevant research development in the domain.},
  keywords = {Adaptive decision making,Artificial intelligence,Innovative robotic process automation,Intelligent automation},
  annotation = {110 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/PLCDA7V7/Ng et al. - 2021 - A systematic literature review on intelligent automation Aligning concepts from theory, practice, a.pdf}
}

@article{nguyen23,
  title = {Leveraging {{Large Language Models}} for {{Educational Enhancement}}: {{A Case Study}} of {{ChatGPT}}, {{BingChat}}, and {{Bard}}},
  shorttitle = {Leveraging {{Large Language Models}} for {{Educational Enhancement}}},
  author = {Nguyen, Thu},
  date = {2023},
  publisher = {Preprints},
  url = {https://www.preprints.org/manuscript/202309.1554},
  urldate = {2023-09-27},
  file = {/home/ral/Zotero/storage/UJKDH3RP/Nguyen - 2023 - Leveraging Large Language Models for Educational Enhancement A Case Study of ChatGPT, BingChat, and.pdf}
}

@online{nori_etal23,
  title = {Capabilities of {{GPT-4}} on {{Medical Challenge Problems}}},
  author = {Nori, Harsha and King, Nicholas and McKinney, Scott Mayer and Carignan, Dean and Horvitz, Eric},
  date = {2023-04-12},
  eprint = {2303.13375},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2303.13375},
  url = {http://arxiv.org/abs/2303.13375},
  urldate = {2024-01-07},
  abstract = {Large language models (LLMs) have demonstrated remarkable capabilities in natural language understanding and generation across various domains, including medicine. We present a comprehensive evaluation of GPT-4, a state-of-the-art LLM, on medical competency examinations and benchmark datasets. GPT-4 is a general-purpose model that is not specialized for medical problems through training or engineered to solve clinical tasks. Our analysis covers two sets of official practice materials for the USMLE, a three-step examination program used to assess clinical competency and grant licensure in the United States. We also evaluate performance on the MultiMedQA suite of benchmark datasets. Beyond measuring model performance, experiments were conducted to investigate the influence of test questions containing both text and images on model performance, probe for memorization of content during training, and study probability calibration, which is of critical importance in high-stakes applications like medicine. Our results show that GPT-4, without any specialized prompt crafting, exceeds the passing score on USMLE by over 20 points and outperforms earlier general-purpose models (GPT-3.5) as well as models specifically fine-tuned on medical knowledge (Med-PaLM, a prompt-tuned version of Flan-PaLM 540B). In addition, GPT-4 is significantly better calibrated than GPT-3.5, demonstrating a much-improved ability to predict the likelihood that its answers are correct. We also explore the behavior of the model qualitatively through a case study that shows the ability of GPT-4 to explain medical reasoning, personalize explanations to students, and interactively craft new counterfactual scenarios around a medical case. Implications of the findings are discussed for potential uses of GPT-4 in medical education, assessment, and clinical practice, with appropriate attention to challenges of accuracy and safety.},
  pubstate = {prepublished},
  file = {/home/ral/Zotero/storage/FDYDVZ8S/Nori et al_2023_Capabilities of GPT-4 on Medical Challenge Problems.pdf;/home/ral/Zotero/storage/LR9DG5EK/2303.html}
}

@dataset{norris19,
  title = {The {{Global Party Survey}}},
  author = {Norris, Pippa},
  date = {2019},
  publisher = {www.GlobalPartySurvey.org},
  langid = {english},
  version = {V1.0},
  file = {/home/ral/Zotero/storage/ZT54WILN/Norris - Harvard’s Kennedy School of Government, Cambridge,.pdf}
}

@article{north_weingast89,
  title = {Constitutions and {{Commitment}}: {{The Evolution}} of {{Institutions Governing Public Choice}} in {{Seventeenth-Century England}}},
  shorttitle = {Constitutions and {{Commitment}}},
  author = {North, Douglass C. and Weingast, Barry R.},
  date = {1989-12},
  journaltitle = {The Journal of Economic History},
  volume = {49},
  number = {4},
  pages = {803--832},
  issn = {1471-6372, 0022-0507},
  doi = {10.1017/S0022050700009451},
  url = {https://www.cambridge.org/core/journals/journal-of-economic-history/article/constitutions-and-commitment-the-evolution-of-institutions-governing-public-choice-in-seventeenthcentury-england/2E0D2B2D3490BE5C556D836ACB096362},
  urldate = {2024-09-12},
  abstract = {The article studies the evolution of the constitutional arrangements in seventeenth-century England following the Glorious Revolution of 1688. It focuses on the relationship between institutions and the behavior of the government and interprets the institutional changes on the basis of the goals of the winners—secure property rights, protection of their wealth, and the elimination of confiscatory government. We argue that the new institutions allowed the government to commit credibly to upholding property rights. Their success was remarkable, as the evidence from capital markets shows.},
  langid = {english},
  file = {/home/ral/Zotero/storage/EYLFKPIX/North and Weingast - 1989 - Constitutions and Commitment The Evolution of Institutions Governing Public Choice in Seventeenth-C.pdf}
}

@article{nunes95,
  title = {Jean {{Baudrillard}} in {{Cyberspace}}: {{Internet}}, {{Virtuality}}, and {{Postmodernity}}},
  shorttitle = {Jean {{Baudrillard}} in {{Cyberspace}}},
  author = {Nunes, Mark},
  date = {1995},
  journaltitle = {Style},
  volume = {29},
  number = {2},
  eprint = {42946283},
  eprinttype = {JSTOR},
  pages = {314--327},
  publisher = {Penn State University Press},
  issn = {0039-4238},
  url = {https://www.jstor.org/stable/42946283},
  urldate = {2023-06-15},
  abstract = {Two metaphors have dominated figurations of internet: the "information superhighway" and "cyberspace." Both these metaphors create an image of internet as a virtual world, one in which motion and direction become possible. These developments in the metaphorical presentation of the internet parallel Jean Baudrillard's discussion of an emerging "hyperreality": a world of simulation in which "the real" becomes less significant than its model. A Baudrillardian reading of internet presents the internet as a "hypertelic" mode of communication. As internet develops, "sites" of virtual reality become more compelling and thereby more "real," exposing the overall conceptual model of Internet as a comprehensive and comprehendible world and a substitute for the real world. But Baudrillard also provides room for a reversal of this reading in which internet becomes a challenge to these closed systems. Ultimately, the seductive qualities of the technology can also lead to the creation of a "space" for drift, experimentation, and play.}
}

@article{obaid_etal23,
  title = {Impact of {{Chat GPT}} on {{Scientific Research}}: {{Opportunities}}, {{Risks}}, {{Limitations}}, and {{Ethical Issues}}},
  shorttitle = {Impact of {{Chat GPT}} on {{Scientific Research}}},
  author = {Obaid, Omar Ibrahim and Ali, Ahmed Hussein and Yaseen, Mohanad Ghazi},
  date = {2023},
  journaltitle = {Iraqi Journal For Computer Science and Mathematics},
  volume = {4},
  number = {4},
  url = {https://journal.esj.edu.iq/index.php/IJCM/article/view/595},
  urldate = {2023-09-27},
  file = {/home/ral/Zotero/storage/RT5IN96K/Obaid et al. - 2023 - Impact of Chat GPT on Scientific Research Opportunities, Risks, Limitations, and Ethical Issues.pdf}
}

@article{obi23,
  title = {A Comparative Study of Several Classification Metrics and Their Performances on Data},
  author = {Obi, Jude Chukwura},
  date = {2023-02-28},
  journaltitle = {World Journal of Advanced Engineering Technology and Sciences},
  shortjournal = {World J. Adv. Eng. Technol. Sci.},
  volume = {8},
  number = {1},
  pages = {308--314},
  issn = {25828266},
  doi = {10.30574/wjaets.2023.8.1.0054},
  url = {https://wjaets.com/content/comparative-study-several-classification-metrics-and-their-performances-data},
  urldate = {2024-06-06},
  abstract = {Six classification metrics namely, Accuracy, Precision, Recall (Sensitivity), Specificity, F1-Score and Area Under the Curve have been studied in this work. A classification model based on the Support Vector Machine, was used to obtain a confusion matrix, which provided the needed information for calculating the different classification metrics. Twenty different datasets were used to assess the performances of the classification metrics. Accuracy and Area Under the Curve are the two metrics that consistently gave a classification result given each dataset used in the study. Although accuracy appears to be marginally better that AUC, it was discovered that in some cases where sensitivity is zero, accuracy yielded a high correct classification result. This goes further to implying that prior to choosing accuracy as a preferred metric for classification, investigation should be carried out to find out what sensitivity and specificity are. Where there are high values for sensitivity and specificity, the study shows that a choice of accuracy as a preferred classification metric leads to a high percentage of correct classification result.},
  annotation = {9 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/AR36RTK3/Jude Chukwura Obi_2023_A comparative study of several classification metrics and their performances on.pdf}
}

@article{oconnor_etal18,
  title = {Moving toward the Automation of the Systematic Review Process: A Summary of Discussions at the Second Meeting of {{International Collaboration}} for the {{Automation}} of {{Systematic Reviews}} ({{ICASR}})},
  shorttitle = {Moving toward the Automation of the Systematic Review Process},
  author = {O’Connor, Annette M. and Tsafnat, Guy and Gilbert, Stephen B. and Thayer, Kristina A. and Wolfe, Mary S.},
  date = {2018-01-09},
  journaltitle = {Systematic Reviews},
  shortjournal = {Syst Rev},
  volume = {7},
  number = {1},
  pages = {3},
  issn = {2046-4053},
  doi = {10.1186/s13643-017-0667-4},
  url = {https://doi.org/10.1186/s13643-017-0667-4},
  urldate = {2023-09-26},
  abstract = {The second meeting of the International Collaboration for Automation of Systematic Reviews (ICASR) was held 3–4 October 2016 in Philadelphia, Pennsylvania, USA. ICASR is an interdisciplinary group whose aim is to maximize the use of technology for conducting rapid, accurate, and efficient systematic reviews of scientific evidence. Having automated tools for systematic review should enable more transparent and timely review, maximizing the potential for identifying and translating research findings to practical application. The meeting brought together multiple stakeholder groups including users of summarized research, methodologists who explore production processes and systematic review quality, and technologists such as software developers, statisticians, and vendors. This diversity of participants was intended to ensure effective communication with numerous stakeholders about progress toward automation of systematic reviews and stimulate discussion about potential solutions to identified challenges. The meeting highlighted challenges, both simple and complex, and raised awareness among participants about ongoing efforts by various stakeholders. An outcome of this forum was to identify several short-term projects that participants felt would advance the automation of tasks in the systematic review workflow including (1) fostering better understanding about available tools, (2) developing validated datasets for testing new tools, (3) determining a standard method to facilitate interoperability of tools such as through an application programming interface or API, and (4) establishing criteria to evaluate the quality of tools’ output. ICASR 2016 provided a beneficial forum to foster focused discussion about tool development and resources and reconfirm ICASR members’ commitment toward systematic reviews’ automation.},
  langid = {english},
  keywords = {Automation,Data abstraction,Data extraction,Evidence synthesis,Priority ranking,Systematic review,Tools},
  annotation = {38 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/IXFQUXQG/O’Connor et al. - 2018 - Moving toward the automation of the systematic review process a summary of discussions at the secon.pdf}
}

@article{oconnor_etal19,
  title = {A Question of Trust: {{Can}} We Build an Evidence Base to Gain Trust in Systematic Review Automation Technologies?},
  shorttitle = {A Question of Trust},
  author = {O’Connor, Annette M. and Tsafnat, Guy and Thomas, James and Glasziou, Paul and Gilbert, Stephen B. and Hutton, Brian},
  date = {2019-06-18},
  journaltitle = {Systematic Reviews},
  shortjournal = {Systematic Reviews},
  volume = {8},
  number = {1},
  pages = {143},
  issn = {2046-4053},
  doi = {10.1186/s13643-019-1062-0},
  url = {https://doi.org/10.1186/s13643-019-1062-0},
  urldate = {2023-09-26},
  abstract = {Although many aspects of systematic reviews use computational tools, systematic reviewers have been reluctant to adopt machine learning tools.},
  keywords = {Artificial intelligence,Automation,Data extraction,Machine learning,Screening},
  annotation = {69 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/PHC5Q2XC/O’Connor et al. - 2019 - A question of trust Can we build an evidence base to gain trust in systematic review automation tec.pdf}
}

@article{odonnell93,
  title = {On the State, Democratization and Some Conceptual Problems: {{A Latin American}} View with Glances at Some Postcommunist Countries},
  shorttitle = {On the State, Democratization and Some Conceptual Problems},
  author = {O'Donnell, Guillermo},
  date = {1993-08},
  journaltitle = {World Development},
  shortjournal = {World Development},
  volume = {21},
  number = {8},
  pages = {1355--1369},
  issn = {0305750X},
  doi = {10.1016/0305-750X(93)90048-E},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0305750X9390048E},
  urldate = {2024-09-12},
  langid = {english},
  file = {/home/ral/Zotero/storage/C4LUMZZM/O'Donnell - 1993 - On the state, democratization and some conceptual problems A Latin American view with glances at so.pdf}
}

@software{ollama24,
  title = {Ollama/Ollama},
  author = {{Ollama}},
  date = {2024-06-02T13:54:07Z},
  origdate = {2023-06-26T19:39:32Z},
  url = {https://github.com/ollama/ollama},
  urldate = {2024-06-02},
  abstract = {Get up and running with Llama 3, Mistral, Gemma, and other large language models.},
  organization = {Ollama},
  keywords = {gemma,go,golang,llama,llama2,llama3,llava,llm,llms,mistral,ollama,phi3}
}

@book{olson65,
  title = {The Logic of Collective Action: Public Goods and the Theory of Groups},
  shorttitle = {The Logic of Collective Action},
  author = {Olson, Mancur},
  date = {1965},
  series = {Harvard Economic Studies},
  edition = {21. printing},
  number = {124},
  publisher = {Harvard Univ. Press},
  location = {Cambridge, Mass.},
  isbn = {978-0-674-53751-4},
  langid = {english},
  pagetotal = {186},
  file = {/home/ral/Zotero/storage/GVFLLLR9/Olson - 2003 - The logic of collective action public goods and the theory of groups.pdf}
}

@book{oneil16,
  title = {Weapons of {{Math Destruction}}},
  author = {O'Neil, Cathy},
  date = {2016-09-06},
  journaltitle = {urn:isbn:9780553418811},
  publisher = {Crown/Archetype},
  abstract = {\textbf{A former Wall Street quant sounds an alarm on mathematical modeling\&\#8212;a pervasive new force in society that threatens to undermine democracy and widen inequality.}{$<$}br{$>$} {$<$}br{$>$} We live in the age of the algorithm. Increasingly, the decisions that affect our lives\&\#8212;where we go to school, whether we get a car loan, how much we pay for health insurance\&\#8212;are being made not by humans, but by mathematical models. In theory, this should lead to greater fairness: Everyone is judged according to the same rules, and bias is eliminated. But as Cathy O'Neil reveals in this shocking book, the opposite is true. The models being used today are opaque, unregulated, and uncontestable, even when they're wrong. Most troubling, they reinforce discrimination: If a poor student can't get a loan because a lending model deems him too risky (by virtue of his race or neighborhood), he's then cut off from the kind of education that could pull him out of poverty, and a vicious spiral ensues....},
  isbn = {978-0-553-41882-8},
  langid = {american},
  annotation = {Item ID: \_:n0},
  file = {/home/ral/Zotero/storage/WJU55J6C/O'Neil - 2016 - Weapons of Math Destruction.epub}
}

@online{openai19,
  type = {Research Publication},
  title = {Better Language Models and Their Implications},
  author = {{OpenAi}},
  date = {2019},
  url = {https://openai.com/research/better-language-models},
  urldate = {2023-12-08},
  abstract = {We’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task-specific~training.},
  langid = {american},
  organization = {OpenAi Research},
  file = {/home/ral/Zotero/storage/EUF9MS7E/better-language-models.html}
}

@online{openai22,
  title = {Is {{ChatGPT}} Biased? | {{OpenAI Help Center}}},
  shorttitle = {Is {{ChatGPT}} Biased?},
  author = {OpenAI},
  date = {2022},
  url = {https://help.openai.com/en/articles/8313359-is-chatgpt-biased},
  urldate = {2023-11-24},
  langid = {english},
  file = {/home/ral/Zotero/storage/NKA7HMLD/8313359-is-chatgpt-biased.html}
}

@online{openai22a,
  title = {Introducing {{ChatGPT}}},
  author = {OpenAI},
  date = {2022-11-30},
  url = {https://openai.com/blog/chatgpt},
  urldate = {2023-12-27},
  abstract = {We’ve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.},
  langid = {american},
  file = {/home/ral/Zotero/storage/XRRUL3JE/chatgpt.html}
}

@online{openai23,
  type = {Large Language Model},
  title = {{{GPT-4}}},
  author = {{OpenAI}},
  date = {2023},
  url = {https://chat.openai.com},
  urldate = {2023-10-07},
  abstract = {A conversational AI system that listens, learns, and challenges},
  langid = {american},
  organization = {ChatGPT},
  file = {/home/ral/Zotero/storage/IBDXCE6A/chat.openai.com.html}
}

@online{openai23a,
  title = {How Should {{AI}} Systems Behave, and Who Should Decide?},
  author = {{OpenAI}},
  date = {2023},
  url = {https://openai.com/blog/how-should-ai-systems-behave},
  urldate = {2024-01-08},
  abstract = {We’re clarifying how ChatGPT’s behavior is shaped and our plans for improving that behavior, allowing more user customization, and getting more public input into our decision-making in these~areas.},
  langid = {american},
  organization = {OpenAI},
  file = {/home/ral/Zotero/storage/WY8QQ7N2/how-should-ai-systems-behave.html}
}

@report{openai23b,
  title = {{{GPT-4 Technical Report}}},
  author = {{OpenAI}},
  date = {2023},
  pages = {100},
  institution = {OpenAI},
  url = {https://cdn.openai.com/papers/gpt-4.pdf},
  urldate = {2024-06-05},
  abstract = {We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10\% of test takers. GPT-4 is a Transformer- based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4’s performance based on models trained with no more than 1/1,000th the compute of GPT-4.},
  file = {/home/ral/Zotero/storage/9MGLMHI6/gpt-4.pdf}
}

@online{pangakis_etal23,
  title = {Automated {{Annotation}} with {{Generative AI Requires Validation}}},
  author = {Pangakis, Nicholas and Wolken, Samuel and Fasching, Neil},
  date = {2023-05-31},
  eprint = {2306.00176},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2306.00176},
  urldate = {2023-09-27},
  abstract = {Generative large language models (LLMs) can be a powerful tool for augmenting text annotation procedures, but their performance varies across annotation tasks due to prompt quality, text data idiosyncrasies, and conceptual difficulty. Because these challenges will persist even as LLM technology improves, we argue that any automated annotation process using an LLM must validate the LLM's performance against labels generated by humans. To this end, we outline a workflow to harness the annotation potential of LLMs in a principled, efficient way. Using GPT-4, we validate this approach by replicating 27 annotation tasks across 11 datasets from recent social science articles in high-impact journals. We find that LLM performance for text annotation is promising but highly contingent on both the dataset and the type of annotation task, which reinforces the necessity to validate on a task-by-task basis. We make available easy-to-use software designed to implement our workflow and streamline the deployment of LLMs for automated annotation.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/ral/Zotero/storage/WW32K8KI/Pangakis et al. - 2023 - Automated Annotation with Generative AI Requires Validation.pdf}
}

@online{parthasarathy_etal24,
  title = {The {{Ultimate Guide}} to {{Fine-Tuning LLMs}} from {{Basics}} to {{Breakthroughs}}: {{An Exhaustive Review}} of {{Technologies}}, {{Research}}, {{Best Practices}}, {{Applied Research Challenges}} and {{Opportunities}}},
  shorttitle = {The {{Ultimate Guide}} to {{Fine-Tuning LLMs}} from {{Basics}} to {{Breakthroughs}}},
  author = {Parthasarathy, Venkatesh Balavadhani and Zafar, Ahtsham and Khan, Aafaq and Shahid, Arsalan},
  date = {2024-08-23},
  eprint = {2408.13296},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2408.13296},
  url = {http://arxiv.org/abs/2408.13296},
  urldate = {2024-12-18},
  abstract = {This report examines the fine-tuning of Large Language Models (LLMs), integrating theoretical insights with practical applications. It outlines the historical evolution of LLMs from traditional Natural Language Processing (NLP) models to their pivotal role in AI. A comparison of fine-tuning methodologies, including supervised, unsupervised, and instruction-based approaches, highlights their applicability to different tasks. The report introduces a structured seven-stage pipeline for fine-tuning LLMs, spanning data preparation, model initialization, hyperparameter tuning, and model deployment. Emphasis is placed on managing imbalanced datasets and optimization techniques. Parameter-efficient methods like Low-Rank Adaptation (LoRA) and Half Fine-Tuning are explored for balancing computational efficiency with performance. Advanced techniques such as memory fine-tuning, Mixture of Experts (MoE), and Mixture of Agents (MoA) are discussed for leveraging specialized networks and multi-agent collaboration. The report also examines novel approaches like Proximal Policy Optimization (PPO) and Direct Preference Optimization (DPO), which align LLMs with human preferences, alongside pruning and routing optimizations to improve efficiency. Further sections cover validation frameworks, post-deployment monitoring, and inference optimization, with attention to deploying LLMs on distributed and cloud-based platforms. Emerging areas such as multimodal LLMs, fine-tuning for audio and speech, and challenges related to scalability, privacy, and accountability are also addressed. This report offers actionable insights for researchers and practitioners navigating LLM fine-tuning in an evolving landscape.},
  pubstate = {prepublished},
  version = {1},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/ral/Zotero/storage/M3JKHTYM/Parthasarathy et al. - 2024 - The Ultimate Guide to Fine-Tuning LLMs from Basics to Breakthroughs An Exhaustive Review of Technol.pdf;/home/ral/Zotero/storage/Z7577HAQ/2408.html}
}

@article{pelizzo03,
  title = {Party Positions or Party Direction? {{An}} Analysis of {{Party Manifesto Data}}},
  shorttitle = {Party Positions or Party Direction?},
  author = {Pelizzo, Riccardo},
  date = {2003-04},
  journaltitle = {West European Politics},
  shortjournal = {West European Politics},
  volume = {26},
  number = {2},
  pages = {67--89},
  issn = {0140-2382, 1743-9655},
  doi = {10.1080/01402380512331341111},
  url = {http://www.tandfonline.com/doi/abs/10.1080/01402380512331341111},
  urldate = {2023-11-16},
  langid = {english},
  annotation = {65 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/8ZSCL9KC/Pelizzo - 2003 - Party positions or party direction An analysis of.pdf}
}

@book{petticrew_roberts06,
  title = {Systematic Reviews in the Social Sciences: A Practical Guide},
  shorttitle = {Systematic Reviews in the Social Sciences},
  author = {Petticrew, Mark and Roberts, Helen},
  date = {2006},
  publisher = {Blackwell Pub},
  location = {Malden, MA ; Oxford},
  isbn = {978-1-4051-2110-1 978-1-4051-2111-8},
  pagetotal = {336},
  keywords = {Research Methodology,Social sciences,Statistical methods},
  annotation = {OCLC: ocm60360309},
  file = {/home/ral/Zotero/storage/WD45NVCV/Petticrew and Roberts - 2006 - Systematic reviews in the social sciences a practical guide.pdf}
}

@article{pham_etal14,
  title = {A Scoping Review of Scoping Reviews: {{Advancing}} the Approach and Enhancing the Consistency},
  shorttitle = {A Scoping Review of Scoping Reviews},
  author = {Pham, Mai T and Rajić, Andrijana and Greig, Judy D and Sargeant, Jan M and Papadopoulos, Andrew and McEwen, Scott A},
  date = {2014-12},
  journaltitle = {Research Synthesis Methods},
  shortjournal = {Res Synth Methods},
  volume = {5},
  number = {4},
  eprint = {26052958},
  eprinttype = {pmid},
  pages = {371--385},
  issn = {1759-2879},
  doi = {10.1002/jrsm.1123},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4491356/},
  urldate = {2023-10-06},
  abstract = {Background The scoping review has become an increasingly popular approach for synthesizing research evidence. It is a relatively new approach for which a universal study definition or definitive procedure has not been established. The purpose of this scoping review was to provide an overview of scoping reviews in the literature. Methods A scoping review was conducted using the Arksey and O'Malley framework. A search was conducted in four bibliographic databases and the gray literature to identify scoping review studies. Review selection and characterization were performed by two independent reviewers using pretested forms. Results The search identified 344 scoping reviews published from 1999 to October 2012. The reviews varied in terms of purpose, methodology, and detail of reporting. Nearly three-quarter of reviews (74.1\%) addressed a health topic. Study completion times varied from 2 weeks to 20 months, and 51\% utilized a published methodological framework. Quality assessment of included studies was infrequently performed (22.38\%). Conclusions Scoping reviews are a relatively new but increasingly common approach for mapping broad topics. Because of variability in their conduct, there is a need for their methodological standardization to ensure the utility and strength of evidence. © 2014 The Authors. Research Synthesis Methods published by John Wiley \& Sons, Ltd.},
  pmcid = {PMC4491356},
  annotation = {1909 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/K8XRRPN5/Pham et al. - 2014 - A scoping review of scoping reviews Advancing the approach and enhancing the consistency.pdf}
}

@article{pierson96,
  title = {The {{New Politics}} of the {{Welfare State}}},
  author = {Pierson, Paul},
  date = {1996},
  journaltitle = {World Politics},
  volume = {48},
  number = {2},
  pages = {143--179},
  publisher = {Johns Hopkins University Press},
  issn = {1086-3338},
  url = {https://muse.jhu.edu/pub/1/article/36346},
  urldate = {2024-09-12},
  abstract = {This essay seeks to lay the foundation for an understanding of welfare state retrenchment. Previous discussions have generally relied, at least implicitly, on a reflexive application of theories designed to explain welfare state expansion. Such an approach is seriously flawed. Not only is the goal of retrenchment (avoiding blame for cutting existing programs) far different from the goal of expansion (claiming credit for new social benefits), but the welfare state itself vastly alters the terrain on which the politics of social policy is fought out. Only an appreciation of how mature social programs create a new politics can allow us to make sense of the welfare state’s remarkable resilience over the past two decades of austerity. Theoretical argument is combined with quantitative and qualitative data from four cases (Britain, the United States, Germany, and Sweden) to demonstrate the shortcomings of conventional wisdom and to highlight the factors that limit or facilitate retrenchment success.},
  file = {/home/ral/Zotero/storage/RXSE9T3G/Pierson - 1995 - The New Politics of the Welfare State.pdf}
}

@article{pietsch_lessmann18a,
  title = {Topic Modeling for Analyzing Open-Ended Survey Responses},
  author = {Pietsch, Andra-Selina and Lessmann, Stefan},
  date = {2018-07-03},
  journaltitle = {Journal of Business Analytics},
  shortjournal = {Journal of Business Analytics},
  volume = {1},
  number = {2},
  pages = {93--116},
  issn = {2573-234X, 2573-2358},
  doi = {10.1080/2573234X.2019.1590131},
  url = {https://www.tandfonline.com/doi/full/10.1080/2573234X.2019.1590131},
  urldate = {2024-06-06},
  abstract = {Open-ended responses are widely used in market research studies. Processing of such responses requires labour-intensive human coding. This paper focuses on unsupervised topic models and tests their ability to automate the analysis of open-ended responses. Since state-of-the-art topic models struggle with the shortness of open-ended responses, the paper considers three novel short text topic models: Latent Feature Latent Dirichlet Allocation, Biterm Topic Model and Word Network Topic Model. The models are fitted and evaluated on a set of real-world open-ended responses provided by a market research company. Multiple components such as topic coherence and document classification are quantitatively and qualitatively evaluated to appraise whether topic models can replace human coding. The results suggest that topic models are a viable alternative for openended response coding. However, their usefulness is limited when a correct one-to-one mapping of responses and topics or the exact topic distribution is needed.},
  langid = {english},
  annotation = {32 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/GD3MLZDS/Pietsch and Lessmann - 2018 - Topic modeling for analyzing open-ended survey res.pdf}
}

@book{powell00,
  title = {Elections as {{Instruments}} of {{Democracy}}: {{Majoritarian}} and {{Proportional Visions}}},
  shorttitle = {Elections as {{Instruments}} of {{Democracy}}},
  author = {Powell, G. Bingham},
  date = {2000},
  eprint = {j.ctt32bwg8},
  eprinttype = {jstor},
  publisher = {Yale University Press},
  url = {https://www.jstor.org/stable/j.ctt32bwg8},
  urldate = {2023-12-26},
  abstract = {In this book, a leading scholar of comparative politics explores elections as instruments of democracy. Focusing on elections in twenty democracies over the past quarter century, G. Bingham Powell, Jr., examines the differences between two great visions of democracy-the \emph{majoritarian} vision, in which citizens use the election process to choose decisively between two competing teams of policymakers, providing the winner with the concentrated power to make public policy; and the \emph{proportional influence} vision, in which citizens use elections to choose political agents to represent their views in postelection bargaining, thereby dispersing power. Powell asks crucial questions for modern democracies: Which vision best serves as an instrument of democracy? What are the reasons and conditions under which each vision succeeds or fails?Careful analyses of more than 150 democratic elections show that each vision succeeds fairly well on its own terms in responsively linking election outcomes to policymaker selection, although advantages and limitations must be traded off. However, Powell concludes, the proportional influence vision and its designs enjoy a clear advantage in creating policy congruence between citizens and their policymakers-a finding that should give pause to those who are attracted to the idea of the decisive election as a direct tool for citizen control.},
  isbn = {978-0-300-08015-5},
  file = {/home/ral/Zotero/storage/BHPQ6A4A/Powell_2000_Elections as Instruments of Democracy.pdf}
}

@online{prabhu_birhane20,
  title = {Large Image Datasets: {{A}} Pyrrhic Win for Computer Vision?},
  shorttitle = {Large Image Datasets},
  author = {Prabhu, Vinay Uday and Birhane, Abeba},
  date = {2020-07-23},
  eprint = {2006.16923},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2006.16923},
  url = {http://arxiv.org/abs/2006.16923},
  urldate = {2024-09-12},
  abstract = {In this paper we investigate problematic practices and consequences of large scale vision datasets. We examine broad issues such as the question of consent and justice as well as specific concerns such as the inclusion of verifiably pornographic images in datasets. Taking the ImageNet-ILSVRC-2012 dataset as an example, we perform a cross-sectional model-based quantitative census covering factors such as age, gender, NSFW content scoring, class-wise accuracy, human-cardinality-analysis, and the semanticity of the image class information in order to statistically investigate the extent and subtleties of ethical transgressions. We then use the census to help hand-curate a look-up-table of images in the ImageNet-ILSVRC-2012 dataset that fall into the categories of verifiably pornographic: shot in a non-consensual setting (up-skirt), beach voyeuristic, and exposed private parts. We survey the landscape of harm and threats both society broadly and individuals face due to uncritical and ill-considered dataset curation practices. We then propose possible courses of correction and critique the pros and cons of these. We have duly open-sourced all of the code and the census meta-datasets generated in this endeavor for the computer vision community to build on. By unveiling the severity of the threats, our hope is to motivate the constitution of mandatory Institutional Review Boards (IRB) for large scale dataset curation processes.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computers and Society,Statistics - Applications,Statistics - Machine Learning},
  file = {/home/ral/Zotero/storage/RJGD377D/Prabhu and Birhane - 2020 - Large image datasets A pyrrhic win for computer vision.pdf;/home/ral/Zotero/storage/K3N82C45/2006.html}
}

@article{pradana_etal23,
  title = {Discussing {{ChatGPT}} in Education: {{A}} Literature Review and Bibliometric Analysis},
  shorttitle = {Discussing {{ChatGPT}} in Education},
  author = {Pradana, Mahir and Elisa, Hanifah Putri and Syarifuddin, Syarifuddin},
  date = {2023-12-11},
  journaltitle = {Cogent Education},
  shortjournal = {Cogent Education},
  volume = {10},
  number = {2},
  pages = {2243134},
  issn = {2331-186X},
  doi = {10.1080/2331186X.2023.2243134},
  url = {https://www.tandfonline.com/doi/full/10.1080/2331186X.2023.2243134},
  urldate = {2023-09-27},
  langid = {english},
  annotation = {43 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/6SI5FVN3/Pradana et al. - 2023 - Discussing ChatGPT in education A literature review and bibliometric analysis.pdf}
}

@article{przeworski_limongineto97,
  title = {Modernization: {{Theories}} and {{Facts}}},
  shorttitle = {Modernization},
  author = {Przeworski, Adam and Limongi Neto, Fernando Papaterra},
  date = {1997},
  journaltitle = {World Politics},
  volume = {49},
  number = {2},
  pages = {155--183},
  publisher = {Johns Hopkins University Press},
  issn = {1086-3338},
  url = {https://muse.jhu.edu/pub/1/article/36370},
  urldate = {2024-09-12},
  abstract = {What makes political regimes rise, endure, and fall? The main question is whether the observed close relation between levels of economic development and the incidence of democratic regimes is due to democracies being more likely to emerge or only more likely to survive in the more developed countries. We answer this question using data concerning 135 countries that existed at any time between 1950 and 1990. We find that the level of economic development does not affect the probability of transitions to democracy but that affluence does make democratic regimes more stable. The relation between affluence and democratic stability is monotonic, and the breakdown of democracies at middle levels of development is a phenomenon peculiar to the Southern Cone of Latin America. These patterns also appear to have been true of the earlier period, but dictatorships are more likely to survive in wealthy countries that became independent only after 1950. We conclude that modernization need not generate democracy but democracies survive in countries that are modern.},
  file = {/home/ral/Zotero/storage/RXA5A8CX/Przeworski and Limongi - 1997 - Modernization Theories and Facts.pdf}
}

@inproceedings{ran_etal23,
  title = {{{YNU-HPCC}} at {{WASSA}} 2023: {{Using Text-Mixed Data Augmentation}} for {{Emotion Classification}} on {{Code-Mixed Text Message}}},
  shorttitle = {{{YNU-HPCC}} at {{WASSA}} 2023},
  booktitle = {Proceedings of the 13th {{Workshop}} on {{Computational Approaches}} to {{Subjectivity}}, {{Sentiment}}, \& {{Social Media Analysis}}},
  author = {Ran, Xuqiao and Zhang, You and Wang, Jin and Xu, Dan and Zhang, Xuejie},
  date = {2023},
  pages = {611--615},
  url = {https://aclanthology.org/2023.wassa-1.60/},
  urldate = {2023-09-27},
  file = {/home/ral/Zotero/storage/4RLRVBYW/Ran et al. - 2023 - YNU-HPCC at WASSA 2023 Using Text-Mixed Data Augmentation for Emotion Classification on Code-Mixed.pdf}
}

@article{rathje_etal23,
  title = {{{GPT}} Is an Effective Tool for Multilingual Psychological Text Analysis},
  author = {Rathje, Steve and Mirea, Dan-Mircea and Sucholutsky, Ilia and Marjieh, Raja and Robertson, Claire and Van Bavel, Jay J.},
  date = {2023},
  publisher = {PsyArXiv},
  url = {https://psyarxiv.com/sekf5?trk=public_post_reshare-text},
  urldate = {2023-09-27}
}

@inproceedings{ribeiro_etal16,
  title = {"{{Why Should I Trust You}}?": {{Explaining}} the {{Predictions}} of {{Any Classifier}}},
  shorttitle = {"{{Why Should I Trust You}}?},
  booktitle = {Proceedings of the 22nd {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  date = {2016-08-13},
  series = {{{KDD}} '16},
  pages = {1135--1144},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/2939672.2939778},
  url = {https://dl.acm.org/doi/10.1145/2939672.2939778},
  urldate = {2024-10-26},
  abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one.In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally varound the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
  isbn = {978-1-4503-4232-2},
  annotation = {7334 citations (Crossref/DOI) [2024-11-13]},
  file = {/home/ral/Zotero/storage/2PPYDDLM/Ribeiro et al. - 2016 - Why Should I Trust You Explaining the Predictions of Any Classifier.pdf}
}

@article{ribeiro_etal16a,
  title = {Model-{{Agnostic Interpretability}} of {{Machine Learning}}},
  author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  date = {2016-06-16},
  journaltitle = {ArXiv},
  url = {https://www.semanticscholar.org/paper/Model-Agnostic-Interpretability-of-Machine-Learning-Ribeiro-Singh/fdd025e077a36166b10120b448d0c4e4009824a9},
  urldate = {2024-10-26},
  abstract = {Understanding why machine learning models behave the way they do empowers both system designers and end-users in many ways: in model selection, feature engineering, in order to trust and act upon the predictions, and in more intuitive user interfaces. Thus, interpretability has become a vital concern in machine learning, and work in the area of interpretable models has found renewed interest. In some applications, such models are as accurate as non-interpretable ones, and thus are preferred for their transparency. Even when they are not accurate, they may still be preferred when interpretability is of paramount importance. However, restricting machine learning to interpretable models is often a severe limitation. In this paper we argue for explaining machine learning predictions using model-agnostic approaches. By treating the machine learning models as black-box functions, these approaches provide crucial flexibility in the choice of models, explanations, and representations, improving debugging, comparison, and interfaces for a variety of users and models. We also outline the main challenges for such methods, and review a recently-introduced model-agnostic explanation approach (LIME) that addresses these challenges.},
  keywords = {⛔ No DOI found},
  file = {/home/ral/Zotero/storage/3NFJYXSE/Ribeiro et al. - 2016 - Model-Agnostic Interpretability of Machine Learning.pdf}
}

@article{roberts_etal14,
  title = {Structural {{Topic Models}} for {{Open-Ended Survey Responses}}},
  author = {Roberts, Margaret E. and Stewart, Brandon M. and Tingley, Dustin and Lucas, Christopher and Leder-Luis, Jetson and Gadarian, Shana Kushner and Albertson, Bethany and Rand, David G.},
  date = {2014},
  journaltitle = {American Journal of Political Science},
  volume = {58},
  number = {4},
  pages = {1064--1082},
  issn = {1540-5907},
  doi = {10.1111/ajps.12103},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ajps.12103},
  urldate = {2023-09-03},
  abstract = {Collection and especially analysis of open-ended survey responses are relatively rare in the discipline and when conducted are almost exclusively done through human coding. We present an alternative, semiautomated approach, the structural topic model (STM) (Roberts, Stewart, and Airoldi 2013; Roberts et al. 2013), that draws on recent developments in machine learning based analysis of textual data. A crucial contribution of the method is that it incorporates information about the document, such as the author's gender, political affiliation, and treatment assignment (if an experimental study). This article focuses on how the STM is helpful for survey researchers and experimentalists. The STM makes analyzing open-ended responses easier, more revealing, and capable of being used to estimate treatment effects. We illustrate these innovations with analysis of text from surveys and experiments.},
  langid = {english},
  keywords = {notion},
  annotation = {1121 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/JZKYWF6B/Roberts et al_2014_Structural Topic Models for Open-Ended Survey Responses.pdf;/home/ral/Zotero/storage/ER9SHKWA/ajps.html}
}

@article{rosenbusch_etal23,
  title = {How {{Accurate}} Are {{GPT-3}}’s {{Hypotheses About Social Science Phenomena}}?},
  author = {Rosenbusch, Hannes and Stevenson, Claire E. and Van Der Maas, Han L. J.},
  date = {2023-08},
  journaltitle = {Digital Society},
  shortjournal = {DISO},
  volume = {2},
  number = {2},
  pages = {26},
  issn = {2731-4650, 2731-4669},
  doi = {10.1007/s44206-023-00054-2},
  url = {https://link.springer.com/10.1007/s44206-023-00054-2},
  urldate = {2023-09-27},
  abstract = {Abstract We test whether GPT-3 can accurately predict simple study outcomes in the social sciences. Ground truth outcomes were obtained by surveying 600 adult US citizens about their political attitudes. GPT-3 was prompted to predict the direction of the empirical inter-attitude correlations. Machine-generated hypotheses were accurate in 78\% (zero-shot), 94\% (five-shot and chained prompting), and 97\% (extensive finetuning) of cases. Positive and negative correlations were balanced in the ground truth data. These results encourage the development of hypothesis engines for more challenging contexts. Moreover, they highlight the importance of addressing the numerous ethical and philosophical challenges that arise with hypothesis automation. While future hypothesis engines could potentially compete with human researchers in terms of empirical accuracy, they have inherent drawbacks that preclude full automations for the foreseeable future.},
  langid = {english},
  annotation = {5 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/JDMBWW2Q/Rosenbusch et al. - 2023 - How Accurate are GPT-3’s Hypotheses About Social Science Phenomena.pdf}
}

@article{rozado23,
  title = {Danger in the {{Machine}}: {{The Perils}} of {{Political}} and {{Demographic Biases Embedded}} in {{AI Systems}}},
  shorttitle = {Danger in the {{Machine}}},
  author = {Rozado, David},
  date = {2023},
  journaltitle = {Manhattan Institute},
  url = {https://media4.manhattan-institute.org/sites/default/files/the-perils-of-political-and-demographic-biases-embedded-in-ai-systems.pdf},
  urldate = {2023-11-24},
  file = {/home/ral/Zotero/storage/SN9N8AH8/Rozado_2023_Danger in the Machine.pdf}
}

@article{rozado23a,
  title = {The {{Political Biases}} of {{ChatGPT}}},
  author = {Rozado, David},
  date = {2023},
  journaltitle = {Social Sciences},
  shortjournal = {Social Sciences},
  volume = {12},
  number = {3},
  pages = {148},
  abstract = {Recent advancements in Large Language Models (LLMs) suggest imminent commercial applications of such AI systems where they will serve as gateways to interact with technology and the accumulated body of human knowledge. The possibility of political biases embedded in these models raises concerns about their potential misusage. In this work, we report the results of administering 15 different political orientation tests (14 in English, 1 in Spanish) to a state-of-the-art Large Language Model, the popular ChatGPT from OpenAI. The results are consistent across tests; 14 of the 15 instruments diagnose ChatGPT answers to their questions as manifesting a preference for left-leaning viewpoints. When asked explicitly about its political preferences, ChatGPT often claims to hold no political opinions and to just strive to provide factual and neutral information. It is desirable that public facing artificial intelligence systems provide accurate and factual information about empirically verifiable issues, but such systems should strive for political neutrality on largely normative questions for which there is no straightforward way to empirically validate a viewpoint. Thus, ethical AI systems should present users with balanced arguments on the issue at hand and avoid claiming neutrality while displaying clear signs of political bias in their content.},
  langid = {english},
  file = {/home/ral/Zotero/storage/5QSDHXJZ/Rozado - 2023 - The Political Biases of ChatGPT.pdf;/home/ral/Zotero/storage/C8IV99LX/Rozado_2023_The Political Biases of ChatGPT.pdf;/home/ral/Zotero/storage/SBIIU6DR/148.html}
}

@article{rudin19,
  title = {Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead},
  author = {Rudin, Cynthia},
  date = {2019-05},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  volume = {1},
  number = {5},
  pages = {206--215},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-019-0048-x},
  url = {https://www.nature.com/articles/s42256-019-0048-x},
  urldate = {2024-09-12},
  abstract = {Black box machine learning models are currently being used for high-stakes decision making throughout society, causing problems in healthcare, criminal justice and other domains. Some people hope that creating methods for explaining these black box models will alleviate some of the problems, but trying to explain black box models, rather than creating models that are interpretable in the first place, is likely to perpetuate bad practice and can potentially cause great harm to society. The way forward is to design models that are inherently interpretable. This Perspective clarifies the chasm between explaining black boxes and using inherently interpretable models, outlines several key reasons why explainable black boxes should be avoided in high-stakes decisions, identifies challenges to interpretable machine learning, and provides several example applications where interpretable models could potentially replace black box models in criminal justice, healthcare and computer vision.},
  langid = {english},
  keywords = {Computer science,Criminology,Science,Statistics,technology and society},
  annotation = {3820 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/Z63U9UU9/Rudin - 2019 - Stop explaining black box machine learning models for high stakes decisions and use interpretable mo.pdf}
}

@online{rutinowski_etal23,
  title = {The {{Self-Perception}} and {{Political Biases}} of {{ChatGPT}}},
  author = {Rutinowski, Jérôme and Franke, Sven and Endendyk, Jan and Dormuth, Ina and Pauly, Markus},
  date = {2023},
  abstract = {This contribution analyzes the self-perception and political biases of OpenAI’s Large Language Model ChatGPT. Taking into account the first small-scale reports and studies that have emerged, claiming that ChatGPT is politically biased towards progressive and libertarian points of view, this contribution aims to provide further clarity on this subject. For this purpose, ChatGPT was asked to answer the questions posed by the political compass test as well as similar questionnaires that are specific to the respective politics of the G7 member states. These eight tests were repeated ten times each and revealed that ChatGPT seems to hold a bias towards progressive views. The political compass test revealed a bias towards progressive and libertarian views, with the average coordinates on the political compass being (-6.48, -5.99) (with (0, 0) the center of the compass, i.e., centrism and the axes ranging from -10 to 10), supporting the claims of prior research. The political questionnaires for the G7 member states indicated a bias towards progressive views but no significant bias between authoritarian and libertarian views, contradicting the findings of prior reports, with the average coordinates being (-3.27, 0.58). In addition, ChatGPT’s Big Five personality traits were tested using the OCEAN test and its personality type was queried using the Myers–Briggs Type Indicator (MBTI) test. Finally, the maliciousness of ChatGPT was evaluated using the Dark Factor test. These three tests were also repeated ten times each, revealing that ChatGPT perceives itself as highly open and agreeable, has the Myers-Briggs personality type ENFJ, and is among the 15\% of test-takers with the least pronounced dark traits.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computers and Society,Computer Science - Human-Computer Interaction}
}

@online{rutinowski_etal23a,
  title = {The {{Self-Perception}} and {{Political Biases}} of {{ChatGPT}}},
  author = {Rutinowski, Jérôme and Franke, Sven and Endendyk, Jan and Dormuth, Ina and Pauly, Markus},
  date = {2023},
  abstract = {This contribution analyzes the self-perception and political biases of OpenAI’s Large Language Model ChatGPT. Taking into account the first small-scale reports and studies that have emerged, claiming that ChatGPT is politically biased towards progressive and libertarian points of view, this contribution aims to provide further clarity on this subject. For this purpose, ChatGPT was asked to answer the questions posed by the political compass test as well as similar questionnaires that are specific to the respective politics of the G7 member states. These eight tests were repeated ten times each and revealed that ChatGPT seems to hold a bias towards progressive views. The political compass test revealed a bias towards progressive and libertarian views, with the average coordinates on the political compass being (-6.48, -5.99) (with (0, 0) the center of the compass, i.e., centrism and the axes ranging from -10 to 10), supporting the claims of prior research. The political questionnaires for the G7 member states indicated a bias towards progressive views but no significant bias between authoritarian and libertarian views, contradicting the findings of prior reports, with the average coordinates being (-3.27, 0.58). In addition, ChatGPT’s Big Five personality traits were tested using the OCEAN test and its personality type was queried using the Myers–Briggs Type Indicator (MBTI) test. Finally, the maliciousness of ChatGPT was evaluated using the Dark Factor test. These three tests were also repeated ten times each, revealing that ChatGPT perceives itself as highly open and agreeable, has the Myers-Briggs personality type ENFJ, and is among the 15\% of test-takers with the least pronounced dark traits.},
  langid = {english},
  pubstate = {prepublished},
  file = {/home/ral/Zotero/storage/HG6IBAUF/Rutinowski et al_2023_The Self-Perception and Political Biases of ChatGPT.pdf;/home/ral/Zotero/storage/DX2743B4/2304.html}
}

@online{rytting_etal23,
  title = {Towards {{Coding Social Science Datasets}} with {{Language Models}}},
  author = {Rytting, Christopher Michael and Sorensen, Taylor and Argyle, Lisa and Busby, Ethan and Fulda, Nancy and Gubler, Joshua and Wingate, David},
  date = {2023-06-03},
  eprint = {2306.02177},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2306.02177},
  urldate = {2023-09-27},
  abstract = {Researchers often rely on humans to code (label, annotate, etc.) large sets of texts. This kind of human coding forms an important part of social science research, yet the coding process is both resource intensive and highly variable from application to application. In some cases, efforts to automate this process have achieved human-level accuracies, but to achieve this, these attempts frequently rely on thousands of hand-labeled training examples, which makes them inapplicable to small-scale research studies and costly for large ones. Recent advances in a specific kind of artificial intelligence tool - language models (LMs) - provide a solution to this problem. Work in computer science makes it clear that LMs are able to classify text, without the cost (in financial terms and human effort) of alternative methods. To demonstrate the possibilities of LMs in this area of political science, we use GPT-3, one of the most advanced LMs, as a synthetic coder and compare it to human coders. We find that GPT-3 can match the performance of typical human coders and offers benefits over other machine learning methods of coding text. We find this across a variety of domains using very different coding procedures. This provides exciting evidence that language models can serve as a critical advance in the coding of open-ended texts in a variety of applications.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence},
  file = {/home/ral/Zotero/storage/J3GKL5MF/Rytting et al. - 2023 - Towards Coding Social Science Datasets with Language Models.pdf}
}

@inproceedings{sallam23,
  title = {{{ChatGPT}} Utility in Healthcare Education, Research, and Practice: {{Systematic}} Review on the Promising Perspectives and Valid Concerns},
  shorttitle = {{{ChatGPT}} Utility in Healthcare Education, Research, and Practice},
  booktitle = {Healthcare},
  author = {Sallam, Malik},
  date = {2023},
  volume = {11},
  number = {6},
  pages = {887},
  publisher = {MDPI},
  url = {https://www.mdpi.com/2227-9032/11/6/887},
  urldate = {2023-09-27},
  file = {/home/ral/Zotero/storage/F66932HA/Sallam - 2023 - ChatGPT utility in healthcare education, research, and practice Systematic review on the promising.pdf}
}

@article{sallam23a,
  title = {The Utility of {{ChatGPT}} as an Example of Large Language Models in Healthcare Education, Research and Practice: {{Systematic}} Review on the Future Perspectives and Potential Limitations},
  shorttitle = {The Utility of {{ChatGPT}} as an Example of Large Language Models in Healthcare Education, Research and Practice},
  author = {Sallam, Malik},
  date = {2023},
  journaltitle = {medRxiv : the preprint server for health sciences},
  shortjournal = {medRxiv},
  pages = {2023--02},
  publisher = {Cold Spring Harbor Laboratory Press},
  url = {https://www.medrxiv.org/content/10.1101/2023.02.19.23286155.abstract},
  urldate = {2023-09-27},
  file = {/home/ral/Zotero/storage/J3BWH73E/Sallam - 2023 - The utility of ChatGPT as an example of large language models in healthcare education, research and.pdf}
}

@online{santurkar_etal23,
  title = {Whose {{Opinions Do Language Models Reflect}}?},
  author = {Santurkar, Shibani and Durmus, Esin and Ladhak, Faisal and Lee, Cinoo and Liang, Percy and Hashimoto, Tatsunori},
  date = {2023},
  abstract = {Language models (LMs) are increasingly being used in open-ended contexts, where the opinions reflected by LMs in response to subjective queries can have a profound impact, both on user satisfaction, as well as shaping the views of society at large. In this work, we put forth a quantitative framework to investigate the opinions reflected by LMs – by leveraging high-quality public opinion polls and their associated human responses. Using this framework, we create OpinionQA, a new dataset for evaluating the alignment of LM opinions with those of 60 US demographic groups over topics ranging from abortion to automation. Across topics, we find substantial misalignment between the views reflected by current LMs and those of US demographic groups: on par with the Democrat-Republican divide on climate change. Notably, this misalignment persists even after explicitly steering the LMs towards particular demographic groups. Our analysis not only confirms prior observations about the left-leaning tendencies of some human feedback-tuned LMs, but also surfaces groups whose opinions are poorly reflected by current LMs (e.g., 65+ and widowed individuals). Our code and data are available at https://github.com/tatsu-lab/opinions\_qa.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computers and Society,Computer Science - Machine Learning}
}

@online{sarmah_etal24,
  title = {How to {{Choose}} a {{Threshold}} for an {{Evaluation Metric}} for {{Large Language Models}}},
  author = {Sarmah, Bhaskarjit and Li, Mingshu and Lyu, Jingrao and Frank, Sebastian and Castellanos, Nathalia and Pasquali, Stefano and Mehta, Dhagash},
  date = {2024-12-10},
  eprint = {2412.12148},
  eprinttype = {arXiv},
  eprintclass = {stat},
  doi = {10.48550/arXiv.2412.12148},
  url = {http://arxiv.org/abs/2412.12148},
  urldate = {2024-12-18},
  abstract = {To ensure and monitor large language models (LLMs) reliably, various evaluation metrics have been proposed in the literature. However, there is little research on prescribing a methodology to identify a robust threshold on these metrics even though there are many serious implications of an incorrect choice of the thresholds during deployment of the LLMs. Translating the traditional model risk management (MRM) guidelines within regulated industries such as the financial industry, we propose a step-by-step recipe for picking a threshold for a given LLM evaluation metric. We emphasize that such a methodology should start with identifying the risks of the LLM application under consideration and risk tolerance of the stakeholders. We then propose concrete and statistically rigorous procedures to determine a threshold for the given LLM evaluation metric using available ground-truth data. As a concrete example to demonstrate the proposed methodology at work, we employ it on the Faithfulness metric, as implemented in various publicly available libraries, using the publicly available HaluBench dataset. We also lay a foundation for creating systematic approaches to select thresholds, not only for LLMs but for any GenAI applications.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Quantitative Finance - Statistical Finance,Statistics - Applications,Statistics - Machine Learning},
  file = {/home/ral/Zotero/storage/3PDLWUQK/Sarmah et al. - 2024 - How to Choose a Threshold for an Evaluation Metric for Large Language Models.pdf;/home/ral/Zotero/storage/XYPANLE4/2412.html}
}

@book{sartori05,
  title = {Parties and Party Systems: A Framework for Analysis},
  shorttitle = {Parties and Party Systems},
  author = {Sartori, Giovanni},
  date = {2005},
  series = {{{ECPR}} Classics Series},
  edition = {1. publ},
  publisher = {ECPR},
  location = {Colchester},
  isbn = {978-0-9547966-1-7},
  langid = {english},
  pagetotal = {342},
  file = {/home/ral/Zotero/storage/QVWLK2P4/Sartori - 2005 - Parties and party systems a framework for analysi.pdf}
}

@book{sartori05a,
  title = {Parties and Party Systems: A Framework for Analysis},
  shorttitle = {Parties and Party Systems},
  author = {Sartori, Giovanni},
  namea = {European Consortium for Political Research},
  nameatype = {collaborator},
  date = {2005},
  series = {{{ECPR}} Classics},
  publisher = {ECPR},
  location = {Colchester},
  abstract = {In this broad-ranging volume Sartori outlines a comprehensive and authoritative approach to the classification of party systems. He also offers an extensive review of the concept and rationale of the political party, and develops a sharp critique of various spatial models of party competition},
  isbn = {978-1-910259-08-5 978-1-910259-07-8},
  pagetotal = {1},
  annotation = {OCLC: 959554709}
}

@article{sartori70,
  title = {Concept {{Misformation}} in {{Comparative Politics}}},
  author = {Sartori, Giovanni},
  date = {1970-12},
  journaltitle = {American Political Science Review},
  shortjournal = {Am Polit Sci Rev},
  volume = {64},
  number = {4},
  pages = {1033--1053},
  issn = {0003-0554, 1537-5943},
  doi = {10.2307/1958356},
  url = {https://www.cambridge.org/core/product/identifier/S0003055400133325/type/journal_article},
  urldate = {2023-07-04},
  abstract = {“To have mastered ‘theory’ and ‘method’ is to have become a               conscious thinker               , a man at work and aware of the assumptions and implications of whatever he is about. To be mastered by ‘method’ or ‘theory’ is simply to be kept from working.” The sentence applies nicely to the present plight of political science. The profession as a whole oscillates between two unsound extremes. At the one end a large majority of political scientists qualify as pure and simple unconscious thinkers. At the other end a sophisticated minority qualify as overconscious thinkers, in the sense that their standards of method and theory are drawn from the physical, “paradigmatic” sciences.                                         The wide gap between the unconscious and the overconscious thinker is concealed by the growing sophistication of statistical and research techniques. Most of the literature introduced by the title “Methods” (in the social, behavioral or political sciences) actually deals with survey techniques and social statistics, and has little if anything to share with the crucial concern of “methodology,” which is a concern with the logical structure and procedure of scientific enquiry. In a very crucial sense there is no methodology without               logos               , without thinking about thinking. And if a firm distinction is drawn—as it should be—between methodology and technique, the latter is no substitute for the former. One may be a wonderful researcher and manipulator of data, and yet remain an unconscious thinker.},
  langid = {english},
  keywords = {comparative politics,conceptual framework,FAVOURITE},
  file = {/home/ral/Zotero/storage/EJBYUM2A/Sartori - 1970 - Concept Misformation in Comparative Politics.pdf}
}

@article{scheiber23,
  entrysubtype = {newspaper},
  title = {Harvard {{Scholar Who Studies Honesty Is Accused}} of {{Fabricating Findings}}},
  author = {Scheiber, Noam},
  date = {2023-06-24},
  journaltitle = {The New York Times},
  issn = {0362-4331},
  url = {https://www.nytimes.com/2023/06/24/business/economy/francesca-gino-harvard-dishonesty.html},
  urldate = {2023-09-04},
  abstract = {Questions about a widely cited paper are the latest to be raised about methods used in behavioral research.},
  journalsubtitle = {Business},
  langid = {american},
  keywords = {Academic and Scientific Journals,Chronicle of Higher Education,Data Colada,Economics (Theory and Philosophy),Falsification of Data,Gino Francesca,Habits and Routines (Behavior),Harvard Business School,Nelson Leif D,notion,Research,Simmons Joseph P (1977- ),Simonsohn Uri},
  file = {/home/ral/Zotero/storage/2MBGMXRX/francesca-gino-harvard-dishonesty.html}
}

@article{schmidt_etal21,
  title = {Data Extraction Methods for Systematic Review (Semi)Automation: {{A}} Living Systematic Review},
  shorttitle = {Data Extraction Methods for Systematic Review (Semi)Automation},
  author = {Schmidt, Lena and Olorisade, Babatunde K. and McGuinness, Luke A. and Thomas, James and Higgins, Julian P. T.},
  date = {2021},
  journaltitle = {F1000Research},
  volume = {10},
  eprint = {34408850},
  eprinttype = {pmid},
  publisher = {Faculty of 1000 Ltd},
  doi = {10.12688/f1000research.51117.1},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8361807/},
  urldate = {2023-09-26},
  abstract = {Background: The reliable and usable (semi)automation of data extraction can support the field of systematic review by reducing the workload required to gather information about the conduct and results of the included studies. This living systematic review ...},
  langid = {english},
  annotation = {35 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/PCNX8GHA/Schmidt et al. - 2021 - Data extraction methods for systematic review (semi)automation A living systematic review.pdf}
}

@book{schuman_presser96,
  title = {Questions and Answers in Attitude Surveys: Experiments on Question Form, Wording, and Context},
  shorttitle = {Questions and Answers in Attitude Surveys},
  author = {Schuman, Howard and Presser, Stanley},
  date = {1996},
  publisher = {Sage Publications},
  location = {Thousand Oaks, CA},
  isbn = {978-0-7619-0359-8},
  pagetotal = {372},
  keywords = {Research,Social sciences,Social surveys}
}

@online{schwartz_etal23,
  title = {Enhancing {{Trust}} in {{LLM-Based AI Automation Agents}}: {{New Considerations}} and {{Future Challenges}}},
  shorttitle = {Enhancing {{Trust}} in {{LLM-Based AI Automation Agents}}},
  author = {Schwartz, Sivan and Yaeli, Avi and Shlomov, Segev},
  date = {2023-08-10},
  eprint = {2308.05391},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2308.05391},
  urldate = {2023-09-27},
  abstract = {Trust in AI agents has been extensively studied in the literature, resulting in significant advancements in our understanding of this field. However, the rapid advancements in Large Language Models (LLMs) and the emergence of LLM-based AI agent frameworks pose new challenges and opportunities for further research. In the field of process automation, a new generation of AI-based agents has emerged, enabling the execution of complex tasks. At the same time, the process of building automation has become more accessible to business users via user-friendly no-code tools and training mechanisms. This paper explores these new challenges and opportunities, analyzes the main aspects of trust in AI agents discussed in existing literature, and identifies specific considerations and challenges relevant to this new generation of automation agents. We also evaluate how nascent products in this category address these considerations. Finally, we highlight several challenges that the research community should address in this evolving landscape.},
  pubstate = {prepublished},
  keywords = {68T01,Computer Science - Artificial Intelligence},
  file = {/home/ral/Zotero/storage/TSY57J9W/Schwartz et al. - 2023 - Enhancing Trust in LLM-Based AI Automation Agents New Considerations and Future Challenges.pdf}
}

@article{schwartz_ungar15,
  title = {Data-{{Driven Content Analysis}} of {{Social Media}}: {{A Systematic Overview}} of {{Automated Methods}}},
  shorttitle = {Data-{{Driven Content Analysis}} of {{Social Media}}},
  author = {Schwartz, H. Andrew and Ungar, Lyle H.},
  date = {2015-05},
  journaltitle = {The ANNALS of the American Academy of Political and Social Science},
  shortjournal = {The ANNALS of the American Academy of Political and Social Science},
  volume = {659},
  number = {1},
  pages = {78--94},
  issn = {0002-7162, 1552-3349},
  doi = {10.1177/0002716215569197},
  url = {http://journals.sagepub.com/doi/10.1177/0002716215569197},
  urldate = {2023-09-27},
  abstract = {Researchers have long measured people’s thoughts, feelings, and personalities using carefully designed survey questions, which are often given to a relatively small number of volunteers. The proliferation of social media, such as Twitter and Facebook, offers alternative measurement approaches: automatic content coding at unprecedented scales and the statistical power to do open-vocabulary exploratory analysis. We describe a range of automatic and partially automatic content analysis techniques and illustrate how their use on social media generates insights into subjective well-being, health, gender differences, and personality.},
  langid = {english},
  annotation = {118 citations (Crossref/DOI) [2024-10-14]}
}

@book{scott99,
  title = {Seeing like a State: How Certain Schemes to Improve the Human Condition Have Failed},
  shorttitle = {Seeing like a State},
  author = {Scott, James C.},
  date = {1999},
  series = {Yale Agrarian Studies},
  edition = {Veritas paperback edition},
  publisher = {Yale University Press},
  location = {New Haven, CT London},
  isbn = {978-0-300-07016-3 978-0-300-24675-9},
  langid = {english},
  pagetotal = {445},
  file = {/home/ral/Zotero/storage/7H8SN4IM/Scott - 2020 - Seeing like a state how certain schemes to improve the human condition have failed.pdf}
}

@inproceedings{sevenans_etal14,
  title = {The {{Automated Coding}} of {{Policy Agendas}}: {{A Dictionary Based Approach}}},
  shorttitle = {The {{Automated Coding}} of {{Policy Agendas}}},
  booktitle = {The {{Automated Coding}} of {{Policy Agendas}}: {{A Dictionary Based Approach}}},
  author = {Sevenans, Julie and Albaugh, Quinn and Shahaf, Tal and Soroka, Stuart and Walgrave, Stefaan},
  date = {2014-06-14},
  pages = {1--27},
  location = {Konstanz, Germany},
  abstract = {For the coding of political and media texts, the Policy Agendas community has mostly taken a human coding approach, or they have turned to automated machine learning methods. Last year, we proposed an alternative dictionary-based approach for the automated content analysis of texts (see Albaugh et al. 2013). We designed a first version of an English and a Dutch CAP-dictionary, and we validated the results of the codings against human coded documents. Although the results were not perfect yet – with respect to certain topic codes our dictionaries could certainly be improved – we showed that dictionaries may produce reliable, valid and comparable measures of policy and media agendas. This year, we take the next step by doing three things. First, we further develop the Dutch and English dictionaries and try to replicate human coding results by making the dictionary assign single topic codes to single items. Second, we compare the dictionaries not only with human coded texts; we also validate them in a substantive manner. We expect individual Members of Parliament (MPs) to act most upon issues that they prioritize. Concretely, we test this by comparing MPs’ dictionary-coded attention for issues with their committee membership. Third, we show that valuable insights can be gained from using the dictionaries in practice.},
  eventtitle = {The 7th {{Annual Conference}} of the {{Comparative Agendas Project}} ({{CAP}})},
  file = {/home/ral/Zotero/storage/BFCUW5ZS/Sevenans et al_2014_The Automated Coding of Policy Agendas.pdf}
}

@book{shalev-shwartz_ben-david14,
  title = {Understanding Machine Learning: From Theory to Algorithms},
  shorttitle = {Understanding Machine Learning},
  author = {Shalev-Shwartz, Shai and Ben-David, Shai},
  date = {2014},
  publisher = {Cambridge University Press},
  location = {New York, NY, USA},
  abstract = {"Machine learning is one of the fastest growing areas of computer science, with far-reaching applications. The aim of this textbook is to introduce machine learning, and the algorithmic paradigms it offers, in a principled way. The book provides an extensive theoretical account of the fundamental ideas underlying machine learning and the mathematical derivations that transform these principles into practical algorithms. Following a presentation of the basics of the field, the book covers a wide array of central topics that have not been addressed by previous textbooks. These include a discussion of the computational complexity of learning and the concepts of convexity and stability; important algorithmic paradigms including stochastic gradient descent, neural networks, and structured output learning; and emerging theoretical concepts such as the PAC-Bayes approach and compression-based bounds. Designed for an advanced undergraduate or beginning graduate course, the text makes the fundamentals and algorithms of machine learning accessible to students and non-expert readers in statistics, computer science, mathematics, and engineering"--},
  isbn = {978-1-107-05713-5},
  pagetotal = {397},
  keywords = {Algorithms,COMPUTERS / Computer Vision & Pattern Recognition,Machine learning},
  file = {/home/ral/Zotero/storage/LL32PSDG/Shalev-Shwartz and Ben-David - 2014 - Understanding machine learning from theory to algorithms.pdf}
}

@online{singer_etal22,
  title = {Make-{{A-Video}}: {{Text-to-Video Generation}} without {{Text-Video Data}}},
  shorttitle = {Make-{{A-Video}}},
  author = {Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and Parikh, Devi and Gupta, Sonal and Taigman, Yaniv},
  date = {2022-09-29},
  eprint = {2209.14792},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2209.14792},
  urldate = {2023-09-27},
  abstract = {We propose Make-A-Video – an approach for directly translating the tremendous recent progress in Text-to-Image (T2I) generation to Text-to-Video (T2V). Our intuition is simple: learn what the world looks like and how it is described from paired text-image data, and learn how the world moves from unsupervised video footage. Make-A-Video has three advantages: (1) it accelerates training of the T2V model (it does not need to learn visual and multimodal representations from scratch), (2) it does not require paired text-video data, and (3) the generated videos inherit the vastness (diversity in aesthetic, fantastical depictions, etc.) of today's image generation models. We design a simple yet effective way to build on T2I models with novel and effective spatial-temporal modules. First, we decompose the full temporal U-Net and attention tensors and approximate them in space and time. Second, we design a spatial temporal pipeline to generate high resolution and frame rate videos with a video decoder, interpolation model and two super resolution models that can enable various applications besides T2V. In all aspects, spatial and temporal resolution, faithfulness to text, and quality, Make-A-Video sets the new state-of-the-art in text-to-video generation, as determined by both qualitative and quantitative measures.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/home/ral/Zotero/storage/SN4AL26M/Singer et al. - 2022 - Make-A-Video Text-to-Video Generation without Text-Video Data.pdf}
}

@article{sitter02,
  title = {Cleavages, Party Strategy and Party System Change in {{Europe}}, East and West},
  author = {Sitter, Nick},
  date = {2002-09},
  journaltitle = {Perspectives on European Politics and Society},
  shortjournal = {Perspectives on European Politics and Society},
  volume = {3},
  number = {3},
  pages = {425--451},
  issn = {1570-5854, 1568-0258},
  doi = {10.1080/15705850208438844},
  url = {http://www.tandfonline.com/doi/abs/10.1080/15705850208438844},
  urldate = {2023-11-16},
  langid = {english},
  annotation = {29 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/MTG7VATE/Sitter - 2002 - Cleavages, party strategy and party system change .pdf}
}

@article{smith79,
  title = {Western {{European}} Party Systems: {{On}} the Trail of a Typology},
  shorttitle = {Western {{European}} Party Systems},
  author = {Smith, Gordon},
  date = {1979-01-01},
  journaltitle = {West European Politics},
  volume = {2},
  number = {1},
  pages = {128--143},
  publisher = {Routledge},
  issn = {0140-2382},
  doi = {10.1080/01402387908424230},
  url = {https://doi.org/10.1080/01402387908424230},
  urldate = {2023-12-26},
  abstract = {Existing typologies frequently fail to bring out the extent of the development which has occurred in West European party systems. The purpose of this article is to propose a construction which is specifically applicable to the parliamentary form of government and which is of use in non‐static conditions. Whilst admitting that problems of measurement exist, the principal argument is that a distinction can be made between two levels of cohesion in a party system, the governing and the societal references. Their independent variation provides a typology which is sensitive and well‐articulated. The four major types are discussed and illustrated and some conclusions are drawn concerning the apparantly predominant West European type.},
  annotation = {9 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/YCFM3SR2/Smith_1979_Western European party systems.pdf}
}

@article{stepan_skach93,
  title = {Constitutional {{Frameworks}} and {{Democratic Consolidation}}: {{Parliamentarianism}} versus {{Presidentialism}}},
  shorttitle = {Constitutional {{Frameworks}} and {{Democratic Consolidation}}},
  author = {Stepan, Alfred and Skach, Cindy},
  date = {1993/1994},
  journaltitle = {World Politics},
  shortjournal = {World Pol.},
  volume = {46},
  number = {1},
  pages = {1--22},
  url = {https://heinonline.org/HOL/P?h=hein.journals/wpot46&i=23},
  urldate = {2024-09-12},
  langid = {english},
  file = {/home/ral/Zotero/storage/R3YGN4SH/Stepan and Skach - 1993 - Constitutional Frameworks and Democratic Consolidation Parliamentarianism versus Presidentialism.pdf}
}

@online{susnjak23,
  title = {{{PRISMA-DFLLM}}: {{An Extension}} of {{PRISMA}} for {{Systematic Literature Reviews}} Using {{Domain-specific Finetuned Large Language Models}}},
  shorttitle = {{{PRISMA-DFLLM}}},
  author = {Susnjak, Teo},
  date = {2023-06-14},
  eprint = {2306.14905},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2306.14905},
  urldate = {2023-09-27},
  abstract = {With the proliferation of open-sourced Large Language Models (LLMs) and efficient finetuning techniques, we are on the cusp of the emergence of numerous domain-specific LLMs that have been finetuned for expertise across specialized fields and applications for which the current general-purpose LLMs are unsuitable. In academia, this technology has the potential to revolutionize the way we conduct systematic literature reviews (SLRs), access knowledge and generate new insights. This paper proposes an AI-enabled methodological framework that combines the power of LLMs with the rigorous reporting guidelines of the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA). By finetuning LLMs on domain-specific academic papers that have been selected as a result of a rigorous SLR process, the proposed PRISMA-DFLLM (for Domain-specific Finetuned LLMs) reporting guidelines offer the potential to achieve greater efficiency, reusability and scalability, while also opening the potential for conducting incremental living systematic reviews with the aid of LLMs. Additionally, the proposed approach for leveraging LLMs for SLRs enables the dissemination of finetuned models, empowering researchers to accelerate advancements and democratize cutting-edge research. This paper presents the case for the feasibility of finetuned LLMs to support rigorous SLRs and the technical requirements for realizing this. This work then proposes the extended PRISMA-DFLLM checklist of reporting guidelines as well as the advantages, challenges, and potential implications of implementing PRISMA-DFLLM. Finally, a future research roadmap to develop this line of AI-enabled SLRs is presented, paving the way for a new era of evidence synthesis and knowledge discovery.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/ral/Zotero/storage/962MH442/Susnjak - 2023 - PRISMA-DFLLM An Extension of PRISMA for Systematic Literature Reviews using Domain-specific Finetun.pdf}
}

@book{sweigart20,
  title = {Automate the Boring Stuff with {{Python}}: {{Practical}} Programming for Total Beginners},
  shorttitle = {Automate the Boring Stuff with {{Python}}},
  author = {Sweigart, Al},
  date = {2020},
  edition = {2nd edition},
  publisher = {No Starch Press},
  location = {San Francisco},
  abstract = {If you've ever spent hours renaming files or updating hundreds of spreadsheet cells, you know how tedious tasks like these can be. But what if you could have your computer do them for you. In this fully revised second edition of the best-selling classic Automate the Boring Stuff with Python, you'll learn how to use Python to write programs that do in minutes what would take you hours to do by hand–no prior programming experience required. You'll learn the basics Python and explore Python's rich library of modules for performing specific tasks, like scraping data off websites, reading PDF and Word documents, and automating clicking and typing tasks. Step-by-step instructions walk you through each program, and updated practice projects at the end of each chapter challenge you to improve those programs and use your newfound skills to automate similar tasks},
  isbn = {978-1-59327-992-9},
  pagetotal = {547},
  keywords = {Computer programming,Python (Computer program language),Software}
}

@online{tamkin_etal21,
  title = {Understanding the {{Capabilities}}, {{Limitations}}, and {{Societal Impact}} of {{Large Language Models}}},
  author = {Tamkin, Alex and Brundage, Miles and Clark, Jack and Ganguli, Deep},
  date = {2021-02-04},
  eprint = {2102.02503},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2102.02503},
  url = {http://arxiv.org/abs/2102.02503},
  urldate = {2023-09-26},
  abstract = {On October 14th, 2020, researchers from OpenAI, the Stanford Institute for Human-Centered Artificial Intelligence, and other universities convened to discuss open research questions surrounding GPT-3, the largest publicly-disclosed dense language model at the time. The meeting took place under Chatham House Rules. Discussants came from a variety of research backgrounds including computer science, linguistics, philosophy, political science, communications, cyber policy, and more. Broadly, the discussion centered around two main questions: 1) What are the technical capabilities and limitations of large language models? 2) What are the societal effects of widespread use of large language models? Here, we provide a detailed summary of the discussion organized by the two themes above.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/ral/Zotero/storage/27VIDRFC/Tamkin et al. - 2021 - Understanding the Capabilities, Limitations, and Societal Impact of Large Language Models.pdf}
}

@book{tarrow11,
  title = {Power in Movement: Social Movements and Contentious Politics},
  shorttitle = {Power in Movement},
  author = {Tarrow, Sidney G.},
  date = {2011},
  edition = {Rev. \& updated 3rd ed},
  publisher = {Cambridge University Press},
  location = {New York},
  abstract = {"Social movements have an elusive power but one that is altogether real. From the French and American revolutions to the post-Soviet, ethnic, and terrorist movements of today, contentious politics exercises a fleeting but powerful influence on politics, society, and international relations. This study surveys the modern history of the modern social movements in the West and their diffusion to the global South through war, colonialism, and diffusion, and it puts forward a theory to explain its cyclical surges and declines. It offers an interpretation of the power of movements that emphasizes effects on the lives of militants, policy reforms, political institutions, and cultural change. The book focuses on the rise and fall of social movements as part of contentious politics in general and as the outcome of changes in political opportunities and constraints, state strategy, the new media of communication, and transnational diffusion"-- Provided by publisher},
  isbn = {978-1-139-01191-4},
  langid = {english},
  annotation = {OCLC: 707080974},
  file = {/home/ral/Zotero/storage/RQWIK78R/(Cambridge Studies in Comparative Politics) SIDNEY G. TARROW - Power in Movement Social Movements and Contentious Politics Revised and Updated Third Edition-Cambridge University Press (2011).pdf}
}

@online{tian_etal24,
  title = {{{SpreadsheetLLM}}: {{Encoding Spreadsheets}} for {{Large Language Models}}},
  shorttitle = {{{SpreadsheetLLM}}},
  author = {Tian, Yuzhang and Zhao, Jianbo and Dong, Haoyu and Xiong, Junyu and Xia, Shiyu and Zhou, Mengyu and Lin, Yun and Cambronero, José and He, Yeye and Han, Shi and Zhang, Dongmei},
  date = {2024-07-12},
  eprint = {2407.09025},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2407.09025},
  urldate = {2024-07-19},
  abstract = {Spreadsheets, with their extensive two-dimensional grids, various layouts, and diverse formatting options, present notable challenges for large language models (LLMs). In response, we introduce SpreadsheetLLM, pioneering an efficient encoding method designed to unleash and optimize LLMs' powerful understanding and reasoning capability on spreadsheets. Initially, we propose a vanilla serialization approach that incorporates cell addresses, values, and formats. However, this approach was limited by LLMs' token constraints, making it impractical for most applications. To tackle this challenge, we develop SheetCompressor, an innovative encoding framework that compresses spreadsheets effectively for LLMs. It comprises three modules: structural-anchor-based compression, inverse index translation, and data-format-aware aggregation. It significantly improves performance in spreadsheet table detection task, outperforming the vanilla approach by 25.6\% in GPT4's in-context learning setting. Moreover, fine-tuned LLM with SheetCompressor has an average compression ratio of 25 times, but achieves a state-of-the-art 78.9\% F1 score, surpassing the best existing models by 12.3\%. Finally, we propose Chain of Spreadsheet for downstream tasks of spreadsheet understanding and validate in a new and demanding spreadsheet QA task. We methodically leverage the inherent layout and structure of spreadsheets, demonstrating that SpreadsheetLLM is highly effective across a variety of spreadsheet tasks.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence},
  file = {/home/ral/Zotero/storage/YESJQ5DD/Tian et al_2024_SpreadsheetLLM.pdf;/home/ral/Zotero/storage/TRGNXWDS/2407.html}
}

@article{tiffin_etal05,
  title = {Integration of Text-and Data-Mining Using Ontologies Successfully Selects Disease Gene Candidates},
  author = {Tiffin, Nicki and Kelso, Janet F. and Powell, Alan R. and Pan, Hong and Bajic, Vladimir B. and Hide, Winston A.},
  date = {2005},
  journaltitle = {Nucleic acids research},
  volume = {33},
  number = {5},
  pages = {1544--1552},
  publisher = {Oxford University Press},
  url = {https://academic.oup.com/nar/article-abstract/33/5/1544/2543610},
  urldate = {2023-09-27},
  file = {/home/ral/Zotero/storage/3BFW98HT/Tiffin et al. - 2005 - Integration of text-and data-mining using ontologies successfully selects disease gene candidates.pdf}
}

@incollection{todd_gigerenzer12,
  title = {What {{Is Ecological Rationality}}?},
  booktitle = {Ecological {{Rationality}}: {{Intelligence}} in the {{World}}},
  author = {Todd, Peter M. and Gigerenzer, Gerd},
  editor = {Todd, Peter M. and Gigerenzer, Gerd},
  date = {2012-03-19},
  pages = {0},
  publisher = {Oxford University Press},
  doi = {10.1093/acprof:oso/9780195315448.003.0011},
  url = {https://doi.org/10.1093/acprof:oso/9780195315448.003.0011},
  urldate = {2023-10-26},
  abstract = {In our uncertain world, more information and computation do not always yield better decisions—simple heuristics that employ few cues and little processing can often match or beat optimizing strategies. This chapter explores when and why less can be more in decision making, through the study of the ecological rationality of decision mechanisms used in appropriate contexts. Ecological rationality appears when the structure of boundedly rational decision mechanisms matches the structure of information in the environment. The chapter introduces the ways that heuristic mechanisms are constructed, the types of information structure they can be applied to, and how to study the intelligent, adaptive behavior that emerges from the interaction of both mind and world.},
  isbn = {978-0-19-531544-8},
  file = {/home/ral/Zotero/storage/QTET5B62/148517064.html}
}

@online{touvron_etal23a,
  title = {{{LLaMA}}: {{Open}} and {{Efficient Foundation Language Models}}},
  shorttitle = {{{LLaMA}}},
  author = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timothée and Rozière, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
  date = {2023-02-27},
  eprint = {2302.13971},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2302.13971},
  urldate = {2023-07-21},
  abstract = {We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community1.},
  langid = {english},
  pubstate = {prepublished},
  file = {/home/ral/Zotero/storage/ERIYH4CX/Touvron et al. - 2023 - LLaMA Open and Efficient Foundation Language Mode.pdf}
}

@online{touvron_etal23b,
  title = {Llama 2: {{Open Foundation}} and {{Fine-Tuned Chat Models}}},
  shorttitle = {Llama 2},
  author = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and Bikel, Dan and Blecher, Lukas and Ferrer, Cristian Canton and Chen, Moya and Cucurull, Guillem and Esiobu, David and Fernandes, Jude and Fu, Jeremy and Fu, Wenyin and Fuller, Brian and Gao, Cynthia and Goswami, Vedanuj and Goyal, Naman and Hartshorn, Anthony and Hosseini, Saghar and Hou, Rui and Inan, Hakan and Kardas, Marcin and Kerkez, Viktor and Khabsa, Madian and Kloumann, Isabel and Korenev, Artem and Koura, Punit Singh and Lachaux, Marie-Anne and Lavril, Thibaut and Lee, Jenya and Liskovich, Diana and Lu, Yinghai and Mao, Yuning and Martinet, Xavier and Mihaylov, Todor and Mishra, Pushkar and Molybog, Igor and Nie, Yixin and Poulton, Andrew and Reizenstein, Jeremy and Rungta, Rashi and Saladi, Kalyan and Schelten, Alan and Silva, Ruan and Smith, Eric Michael and Subramanian, Ranjan and Tan, Xiaoqing Ellen and Tang, Binh and Taylor, Ross and Williams, Adina and Kuan, Jian Xiang and Xu, Puxin and Yan, Zheng and Zarov, Iliyan and Zhang, Yuchen and Fan, Angela and Kambadur, Melanie and Narang, Sharan and Rodriguez, Aurelien and Stojnic, Robert and Edunov, Sergey and Scialom, Thomas},
  date = {2023-07-19},
  eprint = {2307.09288},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2307.09288},
  urldate = {2023-07-21},
  abstract = {In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our models outperform open-source chat models on most benchmarks we tested, and based on our human evaluations for helpfulness and safety, may be a suitable substitute for closedsource models. We provide a detailed description of our approach to fine-tuning and safety improvements of Llama 2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/ral/Zotero/storage/372ECAEM/Touvron et al. - 2023 - Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf}
}

@book{trochim_donnelly06,
  title = {The {{Research Methods Knowledge Base}}},
  author = {Trochim, William and Donnelly, James P.},
  date = {2006},
  edition = {3},
  url = {http://gen.lib.rus.ec/book/index.php?md5=04e0ed3274790c6e5dfdfee003a2fd63},
  urldate = {2024-09-20},
  isbn = {978-1-59260-291-9}
}

@article{tsafnat_etal13,
  title = {The Automation of Systematic Reviews},
  author = {Tsafnat, Guy and Dunn, Adam and Glasziou, Paul and Coiera, Enrico},
  date = {2013-01-10},
  journaltitle = {BMJ},
  shortjournal = {BMJ},
  volume = {346},
  eprint = {23305843},
  eprinttype = {pmid},
  pages = {f139},
  publisher = {British Medical Journal Publishing Group},
  issn = {1756-1833},
  doi = {10.1136/bmj.f139},
  url = {https://www.bmj.com/content/346/bmj.f139},
  urldate = {2023-09-26},
  abstract = {{$<$}p{$>$}Would lead to best currently available evidence at the push of a button {$<$}/p{$>$}},
  langid = {english},
  annotation = {124 citations (Semantic Scholar/DOI) [2024-10-14]\\
85 citations (Crossref/DOI) [2024-10-14]}
}

@article{tsafnat_etal14,
  title = {Systematic Review Automation Technologies},
  author = {Tsafnat, Guy and Glasziou, Paul and Choong, Miew Keen and Dunn, Adam and Galgani, Filippo and Coiera, Enrico},
  date = {2014-07-09},
  journaltitle = {Systematic Reviews},
  shortjournal = {Syst Rev},
  volume = {3},
  number = {1},
  pages = {74},
  issn = {2046-4053},
  doi = {10.1186/2046-4053-3-74},
  url = {https://doi.org/10.1186/2046-4053-3-74},
  urldate = {2023-09-26},
  abstract = {Systematic reviews, a cornerstone of evidence-based medicine, are not produced quickly enough to support clinical practice. The cost of production, availability of the requisite expertise and timeliness are often quoted as major contributors for the delay. This detailed survey of the state of the art of information systems designed to support or automate individual tasks in the systematic review, and in particular systematic reviews of randomized controlled clinical trials, reveals trends that see the convergence of several parallel research projects.},
  langid = {english},
  keywords = {Information extraction,Information retrieval,Process automation,Systematic reviews},
  annotation = {282 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/ESDXL42E/Tsafnat et al. - 2014 - Systematic review automation technologies.pdf}
}

@article{tsebelis95,
  title = {Decision {{Making}} in {{Political Systems}}: {{Veto Players}} in {{Presidentialism}}, {{Parliamentarism}}, {{Multicameralism}} and {{Multipartyism}}},
  shorttitle = {Decision {{Making}} in {{Political Systems}}},
  author = {Tsebelis, George},
  date = {1995-07},
  journaltitle = {British Journal of Political Science},
  volume = {25},
  number = {3},
  pages = {289--325},
  issn = {1469-2112, 0007-1234},
  doi = {10.1017/S0007123400007225},
  url = {https://www.cambridge.org/core/journals/british-journal-of-political-science/article/decision-making-in-political-systems-veto-players-in-presidentialism-parliamentarism-multicameralism-and-multipartyism/5E1E9DBFB4106517287328AEE1879A1E},
  urldate = {2024-09-12},
  abstract = {The article compares different political systems with respect to one property: their capacity to produce policy change. I define the basic concept of the article, the ‘veto player’: veto players are individual or collective actors whose agreement (by majority rule for collective actors) is required for a change of the status quo. Two categories of veto players are identified in the article: institutional and partisan. Institutional veto players (president, chambers) exist in presidential systems while partisan veto players (parties) exist at least in parliamentary systems. Westminster systems, dominant party systems and single-party minority governments have only one veto player, while coalitions in parliamentary systems, presidential or federal systems have multiple veto players. The potential for policy change decreases with the number of veto players, the lack of congruence (dissimilarity of policy positions among veto players) and the cohesion (similarity of policy positions among the constituent units of each veto player) of these players. The veto player framework produces results different from existing theories in comparative politics, but congruent with existing empirical studies. In addition, it permits comparisons across different political and party systems. Finally, the veto player framework enables predictions about government instability (in parliamentary systems) or regime instability (in presidential systems); these predictions are supported by available evidence.},
  langid = {english},
  file = {/home/ral/Zotero/storage/73D7YLGT/Tsebelis - 1995 - Decision Making in Political Systems Veto Players in Presidentialism, Parliamentarism, Multicameral.pdf}
}

@article{uchendu_etal23,
  title = {Attribution and {{Obfuscation}} of {{Neural Text Authorship}}: {{A Data Mining Perspective}}},
  shorttitle = {Attribution and {{Obfuscation}} of {{Neural Text Authorship}}},
  author = {Uchendu, Adaku and Le, Thai and Lee, Dongwon},
  date = {2023-06-22},
  journaltitle = {ACM SIGKDD Explorations Newsletter},
  shortjournal = {SIGKDD Explor. Newsl.},
  volume = {25},
  number = {1},
  pages = {1--18},
  issn = {1931-0145, 1931-0153},
  doi = {10.1145/3606274.3606276},
  url = {https://dl.acm.org/doi/10.1145/3606274.3606276},
  urldate = {2023-09-27},
  abstract = {Two interlocking research questions of growing interest and importance in privacy research are Authorship Attribution (AA) and Authorship Obfuscation (AO). Given an artifact, especially a text t in question, an AA solution aims to accurately attribute t to its true author out of many candidate authors while an AO solution aims to modify t to hide its true authorship. Traditionally, the notion of authorship and its accompanying privacy concern is only toward human authors. However, in recent years, due to the explosive advancements in Neural Text Generation (NTG) techniques in NLP, capable of synthesizing human-quality openended texts (so-called "neural texts"), one has to now consider authorships by humans, machines, or their combination. Due to the implications and potential threats of neural texts when used maliciously, it has become critical to understand the limitations of traditional AA/AO solutions and develop novel AA/AO solutions in dealing with neural texts. In this survey, therefore, we make a comprehensive review of recent literature on the attribution and obfuscation of neural text authorship from a Data Mining perspective, and share our view on their limitations and promising research directions.},
  langid = {english},
  annotation = {4 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/J7XBWQQ8/Uchendu et al. - 2023 - Attribution and Obfuscation of Neural Text Authorship A Data Mining Perspective.pdf}
}

@article{urman_makhortykh23,
  title = {The {{Silence}} of the {{LLMs}}: {{Cross-Lingual Analysis}} of {{Political Bias}} and {{False Information Prevalence}} in {{ChatGPT}}, {{Google Bard}}, and {{Bing Chat}}},
  shorttitle = {The {{Silence}} of the {{LLMs}}},
  author = {Urman, Aleksandra and Makhortykh, Mykola},
  date = {2023-12-23},
  publisher = {OSF},
  doi = {10.31219/osf.io/q9v8f},
  url = {https://osf.io/q9v8f},
  urldate = {2023-12-23},
  abstract = {This article presents a comparative analysis of political bias in the outputs of three Large Language Model (LLM)-based chatbots - ChatGPT, Bing Chat, and Bard - in response to political queries concerning the authoritarian regime in Russia. We investigate whether safeguards implemented in these chatbots contribute to the censorship of information that is viewed as harmful by the regime, in particular information about Vladimir Putin and the Russian war against Ukraine, and whether these safeguards enable the generation of false claims, in particular in relation to the regime's internal and external opponents. To detect whether LLM safeguards reiterate political bias, the article compares the outputs of prompts focusing on Putin's regime and the ones dealing with the Russian opposition and the US and Ukrainian politicians. It also examines whether the degree of bias varies depending on the language of the prompt and compares outputs concerning political personalities and issues across three languages: Russian, Ukrainian, and English. The results reveal significant disparities in how individual chatbots withhold politics-related information or produce false claims in relation to it. Notably, Bard consistently refused to respond to queries about Vladimir Putin in Russian, even when the relevant information was accessible via Google Search, and generally followed the censorship guidelines that, according to Yandex-related data leaks, were issued by the Russian authorities. In terms of false claims, we find substantial variation across languages with Ukrainian and Russian prompts generating false information more often and Bard being more prone to produce false claims in relation to Russian regime opponents (e.g., Navalny or Zelenskyy) than other chatbots. This research aims to stimulate further dialogue and research on developing safeguards against the misuse of LLMs outside of democratic environments.},
  langid = {american},
  annotation = {7 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/TUIPKI84/Urman_Makhortykh_2023_The Silence of the LLMs.pdf;/home/ral/Zotero/storage/Q3LBXSCC/q9v8f.html}
}

@article{vanaltena_etal19a,
  title = {Usage of Automation Tools in Systematic Reviews},
  author = {family=Altena, given=A.j., prefix=van, useprefix=true and Spijker, R. and Olabarriaga, S.d.},
  date = {2019},
  journaltitle = {Research Synthesis Methods},
  volume = {10},
  number = {1},
  pages = {72--82},
  issn = {1759-2887},
  doi = {10.1002/jrsm.1335},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jrsm.1335},
  urldate = {2024-10-28},
  abstract = {Systematic reviews are a cornerstone of today's evidence-informed decision making. With the rapid expansion of questions to be addressed and scientific information produced, there is a growing workload on reviewers, making the current practice unsustainable without the aid of automation tools. While many automation tools have been developed and are available, uptake seems to be lagging. For this reason, we set out to investigate the current level of uptake and what the potential barriers and facilitators are for the adoption of automation tools in systematic reviews. We deployed surveys among systematic reviewers that gathered information on tool uptake, demographics, systematic review characteristics, and barriers and facilitators for uptake. Systematic reviewers from multiple domains were targeted during recruitment; however, responders were predominantly from the biomedical sciences. We found that automation tools are currently not widely used among the participants. When tools are used, participants mostly learn about them from their environment, for example, through colleagues, peers, or organization. Tools are often chosen on the basis of user experience, either by own experience or from colleagues or peers. Lastly, licensing, steep learning curve, lack of support, and mismatch to workflow are often reported by participants as relevant barriers. While conclusions can only be drawn for the biomedical field, our work provides evidence and confirms the conclusions and recommendations of previous work, which was based on expert opinions. Furthermore, our study highlights the importance that organizations and best practices in a field can have for the uptake of automation tools for systematic reviews.},
  langid = {english},
  annotation = {42 citations (Crossref/DOI) [2024-11-13]},
  file = {/home/ral/Zotero/storage/ZAYYX6WV/van Altena et al. - 2019 - Usage of automation tools in systematic reviews.pdf;/home/ral/Zotero/storage/JBU3J3S8/jrsm.html}
}

@article{vandenbroek23,
  title = {{{ChatGPT}}’s Left-Leaning Liberal Bias},
  author = {Van den Broek, Merel},
  date = {2023},
  journaltitle = {University of Leiden},
  url = {https://www.universiteitleiden.nl/binaries/content/assets/algemeen/bb-scm/nieuws/political_bias_in_chatgpt.pdf},
  urldate = {2023-11-24},
  keywords = {Biais gauche,Biais liberal,GPT Suck},
  file = {/home/ral/Zotero/storage/VKIYC6IR/van den Broek_2023_ChatGPT’s left-leaning liberal bias.pdf}
}

@article{vandinter_etal21,
  title = {Automation of Systematic Literature Reviews: {{A}} Systematic Literature Review},
  shorttitle = {Automation of Systematic Literature Reviews},
  author = {family=Dinter, given=Raymon, prefix=van, useprefix=true and Tekinerdogan, Bedir and Catal, Cagatay},
  date = {2021-08-01},
  journaltitle = {Information and Software Technology},
  shortjournal = {Information and Software Technology},
  volume = {136},
  pages = {106589},
  issn = {0950-5849},
  doi = {10.1016/j.infsof.2021.106589},
  url = {https://www.sciencedirect.com/science/article/pii/S0950584921000690},
  urldate = {2023-09-26},
  abstract = {Context Systematic Literature Review (SLR) studies aim to identify relevant primary papers, extract the required data, analyze, and synthesize results to gain further and broader insight into the investigated domain. Multiple SLR studies have been conducted in several domains, such as software engineering, medicine, and pharmacy. Conducting an SLR is a time-consuming, laborious, and costly effort. As such, several researchers developed different techniques to automate the SLR process. However, a systematic overview of the current state-of-the-art in SLR automation seems to be lacking. Objective This study aims to collect and synthesize the studies that focus on the automation of SLR to pave the way for further research. Method A systematic literature review is conducted on published primary studies on the automation of SLR studies, in which 41 primary studies have been analyzed. Results This SLR identifies the objectives of automation studies, application domains, automated steps of the SLR, automation techniques, and challenges and solution directions. Conclusion According to our study, the leading automated step is the Selection of Primary Studies. Although many studies have provided automation approaches for systematic literature reviews, no study has been found to apply automation techniques in the planning and reporting phase. Further research is needed to support the automation of the other activities of the SLR process.},
  keywords = {Automation,Machine learning,Natural language processing,Review,Systematic literature review (SLR),Text mining},
  annotation = {129 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/RCE4IQVD/van Dinter et al. - 2021 - Automation of systematic literature reviews A systematic literature review.pdf}
}

@article{vombrocke_etal15,
  title = {Standing on the {{Shoulders}} of {{Giants}}: {{Challenges}} and {{Recommendations}} of {{Literature Search}} in {{Information Systems Research}}},
  shorttitle = {Standing on the {{Shoulders}} of {{Giants}}},
  author = {family=Brocke, given=Jan, prefix=vom, useprefix=true and Simons, Alexander and Riemer, Kai and Niehaves, Bjoern and Plattfaut, Ralf and Cleven, Anne},
  date = {2015-08-01},
  journaltitle = {Communications of the Association for Information Systems},
  volume = {37},
  number = {1},
  issn = {1529-3181},
  doi = {10.17705/1CAIS.03709},
  url = {https://aisel.aisnet.org/cais/vol37/iss1/9},
  annotation = {197 citations (Crossref/DOI) [2024-11-13]},
  file = {/home/ral/Zotero/storage/397PRVA2/vom Brocke et al. - 2015 - Standing on the Shoulders of Giants Challenges and Recommendations of Literature Search in Informat.pdf;/home/ral/Zotero/storage/2RCFZSPS/9.html}
}

@article{vonkrogh_spaeth07,
  title = {The Open Source Software Phenomenon: {{Characteristics}} That Promote Research},
  shorttitle = {The Open Source Software Phenomenon},
  author = {Von Krogh, Georg and Spaeth, Sebastian},
  date = {2007-09},
  journaltitle = {The Journal of Strategic Information Systems},
  shortjournal = {The Journal of Strategic Information Systems},
  volume = {16},
  number = {3},
  pages = {236--253},
  issn = {09638687},
  doi = {10.1016/j.jsis.2007.06.001},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S096386870700025X},
  urldate = {2024-10-26},
  langid = {english},
  annotation = {116 citations (Crossref/DOI) [2024-11-13]},
  file = {/home/ral/Zotero/storage/CDBNVXMA/Von Krogh and Spaeth - 2007 - The open source software phenomenon Characteristics that promote research.pdf}
}

@inproceedings{waheed23,
  title = {Can {{ChatGPT}} Write a Review Paper on Full-Waveform Inversion?},
  booktitle = {84th {{EAGE Annual Conference}} \& {{Exhibition}}},
  author = {Waheed, U.B.},
  date = {2023},
  pages = {1--5},
  publisher = {European Association of Geoscientists \& Engineers},
  location = {Vienna, Austria,},
  doi = {10.3997/2214-4609.2023101460},
  url = {https://www.earthdoc.org/content/papers/10.3997/2214-4609.2023101460},
  urldate = {2023-09-27},
  eventtitle = {84th {{EAGE Annual Conference}} \& {{Exhibition}}},
  langid = {english},
  annotation = {0 citations (Crossref/DOI) [2024-10-14]}
}

@article{wajcman17,
  title = {Automation: {{Is}} It Really Different This Time?: {{Review}} Essay: {{Automation}}},
  shorttitle = {Automation},
  author = {Wajcman, Judy},
  date = {2017-03},
  journaltitle = {The British Journal of Sociology},
  shortjournal = {The British Journal of Sociology},
  volume = {68},
  number = {1},
  pages = {119--127},
  issn = {00071315},
  doi = {10.1111/1468-4446.12239},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/1468-4446.12239},
  urldate = {2023-09-27},
  langid = {english},
  annotation = {109 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/NTQSLQKI/Wajcman - 2017 - Automation Is it really different this time Review essay Automation.pdf}
}

@online{wan_etal23,
  title = {"{{Kelly}} Is a {{Warm Person}}, {{Joseph}} Is a {{Role Model}}": {{Gender Biases}} in {{LLM-Generated Reference Letters}}},
  shorttitle = {"{{Kelly}} Is a {{Warm Person}}, {{Joseph}} Is a {{Role Model}}"},
  author = {Wan, Yixin and Pu, George and Sun, Jiao and Garimella, Aparna and Chang, Kai-Wei and Peng, Nanyun},
  date = {2023-12-01},
  eprint = {2310.09219},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2310.09219},
  url = {http://arxiv.org/abs/2310.09219},
  urldate = {2023-12-23},
  abstract = {Large Language Models (LLMs) have recently emerged as an effective tool to assist individuals in writing various types of content, including professional documents such as recommendation letters. Though bringing convenience, this application also introduces unprecedented fairness concerns. Model-generated reference letters might be directly used by users in professional scenarios. If underlying biases exist in these model-constructed letters, using them without scrutinization could lead to direct societal harms, such as sabotaging application success rates for female applicants. In light of this pressing issue, it is imminent and necessary to comprehensively study fairness issues and associated harms in this real-world use case. In this paper, we critically examine gender biases in LLM-generated reference letters. Drawing inspiration from social science findings, we design evaluation methods to manifest biases through 2 dimensions: (1) biases in language style and (2) biases in lexical content. We further investigate the extent of bias propagation by analyzing the hallucination bias of models, a term that we define to be bias exacerbation in model-hallucinated contents. Through benchmarking evaluation on 2 popular LLMs- ChatGPT and Alpaca, we reveal significant gender biases in LLM-generated recommendation letters. Our findings not only warn against using LLMs for this application without scrutinization, but also illuminate the importance of thoroughly studying hidden biases and harms in LLM-generated professional documents.},
  pubstate = {prepublished},
  file = {/home/ral/Zotero/storage/W89WPR54/Wan et al. - 2023 - Kelly is a Warm Person, Joseph is a Role Model .pdf;/home/ral/Zotero/storage/5J6N6EDQ/2310.html}
}

@online{wang_etal23,
  title = {A {{Survey}} on {{Large Language Model}} Based {{Autonomous Agents}}},
  author = {Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and Zhang, Jingsen and Chen, Zhiyuan and Tang, Jiakai and Chen, Xu and Lin, Yankai and Zhao, Wayne Xin and Wei, Zhewei and Wen, Ji-Rong},
  date = {2023-09-07},
  eprint = {2308.11432},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2308.11432},
  urldate = {2023-09-27},
  abstract = {Autonomous agents have long been a prominent research focus in both academic and industry communities. Previous research in this field often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and thus makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of web knowledge, large language models (LLMs) have demonstrated remarkable potential in achieving human-level intelligence. This has sparked an upsurge in studies investigating LLM-based autonomous agents. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of the field of LLM-based autonomous agents from a holistic perspective. More specifically, we first discuss the construction of LLM-based autonomous agents, for which we propose a unified framework that encompasses a majority of the previous work. Then, we present a comprehensive overview of the diverse applications of LLM-based autonomous agents in the fields of social science, natural science, and engineering. Finally, we delve into the evaluation strategies commonly used for LLM-based autonomous agents. Based on the previous studies, we also present several challenges and future directions in this field. To keep track of this field and continuously update our survey, we maintain a repository of relevant references at https://github.com/Paitesanshi/LLM-Agent-Survey.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/ral/Zotero/storage/UA5RM5BA/Wang et al. - 2023 - A Survey on Large Language Model based Autonomous Agents.pdf}
}

@online{wang_etal23a,
  title = {Can {{ChatGPT Write}} a {{Good Boolean Query}} for {{Systematic Review Literature Search}}?},
  author = {Wang, Shuai and Scells, Harrisen and Koopman, Bevan and Zuccon, Guido},
  date = {2023-02-09},
  eprint = {2302.03495},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2302.03495},
  urldate = {2023-09-27},
  abstract = {Systematic reviews are comprehensive reviews of the literature for a highly focused research question. These reviews are often treated as the highest form of evidence in evidence-based medicine, and are the key strategy to answer research questions in the medical field. To create a high-quality systematic review, complex Boolean queries are often constructed to retrieve studies for the review topic. However, it often takes a long time for systematic review researchers to construct a high quality systematic review Boolean query, and often the resulting queries are far from effective. Poor queries may lead to biased or invalid reviews, because they missed to retrieve key evidence, or to extensive increase in review costs, because they retrieved too many irrelevant studies. Recent advances in Transformer-based generative models have shown great potential to effectively follow instructions from users and generate answers based on the instructions being made. In this paper, we investigate the effectiveness of the latest of such models, ChatGPT, in generating effective Boolean queries for systematic review literature search. Through a number of extensive experiments on standard test collections for the task, we find that ChatGPT is capable of generating queries that lead to high search precision, although trading-off this for recall. Overall, our study demonstrates the potential of ChatGPT in generating effective Boolean queries for systematic review literature search. The ability of ChatGPT to follow complex instructions and generate queries with high precision makes it a valuable tool for researchers conducting systematic reviews, particularly for rapid reviews where time is a constraint and often trading-off higher precision for lower recall is acceptable.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Information Retrieval},
  file = {/home/ral/Zotero/storage/VPARBT24/Wang et al. - 2023 - Can ChatGPT Write a Good Boolean Query for Systematic Review Literature Search.pdf}
}

@online{wang_etal23b,
  title = {Is {{ChatGPT}} a {{Good NLG Evaluator}}? {{A Preliminary Study}}},
  shorttitle = {Is {{ChatGPT}} a {{Good NLG Evaluator}}?},
  author = {Wang, Jiaan and Liang, Yunlong and Meng, Fandong and Sun, Zengkui and Shi, Haoxiang and Li, Zhixu and Xu, Jinan and Qu, Jianfeng and Zhou, Jie},
  date = {2023-10-24},
  eprint = {2303.04048},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2303.04048},
  urldate = {2023-11-29},
  abstract = {Recently, the emergence of ChatGPT has attracted wide attention from the computational linguistics community. Many prior studies have shown that ChatGPT achieves remarkable performance on various NLP tasks in terms of automatic evaluation metrics. However, the ability of ChatGPT to serve as an evaluation metric is still underexplored. Considering assessing the quality of natural language generation (NLG) models is an arduous task and NLG metrics notoriously show their poor correlation with human judgments, we wonder whether ChatGPT is a good NLG evaluation metric. In this report, we provide a preliminary meta-evaluation on ChatGPT to show its reliability as an NLG metric. In detail, we regard ChatGPT as a human evaluator and give task-specific (e.g., summarization) and aspect-specific (e.g., relevance) instruction to prompt ChatGPT to evaluate the generated results of NLG models. We conduct experiments on five NLG meta-evaluation datasets (including summarization, story generation and data-to-text tasks). Experimental results show that compared with previous automatic metrics, ChatGPT achieves state-of-the-art or competitive correlation with human judgments in most cases. In addition, we find that the effectiveness of the ChatGPT evaluator might be influenced by the creation method of the meta-evaluation datasets. For the meta-evaluation datasets which are created greatly depending on the reference and thus are biased, the ChatGPT evaluator might lose its effectiveness. We hope our preliminary study could prompt the emergence of a general-purposed reliable NLG metric.},
  langid = {english},
  pubstate = {prepublished},
  file = {/home/ral/Zotero/storage/GZPWXTTL/Wang et al. - 2023 - Is ChatGPT a Good NLG Evaluator A Preliminary Stu.pdf}
}

@online{wang_etal24,
  title = {Not {{All Countries Celebrate Thanksgiving}}: {{On}} the {{Cultural Dominance}} in {{Large Language Models}}},
  shorttitle = {Not {{All Countries Celebrate Thanksgiving}}},
  author = {Wang, Wenxuan and Jiao, Wenxiang and Huang, Jingyuan and Dai, Ruyi and Huang, Jen-tse and Tu, Zhaopeng and Lyu, Michael R.},
  date = {2024-02-16},
  eprint = {2310.12481},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2310.12481},
  url = {http://arxiv.org/abs/2310.12481},
  urldate = {2024-10-26},
  abstract = {This paper identifies a cultural dominance issue within large language models (LLMs) due to the predominant use of English data in model training (e.g., ChatGPT). LLMs often provide inappropriate English-culture-related answers that are not relevant to the expected culture when users ask in non-English languages. To systematically evaluate the cultural dominance issue, we build a benchmark of concrete (e.g., holidays and songs) and abstract (e.g., values and opinions) cultural objects. Empirical results show that the representative GPT models suffer from the culture dominance problem, where GPT-4 is the most affected while text-davinci-003 suffers the least from this problem. Our study emphasizes the need to critically examine cultural dominance and ethical consideration in their development and deployment. We show that two straightforward methods in model development (i.e., pretraining on more diverse data) and deployment (e.g., culture-aware prompting) can significantly mitigate the cultural dominance issue in LLMs.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/ral/Zotero/storage/NH9YCNUL/Wang et al. - 2024 - Not All Countries Celebrate Thanksgiving On the Cultural Dominance in Large Language Models.pdf;/home/ral/Zotero/storage/M9MD2QM8/2310.html}
}

@online{wang23,
  title = {Deciphering the {{Enigma}}: {{A Deep Dive}} into {{Understanding}} and {{Interpreting LLM Outputs}}},
  shorttitle = {Deciphering the {{Enigma}}},
  author = {Wang, Yifei},
  date = {2023-09-07},
  doi = {10.36227/techrxiv.24085833.v1},
  url = {https://www.techrxiv.org/doi/full/10.36227/techrxiv.24085833.v1},
  urldate = {2024-10-26},
  abstract = {In the rapidly evolving domain of artificial intelligence, Large Language Models (LLMs) like GPT-3 and GPT-4 have emerged as monumental achievements in natural language processing. However, their intricate architectures often act as “Black Boxes,” making the interpretation of their outputs a formidable challenge. This article delves into the opaque nature of LLMs, highlighting the critical need for enhanced transparency and understandability. We provide a detailed exposition of the “Black Box” problem, examining the real-world implications of misunderstood or misinterpreted outputs. Through a review of current interpretability methodologies, we elucidate their inherent challenges and limitations. Several case studies are presented, offering both successful and problematic instances of LLM outputs. As we navigate the ethical labyrinth surrounding LLM transparency, we emphasize the pressing responsibility of developers and AI practitioners. Concluding with a gaze into the future, we discuss emerging research and prospective pathways that promise to unravel the enigma of LLMs, advocating for a harmonious balance between model capability and interpretability.},
  langid = {english},
  pubstate = {prepublished},
  file = {/home/ral/Zotero/storage/6WQPTGNN/Wang - 2023 - Deciphering the Enigma A Deep Dive into Understanding and Interpreting LLM Outputs.pdf}
}

@article{watters_lemanski23,
  title = {Universal Skepticism of {{ChatGPT}}: A Review of Early Literature on Chat Generative Pre-Trained Transformer},
  shorttitle = {Universal Skepticism of {{ChatGPT}}},
  author = {Watters, Casey and Lemanski, Michal K.},
  date = {2023-08-23},
  journaltitle = {Frontiers in Big Data},
  shortjournal = {Front. Big Data},
  volume = {6},
  pages = {1224976},
  issn = {2624-909X},
  doi = {10.3389/fdata.2023.1224976},
  url = {https://www.frontiersin.org/articles/10.3389/fdata.2023.1224976/full},
  urldate = {2023-11-29},
  abstract = {ChatGPT, a new language model developed by OpenAI, has garnered significant attention in various fields since its release. This literature review provides an overview of early ChatGPT literature across multiple disciplines, exploring its applications, limitations, and ethical considerations. The review encompasses Scopus-indexed publications from November 2022 to April 2023 and includes 156 articles related to ChatGPT. The findings reveal a predominance of negative sentiment across disciplines, though subject-specific attitudes must be considered. The review highlights the implications of ChatGPT in many fields including healthcare, raising concerns about employment opportunities and ethical considerations. While ChatGPT holds promise for improved communication, further research is needed to address its capabilities and limitations. This literature review provides insights into early research on ChatGPT, informing future investigations and practical applications of chatbot technology, as well as development and usage of generative AI.},
  langid = {english},
  annotation = {15 citations (Semantic Scholar/DOI) [2024-10-14]\\
12 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/3PYQNPU2/Watters et Lemanski - 2023 - Universal skepticism of ChatGPT a review of early.pdf}
}

@article{weldon06,
  title = {The {{Structure}} of {{Intersectionality}}: {{A Comparative Politics}} of {{Gender}}},
  shorttitle = {The {{Structure}} of {{Intersectionality}}},
  author = {Weldon, S. Laurel},
  date = {2006-06},
  journaltitle = {Politics \& Gender},
  shortjournal = {Pol Gender},
  volume = {2},
  number = {02},
  issn = {1743-923X, 1743-9248},
  doi = {10.1017/S1743923X06231040},
  url = {http://www.journals.cambridge.org/abstract_S1743923X06231040},
  urldate = {2023-04-11},
  langid = {english},
  file = {/home/ral/Zotero/storage/RGBNZMLI/Weldon - 2006 - The Structure of Intersectionality A Comparative Politics of Gender.pdf}
}

@misc{wells_etal00,
  title = {The {{Newcastle-Ottawa Scale}} ({{NOS}}) for Assessing the Quality of Nonrandomised Studies in Meta-Analyses},
  author = {Wells, George A. and Shea, Beverley and O’Connell, Dianne and Peterson, Joan and Welch, Vivian and Losos, Michelle and Tugwell, Peter},
  date = {2000},
  url = {https://scholar.archive.org/work/zuw33wskgzf4bceqgi7opslsre/access/wayback/http://www3.med.unipmn.it/dispense_ebm/2009-2010/Corso%20Perfezionamento%20EBM_Faggiano/NOS_oxford.pdf},
  urldate = {2023-10-06},
  organization = {Department of Epidemiology and Commuunity Medicine, University of Ottawa},
  file = {/home/ral/Zotero/storage/W3AJ34AC/Wells et al. - 2000 - The Newcastle-Ottawa Scale (NOS) for assessing the quality of nonrandomised studies in meta-analyses.pdf}
}

@online{white_etal23,
  title = {A {{Prompt Pattern Catalog}} to {{Enhance Prompt Engineering}} with {{ChatGPT}}},
  author = {White, Jules and Fu, Quchen and Hays, Sam and Sandborn, Michael and Olea, Carlos and Gilbert, Henry and Elnashar, Ashraf and Spencer-Smith, Jesse and Schmidt, Douglas C.},
  date = {2023-02-21},
  eprint = {2302.11382},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2302.11382},
  urldate = {2023-09-26},
  abstract = {Prompt engineering is an increasingly important skill set needed to converse effectively with large language models (LLMs), such as ChatGPT. Prompts are instructions given to an LLM to enforce rules, automate processes, and ensure specific qualities (and quantities) of generated output. Prompts are also a form of programming that can customize the outputs and interactions with an LLM.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Software Engineering},
  file = {/home/ral/Zotero/storage/8L55J8UD/White et al. - 2023 - A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT.pdf}
}

@article{williamson_etal23,
  title = {Re-Examining {{AI}}, Automation and Datafication in Education},
  author = {Williamson, Ben and Macgilchrist, Felicitas and Potter, John},
  date = {2023-01-02},
  journaltitle = {Learning, Media and Technology},
  shortjournal = {Learning, Media and Technology},
  volume = {48},
  number = {1},
  pages = {1--5},
  issn = {1743-9884, 1743-9892},
  doi = {10.1080/17439884.2023.2167830},
  url = {https://www.tandfonline.com/doi/full/10.1080/17439884.2023.2167830},
  urldate = {2023-09-27},
  langid = {english},
  annotation = {38 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/H5ZUC9TT/Williamson et al. - 2023 - Re-examining AI, automation and datafication in education.pdf}
}

@article{wilson_etal23,
  title = {Using Automated Analysis to Assess Middle School Students' Competence with Scientific Argumentation},
  author = {Wilson, Christopher D. and Haudek, Kevin C. and Osborne, Jonathan F. and Buck Bracey, Zoë E. and Cheuk, Tina and Donovan, Brian M. and Stuhlsatz, Molly A. M. and Santiago, Marisol M. and Zhai, Xiaoming},
  date = {2023-05-04},
  journaltitle = {Journal of Research in Science Teaching},
  shortjournal = {J Res Sci Teach},
  pages = {tea.21864},
  issn = {0022-4308, 1098-2736},
  doi = {10.1002/tea.21864},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/tea.21864},
  urldate = {2023-09-27},
  abstract = {Abstract Argumentation is fundamental to science education, both as a prominent feature of scientific reasoning and as an effective mode of learning—a perspective reflected in contemporary frameworks and standards. The successful implementation of argumentation in school science, however, requires a paradigm shift in science assessment from the measurement of knowledge and understanding to the measurement of performance and knowledge in use. Performance tasks requiring argumentation must capture the many ways students can construct and evaluate arguments in science, yet such tasks are both expensive and resource‐intensive to score. In this study we explore how machine learning text classification techniques can be applied to develop efficient, valid, and accurate constructed‐response measures of students' competency with written scientific argumentation that are aligned with a validated argumentation learning progression. Data come from 933 middle school students in the San Francisco Bay Area and are based on three sets of argumentation items in three different science contexts. The findings demonstrate that we have been able to develop computer scoring models that can achieve substantial to almost perfect agreement between human‐assigned and computer‐predicted scores. Model performance was slightly weaker for harder items targeting higher levels of the learning progression, largely due to the linguistic complexity of these responses and the sparsity of higher‐level responses in the training data set. Comparing the efficacy of different scoring approaches revealed that breaking down students' arguments into multiple components (e.g., the presence of an accurate claim or providing sufficient evidence), developing computer models for each component, and combining scores from these analytic components into a holistic score produced better results than holistic scoring approaches. However, this analytical approach was found to be differentially biased when scoring responses from English learners (EL) students as compared to responses from non‐EL students on some items. Differences in the severity between human and computer scores for EL between these approaches are explored, and potential sources of bias in automated scoring are discussed.},
  langid = {english},
  annotation = {11 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/99UIHLQ6/Wilson et al. - 2023 - Using automated analysis to assess middle school students' competence with scientific argumentation.pdf}
}

@online{wolf_etal23,
  title = {Fundamental {{Limitations}} of {{Alignment}} in {{Large Language Models}}},
  author = {Wolf, Yotam and Wies, Noam and Avnery, Oshri and Levine, Yoav and Shashua, Amnon},
  date = {2023-08-01},
  eprint = {2304.11082},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2304.11082},
  urldate = {2023-09-26},
  abstract = {An important aspect in developing language models that interact with humans is aligning their behavior to be useful and unharmful for their human users. This is usually achieved by tuning the model in a way that enhances desired behaviors and inhibits undesired ones, a process referred to as alignment. In this paper, we propose a theoretical approach called Behavior Expectation Bounds (BEB) which allows us to formally investigate several inherent characteristics and limitations of alignment in large language models. Importantly, we prove that for any behavior that has a finite probability of being exhibited by the model, there exist prompts that can trigger the model into outputting this behavior, with probability that increases with the length of the prompt. This implies that any alignment process that attenuates undesired behavior but does not remove it altogether, is not safe against adversarial prompting attacks. Furthermore, our framework hints at the mechanism by which leading alignment approaches such as reinforcement learning from human feedback increase the LLM’s proneness to being prompted into the undesired behaviors. Moreover, we include the notion of personas in our BEB framework, and find that behaviors which are generally very unlikely to be exhibited by the model can be brought to the front by prompting the model to behave as specific persona. This theoretical result is being experimentally demonstrated in large scale by the so called contemporary “chatGPT jailbreaks", where adversarial users trick the LLM into breaking its alignment guardrails by triggering it into acting as a malicious persona. Our results expose fundamental limitations in alignment of LLMs and bring to the forefront the need to devise reliable mechanisms for ensuring AI safety.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/ral/Zotero/storage/NH4NPIMM/Wolf et al. - 2023 - Fundamental Limitations of Alignment in Large Language Models.pdf}
}

@online{wu_etal23,
  title = {On Decoder-Only Architecture for Speech-to-Text and Large Language Model Integration},
  author = {Wu, Jian and Gaur, Yashesh and Chen, Zhuo and Zhou, Long and Zhu, Yimeng and Wang, Tianrui and Li, Jinyu and Liu, Shujie and Ren, Bo and Liu, Linquan and Wu, Yu},
  date = {2023-07-14},
  eprint = {2307.03917},
  eprinttype = {arXiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/2307.03917},
  urldate = {2023-09-27},
  abstract = {Large language models (LLMs) have achieved remarkable success in the field of natural language processing, enabling better human-computer interaction using natural language. However, the seamless integration of speech signals into LLMs has not been explored well. The "decoder-only" architecture has also not been well studied for speech processing tasks. In this research, we introduce Speech-LLaMA, a novel approach that effectively incorporates acoustic information into text-based large language models. Our method leverages Connectionist Temporal Classification and a simple audio encoder to map the compressed acoustic features to the continuous semantic space of the LLM. In addition, we further probe the decoder-only architecture for speech-to-text tasks by training a smaller scale randomly initialized speech-LLaMA model from speech-text paired data alone. We conduct experiments on multilingual speech-to-text translation tasks and demonstrate a significant improvement over strong baselines, highlighting the potential advantages of decoder-only models for speech-to-text conversion.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/home/ral/Zotero/storage/TPHNXJVD/Wu et al. - 2023 - On decoder-only architecture for speech-to-text and large language model integration.pdf}
}

@online{xu_etal23,
  title = {Mental-{{LLM}}: {{Leveraging Large Language Models}} for {{Mental Health Prediction}} via {{Online Text Data}}},
  shorttitle = {Mental-{{LLM}}},
  author = {Xu, Xuhai and Yao, Bingsheng and Dong, Yuanzhe and Gabriel, Saadia and Yu, Hong and Hendler, James and Ghassemi, Marzyeh and Dey, Anind K. and Wang, Dakuo},
  date = {2023-09-15},
  eprint = {2307.14385},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2307.14385},
  urldate = {2023-09-27},
  abstract = {Advances in large language models (LLMs) have empowered a variety of applications. However, there is still a significant gap in research when it comes to understanding and enhancing the capabilities of LLMs in the field of mental health. In this work, we present the first comprehensive evaluation of multiple LLMs, including Alpaca, Alpaca-LoRA, FLAN-T5, GPT-3.5, and GPT-4, on various mental health prediction tasks via online text data. We conduct a broad range of experiments, covering zero-shot prompting, few-shot prompting, and instruction fine-tuning. The results indicate a promising yet limited performance of LLMs with zero-shot and few-shot prompt designs for the mental health tasks. More importantly, our experiments show that instruction finetuning can significantly boost the performance of LLMs for all tasks simultaneously. Our best-finetuned models, Mental-Alpaca and Mental-FLAN-T5, outperform the best prompt design of GPT-3.5 (25 and 15 times bigger) by 10.9\% on balanced accuracy and the best of GPT-4 (250 and 150 times bigger) by 4.8\%. They further perform on par with the state-of-the-art task-specific language model. We also conduct an exploratory case study on LLMs' capability on the mental health reasoning tasks, illustrating the promising capability of certain models such as GPT-4. We summarize our findings into a set of action guidelines for potential methods to enhance LLMs' capability for mental health tasks. Meanwhile, we also emphasize the important limitations before achieving deployability in real-world mental health settings, such as known racial and gender bias. We highlight the important ethical risks accompanying this line of research.},
  pubstate = {prepublished},
  keywords = {68U35,Computer Science - Computation and Language,Computer Science - Human-Computer Interaction,H.5.2,I.2.m},
  file = {/home/ral/Zotero/storage/SPQT2AAE/Xu et al. - 2023 - Mental-LLM Leveraging Large Language Models for Mental Health Prediction via Online Text Data.pdf}
}

@online{xu_etal24,
  title = {{{AI}} for Social Science and Social Science of {{AI}}: {{A Survey}}},
  shorttitle = {{{AI}} for Social Science and Social Science of {{AI}}},
  author = {Xu, Ruoxi and Sun, Yingfei and Ren, Mengjie and Guo, Shiguang and Pan, Ruotong and Lin, Hongyu and Sun, Le and Han, Xianpei},
  date = {2024-01-22},
  eprint = {2401.11839},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2401.11839},
  urldate = {2024-09-12},
  abstract = {Recent advancements in artificial intelligence, particularly with the emergence of large language models (LLMs), have sparked a rethinking of artificial general intelligence possibilities. The increasing human-like capabilities of AI are also attracting attention in social science research, leading to various studies exploring the combination of these two fields. In this survey, we systematically categorize previous explorations in the combination of AI and social science into two directions that share common technical approaches but differ in their research objectives. The first direction is focused on AI for social science, where AI is utilized as a powerful tool to enhance various stages of social science research. While the second direction is the social science of AI, which examines AI agents as social entities with their human-like cognitive and linguistic capabilities. By conducting a thorough review, particularly on the substantial progress facilitated by recent advancements in large language models, this paper introduces a fresh perspective to reassess the relationship between AI and social science, provides a cohesive framework that allows researchers to understand the distinctions and connections between AI for social science and social science of AI, and also summarized state-of-art experiment simulation platforms to facilitate research in these two directions. We believe that as AI technology continues to advance and intelligent agents find increasing applications in our daily lives, the significance of the combination of AI and social science will become even more prominent.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Computers and Society},
  file = {/home/ral/Zotero/storage/F5VC8ZNC/Xu et al. - 2024 - AI for social science and social science of AI A Survey.pdf}
}

@online{yadav_bethard19,
  title = {A {{Survey}} on {{Recent Advances}} in {{Named Entity Recognition}} from {{Deep Learning}} Models},
  author = {Yadav, Vikas and Bethard, Steven},
  date = {2019-10-24},
  eprint = {1910.11470},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1910.11470},
  urldate = {2024-06-05},
  abstract = {Named Entity Recognition (NER) is a key component in NLP systems for question answering, information retrieval, relation extraction, etc. NER systems have been studied and developed widely for decades, but accurate systems using deep neural networks (NN) have only been introduced in the last few years. We present a comprehensive survey of deep neural network architectures for NER, and contrast them with previous approaches to NER based on feature engineering and other supervised or semi-supervised learning algorithms. Our results highlight the improvements achieved by neural networks, and show how incorporating some of the lessons learned from past work on feature-based NER systems can yield further improvements.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/ral/Zotero/storage/2VKWYK38/Yadav_Bethard_2019_A Survey on Recent Advances in Named Entity Recognition from Deep Learning.pdf}
}

@online{yamin_etal24,
  title = {Failure {{Modes}} of {{LLMs}} for {{Causal Reasoning}} on {{Narratives}}},
  author = {Yamin, Khurram and Gupta, Shantanu and Ghosal, Gaurav R. and Lipton, Zachary C. and Wilder, Bryan},
  date = {2024-10-31},
  eprint = {2410.23884},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2410.23884},
  url = {http://arxiv.org/abs/2410.23884},
  urldate = {2024-12-18},
  abstract = {In this work, we investigate the causal reasoning abilities of large language models (LLMs) through the representative problem of inferring causal relationships from narratives. We find that even state-of-the-art language models rely on unreliable shortcuts, both in terms of the narrative presentation and their parametric knowledge. For example, LLMs tend to determine causal relationships based on the topological ordering of events (i.e., earlier events cause later ones), resulting in lower performance whenever events are not narrated in their exact causal order. Similarly, we demonstrate that LLMs struggle with long-term causal reasoning and often fail when the narratives are long and contain many events. Additionally, we show LLMs appear to rely heavily on their parametric knowledge at the expense of reasoning over the provided narrative. This degrades their abilities whenever the narrative opposes parametric knowledge. We extensively validate these failure modes through carefully controlled synthetic experiments, as well as evaluations on real-world narratives. Finally, we observe that explicitly generating a causal graph generally improves performance while naive chain-of-thought is ineffective. Collectively, our results distill precise failure modes of current state-of-the-art models and can pave the way for future techniques to enhance causal reasoning in LLMs.},
  pubstate = {prepublished},
  version = {1},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/ral/Zotero/storage/XFIHWQDG/Yamin et al. - 2024 - Failure Modes of LLMs for Causal Reasoning on Narratives.pdf;/home/ral/Zotero/storage/L2V887DZ/2410.html}
}

@article{yan_etal23,
  title = {Practical and {{Ethical Challenges}} of {{Large Language Models}} in {{Education}}: {{A Systematic Scoping Review}}},
  shorttitle = {Practical and {{Ethical Challenges}} of {{Large Language Models}} in {{Education}}},
  author = {Yan, Lixiang and Sha, Lele and Zhao, Linxuan and Li, Yuheng and Martinez-Maldonado, Roberto and Chen, Guanliang and Li, Xinyu and Jin, Yueqiao and Gašević, Dragan},
  date = {2023-08-06},
  journaltitle = {British Journal of Educational Technology},
  shortjournal = {Brit J Educational Tech},
  eprint = {2303.13379},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {bjet.13370},
  issn = {0007-1013, 1467-8535},
  doi = {10.1111/bjet.13370},
  url = {http://arxiv.org/abs/2303.13379},
  urldate = {2023-09-27},
  abstract = {Educational technology innovations leveraging large language models (LLMs) have shown the potential to automate the laborious process of generating and analysing textual content. While various innovations have been developed to automate a range of educational tasks (e.g., question generation, feedback provision, and essay grading), there are concerns regarding the practicality and ethicality of these innovations. Such concerns may hinder future research and the adoption of LLMs-based innovations in authentic educational contexts. To address this, we conducted a systematic scoping review of 118 peer-reviewed papers published since 2017 to pinpoint the current state of research on using LLMs to automate and support educational tasks. The findings revealed 53 use cases for LLMs in automating education tasks, categorised into nine main categories: profiling/labelling, detection, grading, teaching support, prediction, knowledge representation, feedback, content generation, and recommendation. Additionally, we also identified several practical and ethical challenges, including low technological readiness, lack of replicability and transparency, and insufficient privacy and beneficence considerations. The findings were summarised into three recommendations for future studies, including updating existing innovations with state-of-the-art models (e.g., GPT-3/4), embracing the initiative of open-sourcing models/systems, and adopting a human-centred approach throughout the developmental process. As the intersection of AI and education is continuously evolving, the findings of this study can serve as an essential reference point for researchers, allowing them to leverage the strengths, learn from the limitations, and uncover potential research opportunities enabled by ChatGPT and other generative AI models.},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computers and Society},
  annotation = {70 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/75B9U6U8/Yan et al. - 2023 - Practical and Ethical Challenges of Large Language Models in Education A Systematic Scoping Review.pdf}
}

@online{yang_etal23,
  title = {Large {{Language Models}} for {{Automated Open-domain Scientific Hypotheses Discovery}}},
  author = {Yang, Zonglin and Du, Xinya and Li, Junxian and Zheng, Jie and Poria, Soujanya and Cambria, Erik},
  date = {2023-09-06},
  eprint = {2309.02726},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2309.02726},
  urldate = {2023-09-27},
  abstract = {Hypothetical induction is recognized as the main reasoning type when scientists make observations about the world and try to propose hypotheses to explain those observations. Past research on hypothetical induction has a limited setting that (1) the observation annotations of the dataset are not raw web corpus but are manually selected sentences (resulting in a close-domain setting); and (2) the ground truth hypotheses annotations are mostly commonsense knowledge, making the task less challenging. In this work, we propose the first NLP dataset for social science academic hypotheses discovery, consisting of 50 recent papers published in top social science journals. Raw web corpora that are necessary for developing hypotheses in the published papers are also collected in the dataset, with the final goal of creating a system that automatically generates valid, novel, and helpful (to human researchers) hypotheses, given only a pile of raw web corpora. The new dataset can tackle the previous problems because it requires to (1) use raw web corpora as observations; and (2) propose hypotheses even new to humanity. A multi-module framework is developed for the task, as well as three different feedback mechanisms that empirically show performance gain over the base framework. Finally, our framework exhibits high performance in terms of both GPT-4 based evaluation and social science expert evaluation.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  annotation = {15 citations (Semantic Scholar/arXiv) [2024-10-14]},
  file = {/home/ral/Zotero/storage/CWGZN8NG/Yang et al. - 2023 - Large Language Models for Automated Open-domain Scientific Hypotheses Discovery.pdf}
}

@online{yang_etal23a,
  title = {Large {{Language Models}} as {{Optimizers}}},
  author = {Yang, Chengrun and Wang, Xuezhi and Lu, Yifeng and Liu, Hanxiao and Le, Quoc V. and Zhou, Denny and Chen, Xinyun},
  date = {2023-12-07},
  eprint = {2309.03409},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2309.03409},
  urldate = {2024-01-08},
  abstract = {Optimization is ubiquitous. While derivative-based algorithms have been powerful tools for various problems, the absence of gradient imposes challenges on many real-world applications. In this work, we propose Optimization by PROmpting (OPRO), a simple and effective approach to leverage large language models (LLMs) as optimizers, where the optimization task is described in natural language. In each optimization step, the LLM generates new solutions from the prompt that contains previously generated solutions with their values, then the new solutions are evaluated and added to the prompt for the next optimization step. We first showcase OPRO on linear regression and traveling salesman problems, then move on to prompt optimization where the goal is to find instructions that maximize the task accuracy. With a variety of LLMs, we demonstrate that the best prompts optimized by OPRO outperform human-designed prompts by up to 8\% on GSM8K, and by up to 50\% on Big-Bench Hard tasks. Code at https://github.com/ google-deepmind/opro.},
  langid = {english},
  pubstate = {prepublished},
  file = {/home/ral/Zotero/storage/GWDL8CZX/Yang et al. - 2023 - Large Language Models as Optimizers.pdf}
}

@inproceedings{yang22,
  title = {A Systematic Literature Review on the Disruptions of Artificial Intelligence within the Business World: {{In}} Terms of the Evolution of Competences},
  shorttitle = {A Systematic Literature Review on the Disruptions of Artificial Intelligence within the Business World},
  booktitle = {27ème {{Conférence}} de l'{{AIM}}},
  author = {Yang, Shengxing},
  date = {2022-06},
  location = {Carry Le Rouet, France},
  url = {https://hal.science/hal-03694170},
  urldate = {2023-10-03},
  abstract = {The advancement of artificial intelligence has brought both opportunities and challenges to the business world, and its potentially disruptive impact has attracted the research interest of management scholars. This exploratory research applied a systematic literature review approach to explore the nexus between AI and competences to help both firms and individuals better address the disruptions from AI. After reviewing relevant publications from the Business Source Complete database for the past decade (2011-2021), we selected 65 articl debates and issues on AI and perspectives linked with competences. Furthermore, we synthesize two frameworks (RBV framework for firm-level; Key and STEM competences for individual-level) and an overview to gain a holistic understanding of the nexus between AI and competences. We found relatively little empirical evidence in the literature, the implementation of AI was still in its preliminary stages, and the frameworks we aggregated industry and yield richer insights.},
  keywords = {Artificial Intelligence,Competences,Firm,Individual,Systematic literature review},
  file = {/home/ral/Zotero/storage/E5F7WK7Z/Yang - 2022 - A systematic literature review on the disruptions of artificial intelligence within the business wor.pdf}
}

@article{yarkoni_etal19a,
  title = {Enhancing and Accelerating Social Science via Automation: {{Challenges}} and Opportunities},
  shorttitle = {Enhancing and Accelerating Social Science via Automation},
  author = {Yarkoni, Tal and Eckles, Dean and Heathers, James AJ and Levenstein, Margaret and Smaldino, Paul E. and Lane, Julia I.},
  date = {2019},
  journaltitle = {Harv. Data Sci. Rev},
  url = {https://assets.pubpub.org/613tgd6o/df2262f5-76cc-4c1b-85a1-328ef65598e5.pdf},
  urldate = {2023-09-27}
}

@inproceedings{yeh_etal23,
  title = {Evaluating {{Interfaced LLM Bias}}},
  booktitle = {Proceedings of the 35th {{Conference}} on {{Computational Linguistics}} and {{Speech Processing}} ({{ROCLING}} 2023)},
  author = {Yeh, Kai-Ching and Chi, Jou-An and Lian, Da-Chen and Hsieh, Shu-Kai},
  editor = {Wu, Jheng-Long and Su, Ming-Hsiang},
  date = {2023-10},
  pages = {292--299},
  publisher = {{The Association for Computational Linguistics and Chinese Language Processing (ACLCLP)}},
  location = {Taipei City, Taiwan},
  url = {https://aclanthology.org/2023.rocling-1.37},
  urldate = {2023-12-23},
  eventtitle = {{{ROCLING}} 2023},
  file = {/home/ral/Zotero/storage/HWYGZGSL/Yeh et al. - 2023 - Evaluating Interfaced LLM Bias.pdf}
}

@article{zack_etal23,
  title = {Coding {{Inequity}}: {{Assessing GPT-4}}'s {{Potential}} for {{Perpetuating Racial}} and {{Gender Biases}} in {{Healthcare}}},
  shorttitle = {Coding {{Inequity}}},
  author = {Zack, Travis and Lehman, Eric and Suzgun, Mirac and Rodriguez, Jorge A. and Celi, Leo Anthony and Gichoya, Judy and Jurafsky, Dan and Szolovits, Peter and Bates, David W. and Abdulnour, Raja-Elie E.},
  date = {2023},
  journaltitle = {medRxiv},
  pages = {2023--07},
  publisher = {Cold Spring Harbor Laboratory Press},
  url = {https://www.medrxiv.org/content/10.1101/2023.07.13.23292577.abstract},
  urldate = {2023-11-24},
  file = {/home/ral/Zotero/storage/REYACVDQ/Zack et al_2023_Coding Inequity.pdf}
}

@book{zaller92,
  title = {The Nature and Origins of Mass Opinion},
  author = {Zaller, John R.},
  date = {1992},
  edition = {13. printing},
  publisher = {Cambridge Univ. Press},
  location = {Cambridge},
  isbn = {978-0-521-40449-5 978-0-521-40786-1},
  langid = {english},
  pagetotal = {367}
}

@inproceedings{zhang_etal15,
  title = {A {{Bayesian Hierarchical Model}} for {{Comparing Average F1 Scores}}},
  booktitle = {2015 {{IEEE International Conference}} on {{Data Mining}}},
  author = {Zhang, Dell and Wang, Jun and Zhao, Xiaoxue and Wang, Xiaoling},
  date = {2015-11},
  pages = {589--598},
  publisher = {IEEE},
  location = {Atlantic City, NJ, USA},
  doi = {10.1109/ICDM.2015.44},
  url = {http://ieeexplore.ieee.org/document/7373363/},
  urldate = {2024-08-02},
  eventtitle = {2015 {{IEEE International Conference}} on {{Data Mining}} ({{ICDM}})},
  isbn = {978-1-4673-9504-5},
  annotation = {12 citations (Crossref/DOI) [2024-10-14]},
  file = {/home/ral/Zotero/storage/GAM7Y89K/Zhang et al_2015_A Bayesian Hierarchical Model for Comparing Average F1 Scores.pdf}
}

@online{zhao_etal23,
  title = {Automatic {{Model Selection}} with {{Large Language Models}} for {{Reasoning}}},
  author = {Zhao, James Xu and Xie, Yuxi and Kawaguchi, Kenji and He, Junxian and Xie, Michael Qizhe},
  date = {2023-10-23},
  eprint = {2305.14333},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2305.14333},
  url = {http://arxiv.org/abs/2305.14333},
  urldate = {2024-12-18},
  abstract = {Chain-of-Thought (CoT) and Program-Aided Language Models (PAL) represent two distinct reasoning methods, each with its own strengths. CoT employs natural language, offering flexibility and interpretability, while PAL utilizes programming language, yielding more structured and rigorous logic. We introduce a model selection method to combine the best of both worlds by employing a large language model (LLM) to dynamically select between them. Our theoretical analysis underscores the feasibility of this method, which is further corroborated by empirical results. Our proposed method demonstrates significant performance improvements across eight reasoning datasets with Codex, ChatGPT, and GPT-4. Additionally, our method is complementary to self-consistency; when integrated, it can further enhance performance while significantly reducing computation costs. Moreover, we achieve new state-of-the-art results on GSM8K and SVAMP, with respective accuracies of 96.8\% and 93.7\%. Our code, data and prompts are available at https://github.com/XuZhao0/Model-Selection-Reasoning},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/ral/Zotero/storage/TU3YD4T8/Zhao et al. - 2023 - Automatic Model Selection with Large Language Models for Reasoning.pdf;/home/ral/Zotero/storage/F9YZ2WB4/2305.html}
}

@incollection{zino_etal23,
  title = {Network {{Science}} and {{Automation}}},
  booktitle = {Springer {{Handbook}} of {{Automation}}},
  author = {Zino, Lorenzo and Barzel, Baruch and Rizzo, Alessandro},
  editor = {Nof, Shimon Y.},
  date = {2023},
  pages = {251--274},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-96729-1_11},
  url = {https://link.springer.com/10.1007/978-3-030-96729-1_11},
  urldate = {2023-09-27},
  isbn = {978-3-030-96728-4 978-3-030-96729-1},
  langid = {english},
  file = {/home/ral/Zotero/storage/HMM38J8U/Zino et al. - 2023 - Network Science and Automation.pdf}
}
